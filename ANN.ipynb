{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_excel(\"Data/tr.xlsx\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_missing_sample = []\n",
    "row_value_count = train_data.apply(pd.Series.value_counts,axis=1,dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools\n",
    "#Data transform\n",
    "train_y = pd.DataFrame(train_data['outcome']) \n",
    "train_X = pd.DataFrame(train_data.drop(['outcome'],axis=1))\n",
    "\n",
    "train_X = tools.data_transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools\n",
    "tools.set_pandas_display_options()\n",
    "#train_X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[879, 51280]\n",
      "[879, 27076]\n"
     ]
    }
   ],
   "source": [
    "threshhold =len(train_X.columns)*0.25\n",
    "over_missing = row_value_count[np.nan]<=threshhold\n",
    "class_0 = train_y['outcome']==1\n",
    "\n",
    "print(sorted(train_y.value_counts()))\n",
    "train_X = train_X[over_missing|class_0]\n",
    "train_y = train_y[over_missing|class_0]\n",
    "print(sorted(train_y.value_counts()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[718, 21646]\n",
      "[161, 5430]\n"
     ]
    }
   ],
   "source": [
    "# Data split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(\n",
    "    train_X ,\n",
    "    train_y,\n",
    "    test_size=0.2,\n",
    "    random_state=42)\n",
    "\n",
    "print(sorted(train_y.value_counts()))\n",
    "print(sorted(val_y.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled continuous missing value with median\n",
      "filled nominal missing value with  constant\n"
     ]
    }
   ],
   "source": [
    "# Missing value imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import tools\n",
    "feature_kind = tools.init_feature_kind(train_X)\n",
    "cont,cate = tools.get_feature_kind(train_X,feature_kind)  \n",
    "\n",
    "strategy = 'median'\n",
    "\n",
    "imp_mean = IterativeImputer(max_iter=100,random_state=0)\n",
    "imp_mean.fit(train_X[cont])\n",
    "\n",
    "train_X[cont] = imp_mean.transform(train_X[cont])\n",
    "val_X[cont] = imp_mean.transform(val_X[cont])\n",
    "\n",
    "print(\"filled continuous missing value with \"+strategy)\n",
    "\n",
    "strategy = 'constant'\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy=strategy,fill_value=10.0)\n",
    "imp.fit(train_X[cate])\n",
    "\n",
    "train_X[cate] = imp.transform(train_X[cate])\n",
    "val_X[cate] = imp.transform(val_X[cate])\n",
    "\n",
    "\n",
    "print(\"filled nominal missing value with \",strategy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "cont,cate = tools.get_feature_kind(train_X,feature_kind)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(train_X[cont])\n",
    "train_X[cont] = scaler.transform(train_X[cont])\n",
    "val_X[cont] = scaler.transform(val_X[cont])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "minmax_train = pd.DataFrame(scaler.fit_transform(train_X),columns=train_X.columns)\n",
    "minmax_val = pd.DataFrame(scaler.fit_transform(val_X),columns=train_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>LOS</th>\n",
       "      <th>Joint</th>\n",
       "      <th>Drain</th>\n",
       "      <th>Cemented</th>\n",
       "      <th>Commercial_ALBC</th>\n",
       "      <th>Non_commercial_ALBC</th>\n",
       "      <th>cci_index</th>\n",
       "      <th>elx_index</th>\n",
       "      <th>Blood_trans</th>\n",
       "      <th>ASA</th>\n",
       "      <th>CBC_WBC</th>\n",
       "      <th>CBC_RBC</th>\n",
       "      <th>CBC_HG</th>\n",
       "      <th>CBC_HT</th>\n",
       "      <th>CBC_MCV</th>\n",
       "      <th>CBC_MCH</th>\n",
       "      <th>CBC_MCHC</th>\n",
       "      <th>CBC_RDW</th>\n",
       "      <th>CBC_Platelet</th>\n",
       "      <th>CBC_RDWCV</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Crea</th>\n",
       "      <th>GOT</th>\n",
       "      <th>GPT</th>\n",
       "      <th>ALB</th>\n",
       "      <th>Na</th>\n",
       "      <th>K</th>\n",
       "      <th>UA</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Congestive Heart Failure</th>\n",
       "      <th>Cardiac Arrhythmia</th>\n",
       "      <th>Valvular Disease</th>\n",
       "      <th>Heart disease</th>\n",
       "      <th>Pulmonary Circulation Disorders</th>\n",
       "      <th>Peripheral Vascular Disorders</th>\n",
       "      <th>Hypertension Uncomplicated</th>\n",
       "      <th>Paralysis</th>\n",
       "      <th>Other Neurological Disorders</th>\n",
       "      <th>Chronic Pulmonary Disease</th>\n",
       "      <th>Lung disease</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Hypothyroidism</th>\n",
       "      <th>Renal Failure</th>\n",
       "      <th>Liver Disease</th>\n",
       "      <th>Peptic Ulcer Disease excluding bleeding</th>\n",
       "      <th>AIDS/HIV</th>\n",
       "      <th>Lymphoma</th>\n",
       "      <th>Metastatic Cancer</th>\n",
       "      <th>Solid Tumor without Metastasis</th>\n",
       "      <th>Cancer history</th>\n",
       "      <th>Rheumatoid Arthritis/collagen</th>\n",
       "      <th>Coagulopathy</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Weight Loss</th>\n",
       "      <th>Fluid and Electrolyte Disorders</th>\n",
       "      <th>Blood Loss Anemia</th>\n",
       "      <th>Deficiency Anemia</th>\n",
       "      <th>Anemia</th>\n",
       "      <th>Alcohol Abuse</th>\n",
       "      <th>Drug Abuse</th>\n",
       "      <th>Psychoses</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Psyciatric disorder</th>\n",
       "      <th>OP_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.00000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "      <td>22364.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.606304</td>\n",
       "      <td>0.035123</td>\n",
       "      <td>0.067074</td>\n",
       "      <td>0.360937</td>\n",
       "      <td>0.689143</td>\n",
       "      <td>0.638839</td>\n",
       "      <td>0.092023</td>\n",
       "      <td>0.550617</td>\n",
       "      <td>0.039459</td>\n",
       "      <td>0.059199</td>\n",
       "      <td>0.122429</td>\n",
       "      <td>0.421541</td>\n",
       "      <td>0.035979</td>\n",
       "      <td>0.545102</td>\n",
       "      <td>0.665808</td>\n",
       "      <td>0.670762</td>\n",
       "      <td>0.559291</td>\n",
       "      <td>0.608514</td>\n",
       "      <td>0.609937</td>\n",
       "      <td>0.248170</td>\n",
       "      <td>0.360266</td>\n",
       "      <td>0.058710</td>\n",
       "      <td>0.140585</td>\n",
       "      <td>0.346144</td>\n",
       "      <td>0.019846</td>\n",
       "      <td>0.149236</td>\n",
       "      <td>0.959610</td>\n",
       "      <td>0.503449</td>\n",
       "      <td>0.761993</td>\n",
       "      <td>0.166735</td>\n",
       "      <td>0.081327</td>\n",
       "      <td>0.022223</td>\n",
       "      <td>0.031971</td>\n",
       "      <td>0.020077</td>\n",
       "      <td>0.024757</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.005589</td>\n",
       "      <td>0.216240</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.012610</td>\n",
       "      <td>0.047711</td>\n",
       "      <td>0.024705</td>\n",
       "      <td>0.096405</td>\n",
       "      <td>0.009211</td>\n",
       "      <td>0.022805</td>\n",
       "      <td>0.055938</td>\n",
       "      <td>0.04543</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>0.037784</td>\n",
       "      <td>0.014279</td>\n",
       "      <td>0.033670</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>0.008809</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.012788</td>\n",
       "      <td>0.002236</td>\n",
       "      <td>0.006797</td>\n",
       "      <td>0.004516</td>\n",
       "      <td>0.007691</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>0.016813</td>\n",
       "      <td>0.009748</td>\n",
       "      <td>0.546819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.144393</td>\n",
       "      <td>0.055531</td>\n",
       "      <td>0.043374</td>\n",
       "      <td>0.480283</td>\n",
       "      <td>0.462855</td>\n",
       "      <td>0.480348</td>\n",
       "      <td>0.289065</td>\n",
       "      <td>0.497442</td>\n",
       "      <td>0.083324</td>\n",
       "      <td>0.101646</td>\n",
       "      <td>0.327788</td>\n",
       "      <td>0.395705</td>\n",
       "      <td>0.011664</td>\n",
       "      <td>0.077362</td>\n",
       "      <td>0.088546</td>\n",
       "      <td>0.087403</td>\n",
       "      <td>0.069969</td>\n",
       "      <td>0.068705</td>\n",
       "      <td>0.055966</td>\n",
       "      <td>0.111240</td>\n",
       "      <td>0.050317</td>\n",
       "      <td>0.021370</td>\n",
       "      <td>0.052517</td>\n",
       "      <td>0.037145</td>\n",
       "      <td>0.006712</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.010555</td>\n",
       "      <td>0.043670</td>\n",
       "      <td>0.051829</td>\n",
       "      <td>0.031921</td>\n",
       "      <td>0.190646</td>\n",
       "      <td>0.147412</td>\n",
       "      <td>0.175927</td>\n",
       "      <td>0.140267</td>\n",
       "      <td>0.104968</td>\n",
       "      <td>0.041187</td>\n",
       "      <td>0.074554</td>\n",
       "      <td>0.411689</td>\n",
       "      <td>0.049532</td>\n",
       "      <td>0.111585</td>\n",
       "      <td>0.213158</td>\n",
       "      <td>0.111315</td>\n",
       "      <td>0.295152</td>\n",
       "      <td>0.095534</td>\n",
       "      <td>0.149283</td>\n",
       "      <td>0.229807</td>\n",
       "      <td>0.20825</td>\n",
       "      <td>0.017690</td>\n",
       "      <td>0.039530</td>\n",
       "      <td>0.058955</td>\n",
       "      <td>0.190678</td>\n",
       "      <td>0.073353</td>\n",
       "      <td>0.180383</td>\n",
       "      <td>0.067382</td>\n",
       "      <td>0.093443</td>\n",
       "      <td>0.039530</td>\n",
       "      <td>0.112363</td>\n",
       "      <td>0.047232</td>\n",
       "      <td>0.082163</td>\n",
       "      <td>0.047541</td>\n",
       "      <td>0.087362</td>\n",
       "      <td>0.032742</td>\n",
       "      <td>0.051728</td>\n",
       "      <td>0.128572</td>\n",
       "      <td>0.072602</td>\n",
       "      <td>0.050935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.030011</td>\n",
       "      <td>0.502763</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.625217</td>\n",
       "      <td>0.553947</td>\n",
       "      <td>0.606837</td>\n",
       "      <td>0.596026</td>\n",
       "      <td>0.176235</td>\n",
       "      <td>0.331745</td>\n",
       "      <td>0.045505</td>\n",
       "      <td>0.109893</td>\n",
       "      <td>0.317936</td>\n",
       "      <td>0.019291</td>\n",
       "      <td>0.131709</td>\n",
       "      <td>0.952565</td>\n",
       "      <td>0.484232</td>\n",
       "      <td>0.717462</td>\n",
       "      <td>0.148560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.515336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.639535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.035674</td>\n",
       "      <td>0.543254</td>\n",
       "      <td>0.664329</td>\n",
       "      <td>0.667680</td>\n",
       "      <td>0.559211</td>\n",
       "      <td>0.608670</td>\n",
       "      <td>0.610374</td>\n",
       "      <td>0.200135</td>\n",
       "      <td>0.354299</td>\n",
       "      <td>0.054812</td>\n",
       "      <td>0.134928</td>\n",
       "      <td>0.353247</td>\n",
       "      <td>0.019605</td>\n",
       "      <td>0.142627</td>\n",
       "      <td>0.961229</td>\n",
       "      <td>0.505568</td>\n",
       "      <td>0.771313</td>\n",
       "      <td>0.164035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.542556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.709302</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.075758</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.040770</td>\n",
       "      <td>0.586107</td>\n",
       "      <td>0.718085</td>\n",
       "      <td>0.726759</td>\n",
       "      <td>0.580263</td>\n",
       "      <td>0.630363</td>\n",
       "      <td>0.626364</td>\n",
       "      <td>0.270460</td>\n",
       "      <td>0.383449</td>\n",
       "      <td>0.064415</td>\n",
       "      <td>0.159963</td>\n",
       "      <td>0.365792</td>\n",
       "      <td>0.019982</td>\n",
       "      <td>0.157029</td>\n",
       "      <td>0.966488</td>\n",
       "      <td>0.530007</td>\n",
       "      <td>0.800821</td>\n",
       "      <td>0.182249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.570785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                AGE           SEX           LOS         Joint         Drain  \\\n",
       "count  22364.000000  22364.000000  22364.000000  22364.000000  22364.000000   \n",
       "mean       0.606304      0.035123      0.067074      0.360937      0.689143   \n",
       "std        0.144393      0.055531      0.043374      0.480283      0.462855   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.534884      0.000000      0.045455      0.000000      0.000000   \n",
       "50%        0.639535      0.000000      0.060606      0.000000      1.000000   \n",
       "75%        0.709302      0.100000      0.075758      1.000000      1.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           Cemented  Commercial_ALBC  Non_commercial_ALBC     cci_index  \\\n",
       "count  22364.000000     22364.000000         22364.000000  22364.000000   \n",
       "mean       0.638839         0.092023             0.550617      0.039459   \n",
       "std        0.480348         0.289065             0.497442      0.083324   \n",
       "min        0.000000         0.000000             0.000000      0.000000   \n",
       "25%        0.000000         0.000000             0.000000      0.000000   \n",
       "50%        1.000000         0.000000             1.000000      0.000000   \n",
       "75%        1.000000         0.000000             1.000000      0.066667   \n",
       "max        1.000000         1.000000             1.000000      1.000000   \n",
       "\n",
       "          elx_index   Blood_trans           ASA       CBC_WBC       CBC_RBC  \\\n",
       "count  22364.000000  22364.000000  22364.000000  22364.000000  22364.000000   \n",
       "mean       0.059199      0.122429      0.421541      0.035979      0.545102   \n",
       "std        0.101646      0.327788      0.395705      0.011664      0.077362   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.111111      0.030011      0.502763   \n",
       "50%        0.000000      0.000000      0.222222      0.035674      0.543254   \n",
       "75%        0.076923      0.000000      1.000000      0.040770      0.586107   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "             CBC_HG        CBC_HT       CBC_MCV       CBC_MCH      CBC_MCHC  \\\n",
       "count  22364.000000  22364.000000  22364.000000  22364.000000  22364.000000   \n",
       "mean       0.665808      0.670762      0.559291      0.608514      0.609937   \n",
       "std        0.088546      0.087403      0.069969      0.068705      0.055966   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.617021      0.625217      0.553947      0.606837      0.596026   \n",
       "50%        0.664329      0.667680      0.559211      0.608670      0.610374   \n",
       "75%        0.718085      0.726759      0.580263      0.630363      0.626364   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "            CBC_RDW  CBC_Platelet     CBC_RDWCV           BUN          Crea  \\\n",
       "count  22364.000000  22364.000000  22364.000000  22364.000000  22364.000000   \n",
       "mean       0.248170      0.360266      0.058710      0.140585      0.346144   \n",
       "std        0.111240      0.050317      0.021370      0.052517      0.037145   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.176235      0.331745      0.045505      0.109893      0.317936   \n",
       "50%        0.200135      0.354299      0.054812      0.134928      0.353247   \n",
       "75%        0.270460      0.383449      0.064415      0.159963      0.365792   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                GOT           GPT           ALB            Na             K  \\\n",
       "count  22364.000000  22364.000000  22364.000000  22364.000000  22364.000000   \n",
       "mean       0.019846      0.149236      0.959610      0.503449      0.761993   \n",
       "std        0.006712      0.033600      0.010555      0.043670      0.051829   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.019291      0.131709      0.952565      0.484232      0.717462   \n",
       "50%        0.019605      0.142627      0.961229      0.505568      0.771313   \n",
       "75%        0.019982      0.157029      0.966488      0.530007      0.800821   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                 UA     Diagnosis  Congestive Heart Failure  \\\n",
       "count  22364.000000  22364.000000              22364.000000   \n",
       "mean       0.166735      0.081327                  0.022223   \n",
       "std        0.031921      0.190646                  0.147412   \n",
       "min        0.000000      0.000000                  0.000000   \n",
       "25%        0.148560      0.000000                  0.000000   \n",
       "50%        0.164035      0.000000                  0.000000   \n",
       "75%        0.182249      0.000000                  0.000000   \n",
       "max        1.000000      1.000000                  1.000000   \n",
       "\n",
       "       Cardiac Arrhythmia  Valvular Disease  Heart disease  \\\n",
       "count        22364.000000      22364.000000   22364.000000   \n",
       "mean             0.031971          0.020077       0.024757   \n",
       "std              0.175927          0.140267       0.104968   \n",
       "min              0.000000          0.000000       0.000000   \n",
       "25%              0.000000          0.000000       0.000000   \n",
       "50%              0.000000          0.000000       0.000000   \n",
       "75%              0.000000          0.000000       0.000000   \n",
       "max              1.000000          1.000000       1.000000   \n",
       "\n",
       "       Pulmonary Circulation Disorders  Peripheral Vascular Disorders  \\\n",
       "count                     22364.000000                   22364.000000   \n",
       "mean                          0.001699                       0.005589   \n",
       "std                           0.041187                       0.074554   \n",
       "min                           0.000000                       0.000000   \n",
       "25%                           0.000000                       0.000000   \n",
       "50%                           0.000000                       0.000000   \n",
       "75%                           0.000000                       0.000000   \n",
       "max                           1.000000                       1.000000   \n",
       "\n",
       "       Hypertension Uncomplicated     Paralysis  Other Neurological Disorders  \\\n",
       "count                22364.000000  22364.000000                  22364.000000   \n",
       "mean                     0.216240      0.002459                      0.012610   \n",
       "std                      0.411689      0.049532                      0.111585   \n",
       "min                      0.000000      0.000000                      0.000000   \n",
       "25%                      0.000000      0.000000                      0.000000   \n",
       "50%                      0.000000      0.000000                      0.000000   \n",
       "75%                      0.000000      0.000000                      0.000000   \n",
       "max                      1.000000      1.000000                      1.000000   \n",
       "\n",
       "       Chronic Pulmonary Disease  Lung disease      Diabetes  Hypothyroidism  \\\n",
       "count               22364.000000  22364.000000  22364.000000    22364.000000   \n",
       "mean                    0.047711      0.024705      0.096405        0.009211   \n",
       "std                     0.213158      0.111315      0.295152        0.095534   \n",
       "min                     0.000000      0.000000      0.000000        0.000000   \n",
       "25%                     0.000000      0.000000      0.000000        0.000000   \n",
       "50%                     0.000000      0.000000      0.000000        0.000000   \n",
       "75%                     0.000000      0.000000      0.000000        0.000000   \n",
       "max                     1.000000      1.000000      1.000000        1.000000   \n",
       "\n",
       "       Renal Failure  Liver Disease  Peptic Ulcer Disease excluding bleeding  \\\n",
       "count   22364.000000   22364.000000                              22364.00000   \n",
       "mean        0.022805       0.055938                                  0.04543   \n",
       "std         0.149283       0.229807                                  0.20825   \n",
       "min         0.000000       0.000000                                  0.00000   \n",
       "25%         0.000000       0.000000                                  0.00000   \n",
       "50%         0.000000       0.000000                                  0.00000   \n",
       "75%         0.000000       0.000000                                  0.00000   \n",
       "max         1.000000       1.000000                                  1.00000   \n",
       "\n",
       "           AIDS/HIV      Lymphoma  Metastatic Cancer  \\\n",
       "count  22364.000000  22364.000000       22364.000000   \n",
       "mean       0.000313      0.001565           0.003488   \n",
       "std        0.017690      0.039530           0.058955   \n",
       "min        0.000000      0.000000           0.000000   \n",
       "25%        0.000000      0.000000           0.000000   \n",
       "50%        0.000000      0.000000           0.000000   \n",
       "75%        0.000000      0.000000           0.000000   \n",
       "max        1.000000      1.000000           1.000000   \n",
       "\n",
       "       Solid Tumor without Metastasis  Cancer history  \\\n",
       "count                    22364.000000    22364.000000   \n",
       "mean                         0.037784        0.014279   \n",
       "std                          0.190678        0.073353   \n",
       "min                          0.000000        0.000000   \n",
       "25%                          0.000000        0.000000   \n",
       "50%                          0.000000        0.000000   \n",
       "75%                          0.000000        0.000000   \n",
       "max                          1.000000        1.000000   \n",
       "\n",
       "       Rheumatoid Arthritis/collagen  Coagulopathy       Obesity  \\\n",
       "count                   22364.000000  22364.000000  22364.000000   \n",
       "mean                        0.033670      0.004561      0.008809   \n",
       "std                         0.180383      0.067382      0.093443   \n",
       "min                         0.000000      0.000000      0.000000   \n",
       "25%                         0.000000      0.000000      0.000000   \n",
       "50%                         0.000000      0.000000      0.000000   \n",
       "75%                         0.000000      0.000000      0.000000   \n",
       "max                         1.000000      1.000000      1.000000   \n",
       "\n",
       "        Weight Loss  Fluid and Electrolyte Disorders  Blood Loss Anemia  \\\n",
       "count  22364.000000                     22364.000000       22364.000000   \n",
       "mean       0.001565                         0.012788           0.002236   \n",
       "std        0.039530                         0.112363           0.047232   \n",
       "min        0.000000                         0.000000           0.000000   \n",
       "25%        0.000000                         0.000000           0.000000   \n",
       "50%        0.000000                         0.000000           0.000000   \n",
       "75%        0.000000                         0.000000           0.000000   \n",
       "max        1.000000                         1.000000           1.000000   \n",
       "\n",
       "       Deficiency Anemia        Anemia  Alcohol Abuse    Drug Abuse  \\\n",
       "count       22364.000000  22364.000000   22364.000000  22364.000000   \n",
       "mean            0.006797      0.004516       0.007691      0.001073   \n",
       "std             0.082163      0.047541       0.087362      0.032742   \n",
       "min             0.000000      0.000000       0.000000      0.000000   \n",
       "25%             0.000000      0.000000       0.000000      0.000000   \n",
       "50%             0.000000      0.000000       0.000000      0.000000   \n",
       "75%             0.000000      0.000000       0.000000      0.000000   \n",
       "max             1.000000      1.000000       1.000000      1.000000   \n",
       "\n",
       "          Psychoses    Depression  Psyciatric disorder       OP_time  \n",
       "count  22364.000000  22364.000000         22364.000000  22364.000000  \n",
       "mean       0.002683      0.016813             0.009748      0.546819  \n",
       "std        0.051728      0.128572             0.072602      0.050935  \n",
       "min        0.000000      0.000000             0.000000      0.000000  \n",
       "25%        0.000000      0.000000             0.000000      0.515336  \n",
       "50%        0.000000      0.000000             0.000000      0.542556  \n",
       "75%        0.000000      0.000000             0.000000      0.570785  \n",
       "max        1.000000      1.000000             1.000000      1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax_train.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw \n",
    "from torchvision import transforms\n",
    "def raw_to_image(X):\n",
    "    bar_width = 1\n",
    "    gap_width = 2\n",
    "    num_of_feature = len(train_X.columns)\n",
    "    w = bar_width*num_of_feature + gap_width*(num_of_feature+1)\n",
    "    h = w\n",
    "\n",
    "    img_X = []\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    for ind,sample in minmax_train.iterrows():\n",
    "        h_pt = gap_width\n",
    "        img = Image.new('1', (w, h)) \n",
    "        for feature in np.array(sample):\n",
    "            draw = ImageDraw.Draw(img)\n",
    "            draw.rectangle([h_pt,0,h_pt+bar_width,h*feature],fill=1)\n",
    "            h_pt+=bar_width+gap_width\n",
    "        #img.show()\n",
    "        img_X.append(transform(img))\n",
    "    \n",
    "    return img_X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_train_X = raw_to_image(train_X)\n",
    "#img_val_X = raw_to_image(val_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_onehot(y):\n",
    "    mapped = []\n",
    "    \n",
    "    for ind,lab in y.iterrows():\n",
    "        if(lab[0]==0):\n",
    "            mapped.append([1,0])\n",
    "        elif(lab[0]==1):\n",
    "            mapped.append([0,1])\n",
    "        else:\n",
    "            print(lab)\n",
    "            print('error')\n",
    "    return mapped\n",
    "map_train_y = y_onehot(train_y)\n",
    "map_val_y = y_onehot(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self,X,y) -> None:\n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, index) :\n",
    "        return torch.tensor(self.X.iloc[index]).to(device),torch.tensor(self.y[index]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import dataloader\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "train_dataset = TrainDataset(train_X,map_train_y)\n",
    "val_dataset = TrainDataset(val_X,map_val_y)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    21646\n",
      "1      718\n",
      "Name: outcome, dtype: int64\n",
      "0    0.000046\n",
      "1    0.001393\n",
      "Name: outcome, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "def balance_prob(y):\n",
    "    print(y.value_counts())\n",
    "    prob = 1/y.value_counts()\n",
    "    print(prob)\n",
    "    dataset_element_weights = [] # each element prob\n",
    "    for label_id in y:                \n",
    "        dataset_element_weights.append(prob[label_id])\n",
    "    return dataset_element_weights\n",
    "\n",
    "balance_prob = balance_prob(train_y['outcome'])\n",
    "sampler = WeightedRandomSampler(weights=balance_prob,num_samples=len(map_train_y),replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# Create CNN Model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.line1 = nn.Linear(66,16)\n",
    "        self.line2 = nn.Linear(16,4)\n",
    "        self.line3 = nn.Linear(4,2)\n",
    "        self.sig = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.line1(x)\n",
    "        out = self.sig(out)\n",
    "        out = self.line2(out)\n",
    "        out = self.sig(out)\n",
    "        out = self.line3(out)\n",
    "        out = F.softmax(out,1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "# Hyper parm\n",
    "# batch_size, epoch and iteration\n",
    "batch_size = 80\n",
    "n_iters = 11000\n",
    "num_epochs = n_iters / (len(train_X) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, sampler=sampler)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "model = Net()\n",
    "model.to(device)\n",
    "# Cross Entropy Loss \n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 100 train loss: 0.686720609664917 val_loss: 0.6970499753952026\n",
      "val\n",
      "f1_score: 0.08248062015503875 confusion matrix:\n",
      " [[2499 2931]\n",
      " [  28  133]]\n",
      "\n",
      "iter: 200 train loss: 0.6807495355606079 val_loss: 0.6992378830909729\n",
      "val\n",
      "f1_score: 0.08274078862314156 confusion matrix:\n",
      " [[2625 2805]\n",
      " [  33  128]]\n",
      "\n",
      "iter: 300 train loss: 0.668623149394989 val_loss: 0.66982501745224\n",
      "val\n",
      "f1_score: 0.086716594402838 confusion matrix:\n",
      " [[3164 2266]\n",
      " [  51  110]]\n",
      "\n",
      "iter: 400 train loss: 0.642996072769165 val_loss: 0.6747235655784607\n",
      "val\n",
      "f1_score: 0.08505747126436783 confusion matrix:\n",
      " [[3092 2338]\n",
      " [  50  111]]\n",
      "\n",
      "iter: 500 train loss: 0.647574245929718 val_loss: 0.6667486429214478\n",
      "val\n",
      "f1_score: 0.09208400646203554 confusion matrix:\n",
      " [[3229 2201]\n",
      " [  47  114]]\n",
      "\n",
      "iter: 600 train loss: 0.6310554146766663 val_loss: 0.633682131767273\n",
      "val\n",
      "f1_score: 0.09878934624697336 confusion matrix:\n",
      " [[3628 1802]\n",
      " [  59  102]]\n",
      "\n",
      "iter: 700 train loss: 0.630173921585083 val_loss: 0.6120939254760742\n",
      "val\n",
      "f1_score: 0.1103591879229568 confusion matrix:\n",
      " [[3776 1654]\n",
      " [  55  106]]\n",
      "\n",
      "iter: 800 train loss: 0.5847681760787964 val_loss: 0.6008604764938354\n",
      "val\n",
      "f1_score: 0.11919831223628692 confusion matrix:\n",
      " [[3808 1622]\n",
      " [  48  113]]\n",
      "\n",
      "iter: 900 train loss: 0.6234404444694519 val_loss: 0.5955467820167542\n",
      "val\n",
      "f1_score: 0.12916666666666668 confusion matrix:\n",
      " [[3795 1635]\n",
      " [  37  124]]\n",
      "\n",
      "iter: 1000 train loss: 0.552264392375946 val_loss: 0.5700371861457825\n",
      "val\n",
      "f1_score: 0.1418604651162791 confusion matrix:\n",
      " [[3993 1437]\n",
      " [  39  122]]\n",
      "\n",
      "iter: 1100 train loss: 0.5991641879081726 val_loss: 0.5701577067375183\n",
      "val\n",
      "f1_score: 0.14487832484436897 confusion matrix:\n",
      " [[3952 1478]\n",
      " [  33  128]]\n",
      "\n",
      "iter: 1200 train loss: 0.5059297680854797 val_loss: 0.5353375673294067\n",
      "val\n",
      "f1_score: 0.1615233092580433 confusion matrix:\n",
      " [[4191 1239]\n",
      " [  38  123]]\n",
      "\n",
      "iter: 1300 train loss: 0.5330423712730408 val_loss: 0.5172280669212341\n",
      "val\n",
      "f1_score: 0.17304964539007092 confusion matrix:\n",
      " [[4303 1127]\n",
      " [  39  122]]\n",
      "\n",
      "iter: 1400 train loss: 0.5492473244667053 val_loss: 0.5132507681846619\n",
      "val\n",
      "f1_score: 0.17198335644937587 confusion matrix:\n",
      " [[4273 1157]\n",
      " [  37  124]]\n",
      "\n",
      "iter: 1500 train loss: 0.48440003395080566 val_loss: 0.4838111698627472\n",
      "val\n",
      "f1_score: 0.18579234972677597 confusion matrix:\n",
      " [[4429 1001]\n",
      " [  42  119]]\n",
      "\n",
      "iter: 1600 train loss: 0.5152506232261658 val_loss: 0.4927428662776947\n",
      "val\n",
      "f1_score: 0.17820324005891014 confusion matrix:\n",
      " [[4354 1076]\n",
      " [  40  121]]\n",
      "\n",
      "iter: 1700 train loss: 0.46832966804504395 val_loss: 0.4828111231327057\n",
      "val\n",
      "f1_score: 0.18101545253863136 confusion matrix:\n",
      " [[4355 1075]\n",
      " [  38  123]]\n",
      "\n",
      "iter: 1800 train loss: 0.5003006458282471 val_loss: 0.46192365884780884\n",
      "val\n",
      "f1_score: 0.19983347210657787 confusion matrix:\n",
      " [[4510  920]\n",
      " [  41  120]]\n",
      "\n",
      "iter: 1900 train loss: 0.558716893196106 val_loss: 0.4618392586708069\n",
      "val\n",
      "f1_score: 0.1979082864038616 confusion matrix:\n",
      " [[4471  959]\n",
      " [  38  123]]\n",
      "\n",
      "iter: 2000 train loss: 0.4691565930843353 val_loss: 0.4408189654350281\n",
      "val\n",
      "f1_score: 0.2148014440433213 confusion matrix:\n",
      " [[4602  828]\n",
      " [  42  119]]\n",
      "\n",
      "iter: 2100 train loss: 0.4987137019634247 val_loss: 0.43860891461372375\n",
      "val\n",
      "f1_score: 0.21345291479820627 confusion matrix:\n",
      " [[4595  835]\n",
      " [  42  119]]\n",
      "\n",
      "iter: 2200 train loss: 0.5210847854614258 val_loss: 0.4409492611885071\n",
      "val\n",
      "f1_score: 0.20969162995594717 confusion matrix:\n",
      " [[4575  855]\n",
      " [  42  119]]\n",
      "\n",
      "iter: 2300 train loss: 0.5192062258720398 val_loss: 0.43375319242477417\n",
      "val\n",
      "f1_score: 0.21350364963503649 confusion matrix:\n",
      " [[4612  818]\n",
      " [  44  117]]\n",
      "\n",
      "iter: 2400 train loss: 0.512651801109314 val_loss: 0.42840662598609924\n",
      "val\n",
      "f1_score: 0.21851851851851853 confusion matrix:\n",
      " [[4629  801]\n",
      " [  43  118]]\n",
      "\n",
      "iter: 2500 train loss: 0.4917384088039398 val_loss: 0.43510982394218445\n",
      "val\n",
      "f1_score: 0.20887728459530025 confusion matrix:\n",
      " [[4562  868]\n",
      " [  41  120]]\n",
      "\n",
      "iter: 2600 train loss: 0.5687085390090942 val_loss: 0.42575201392173767\n",
      "val\n",
      "f1_score: 0.21223021582733814 confusion matrix:\n",
      " [[4597  833]\n",
      " [  43  118]]\n",
      "\n",
      "iter: 2700 train loss: 0.43832769989967346 val_loss: 0.4326469898223877\n",
      "val\n",
      "f1_score: 0.2088006902502157 confusion matrix:\n",
      " [[4553  877]\n",
      " [  40  121]]\n",
      "\n",
      "iter: 2800 train loss: 0.45822665095329285 val_loss: 0.42142751812934875\n",
      "val\n",
      "f1_score: 0.21814848762603117 confusion matrix:\n",
      " [[4619  811]\n",
      " [  42  119]]\n",
      "\n",
      "iter: 2900 train loss: 0.43717795610427856 val_loss: 0.41469666361808777\n",
      "val\n",
      "f1_score: 0.23529411764705882 confusion matrix:\n",
      " [[4706  724]\n",
      " [  43  118]]\n",
      "\n",
      "iter: 3000 train loss: 0.4626637399196625 val_loss: 0.41710662841796875\n",
      "val\n",
      "f1_score: 0.22369668246445495 confusion matrix:\n",
      " [[4654  776]\n",
      " [  43  118]]\n",
      "\n",
      "iter: 3100 train loss: 0.4777238965034485 val_loss: 0.41908079385757446\n",
      "val\n",
      "f1_score: 0.22180801491146318 confusion matrix:\n",
      " [[4637  793]\n",
      " [  42  119]]\n",
      "\n",
      "iter: 3200 train loss: 0.4907035827636719 val_loss: 0.41418007016181946\n",
      "val\n",
      "f1_score: 0.22284644194756553 confusion matrix:\n",
      " [[4642  788]\n",
      " [  42  119]]\n",
      "\n",
      "iter: 3300 train loss: 0.48226723074913025 val_loss: 0.41114547848701477\n",
      "val\n",
      "f1_score: 0.22966507177033493 confusion matrix:\n",
      " [[4666  764]\n",
      " [  41  120]]\n",
      "\n",
      "iter: 3400 train loss: 0.5062971115112305 val_loss: 0.41245847940444946\n",
      "val\n",
      "f1_score: 0.224105461393597 confusion matrix:\n",
      " [[4648  782]\n",
      " [  42  119]]\n",
      "\n",
      "iter: 3500 train loss: 0.496755987405777 val_loss: 0.41092193126678467\n",
      "val\n",
      "f1_score: 0.23062015503875968 confusion matrix:\n",
      " [[4678  752]\n",
      " [  42  119]]\n",
      "\n",
      "iter: 3600 train loss: 0.5087745189666748 val_loss: 0.40564486384391785\n",
      "val\n",
      "f1_score: 0.23943661971830987 confusion matrix:\n",
      " [[4716  714]\n",
      " [  42  119]]\n",
      "\n",
      "iter: 3700 train loss: 0.4517555236816406 val_loss: 0.4127006232738495\n",
      "val\n",
      "f1_score: 0.22659176029962547 confusion matrix:\n",
      " [[4644  786]\n",
      " [  40  121]]\n",
      "\n",
      "iter: 3800 train loss: 0.497861385345459 val_loss: 0.4002927243709564\n",
      "val\n",
      "f1_score: 0.2502651113467656 confusion matrix:\n",
      " [[4766  664]\n",
      " [  43  118]]\n",
      "\n",
      "iter: 3900 train loss: 0.4776597023010254 val_loss: 0.4037521183490753\n",
      "val\n",
      "f1_score: 0.24514811031664965 confusion matrix:\n",
      " [[4732  698]\n",
      " [  41  120]]\n",
      "\n",
      "iter: 4000 train loss: 0.45796871185302734 val_loss: 0.39637577533721924\n",
      "val\n",
      "f1_score: 0.25438596491228066 confusion matrix:\n",
      " [[4795  635]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 4100 train loss: 0.4055037498474121 val_loss: 0.3978329002857208\n",
      "val\n",
      "f1_score: 0.2523860021208908 confusion matrix:\n",
      " [[4767  663]\n",
      " [  42  119]]\n",
      "\n",
      "iter: 4200 train loss: 0.4514148235321045 val_loss: 0.39523348212242126\n",
      "val\n",
      "f1_score: 0.25792349726775954 confusion matrix:\n",
      " [[4794  636]\n",
      " [  43  118]]\n",
      "\n",
      "iter: 4300 train loss: 0.4843009114265442 val_loss: 0.3953334093093872\n",
      "val\n",
      "f1_score: 0.25215517241379315 confusion matrix:\n",
      " [[4780  650]\n",
      " [  44  117]]\n",
      "\n",
      "iter: 4400 train loss: 0.5284816026687622 val_loss: 0.39445990324020386\n",
      "val\n",
      "f1_score: 0.2502651113467656 confusion matrix:\n",
      " [[4766  664]\n",
      " [  43  118]]\n",
      "\n",
      "iter: 4500 train loss: 0.4360903203487396 val_loss: 0.38306179642677307\n",
      "val\n",
      "f1_score: 0.2723004694835681 confusion matrix:\n",
      " [[4855  575]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 4600 train loss: 0.4473278522491455 val_loss: 0.38252365589141846\n",
      "val\n",
      "f1_score: 0.2740046838407494 confusion matrix:\n",
      " [[4854  576]\n",
      " [  44  117]]\n",
      "\n",
      "iter: 4700 train loss: 0.408480703830719 val_loss: 0.37734612822532654\n",
      "val\n",
      "f1_score: 0.28121212121212125 confusion matrix:\n",
      " [[4882  548]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 4800 train loss: 0.4353860318660736 val_loss: 0.38074952363967896\n",
      "val\n",
      "f1_score: 0.2728323699421965 confusion matrix:\n",
      " [[4844  586]\n",
      " [  43  118]]\n",
      "\n",
      "iter: 4900 train loss: 0.408962219953537 val_loss: 0.3840413987636566\n",
      "val\n",
      "f1_score: 0.26516853932584267 confusion matrix:\n",
      " [[4819  611]\n",
      " [  43  118]]\n",
      "\n",
      "iter: 5000 train loss: 0.46085357666015625 val_loss: 0.37497478723526\n",
      "val\n",
      "f1_score: 0.2874845105328377 confusion matrix:\n",
      " [[4900  530]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 5100 train loss: 0.4024500846862793 val_loss: 0.3775028884410858\n",
      "val\n",
      "f1_score: 0.28125000000000006 confusion matrix:\n",
      " [[4876  554]\n",
      " [  44  117]]\n",
      "\n",
      "iter: 5200 train loss: 0.4720158576965332 val_loss: 0.3782977759838104\n",
      "val\n",
      "f1_score: 0.28192771084337354 confusion matrix:\n",
      " [[4878  552]\n",
      " [  44  117]]\n",
      "\n",
      "iter: 5300 train loss: 0.407819002866745 val_loss: 0.3752135634422302\n",
      "val\n",
      "f1_score: 0.2888616891064871 confusion matrix:\n",
      " [[4892  538]\n",
      " [  43  118]]\n",
      "\n",
      "iter: 5400 train loss: 0.4583740234375 val_loss: 0.3686705231666565\n",
      "val\n",
      "f1_score: 0.2896039603960396 confusion matrix:\n",
      " [[4900  530]\n",
      " [  44  117]]\n",
      "\n",
      "iter: 5500 train loss: 0.4097428023815155 val_loss: 0.3689121603965759\n",
      "val\n",
      "f1_score: 0.28361858190709044 confusion matrix:\n",
      " [[4889  541]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 5600 train loss: 0.4075154960155487 val_loss: 0.3610415458679199\n",
      "val\n",
      "f1_score: 0.3018372703412074 confusion matrix:\n",
      " [[4944  486]\n",
      " [  46  115]]\n",
      "\n",
      "iter: 5700 train loss: 0.4644000232219696 val_loss: 0.3665026128292084\n",
      "val\n",
      "f1_score: 0.29280397022332505 confusion matrix:\n",
      " [[4903  527]\n",
      " [  43  118]]\n",
      "\n",
      "iter: 5800 train loss: 0.41770726442337036 val_loss: 0.3685886263847351\n",
      "val\n",
      "f1_score: 0.28433734939759037 confusion matrix:\n",
      " [[4879  551]\n",
      " [  43  118]]\n",
      "\n",
      "iter: 5900 train loss: 0.42581796646118164 val_loss: 0.3619147837162018\n",
      "val\n",
      "f1_score: 0.3020833333333333 confusion matrix:\n",
      " [[4939  491]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 6000 train loss: 0.47720766067504883 val_loss: 0.35936006903648376\n",
      "val\n",
      "f1_score: 0.3040629095674967 confusion matrix:\n",
      " [[4944  486]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 6100 train loss: 0.4377942979335785 val_loss: 0.3587752878665924\n",
      "val\n",
      "f1_score: 0.3054830287206266 confusion matrix:\n",
      " [[4942  488]\n",
      " [  44  117]]\n",
      "\n",
      "iter: 6200 train loss: 0.424983412027359 val_loss: 0.3612118363380432\n",
      "val\n",
      "f1_score: 0.29820051413881743 confusion matrix:\n",
      " [[4929  501]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 6300 train loss: 0.5062384605407715 val_loss: 0.36090031266212463\n",
      "val\n",
      "f1_score: 0.29935483870967744 confusion matrix:\n",
      " [[4932  498]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 6400 train loss: 0.44084882736206055 val_loss: 0.36304494738578796\n",
      "val\n",
      "f1_score: 0.2986198243412798 confusion matrix:\n",
      " [[4913  517]\n",
      " [  42  119]]\n",
      "\n",
      "iter: 6500 train loss: 0.41823115944862366 val_loss: 0.3588297665119171\n",
      "val\n",
      "f1_score: 0.3007712082262211 confusion matrix:\n",
      " [[4930  500]\n",
      " [  44  117]]\n",
      "\n",
      "iter: 6600 train loss: 0.39667245745658875 val_loss: 0.35715606808662415\n",
      "val\n",
      "f1_score: 0.30486202365308807 confusion matrix:\n",
      " [[4946  484]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 6700 train loss: 0.4220099151134491 val_loss: 0.3599918484687805\n",
      "val\n",
      "f1_score: 0.2972292191435768 confusion matrix:\n",
      " [[4915  515]\n",
      " [  43  118]]\n",
      "\n",
      "iter: 6800 train loss: 0.43649062514305115 val_loss: 0.3561132252216339\n",
      "val\n",
      "f1_score: 0.3097463284379172 confusion matrix:\n",
      " [[4958  472]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 6900 train loss: 0.4231521785259247 val_loss: 0.3541664779186249\n",
      "val\n",
      "f1_score: 0.31283422459893045 confusion matrix:\n",
      " [[4960  470]\n",
      " [  44  117]]\n",
      "\n",
      "iter: 7000 train loss: 0.4364943206310272 val_loss: 0.35196787118911743\n",
      "val\n",
      "f1_score: 0.31868131868131866 confusion matrix:\n",
      " [[4979  451]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 7100 train loss: 0.4012378752231598 val_loss: 0.3639378547668457\n",
      "val\n",
      "f1_score: 0.2860548271752086 confusion matrix:\n",
      " [[4872  558]\n",
      " [  41  120]]\n",
      "\n",
      "iter: 7200 train loss: 0.4299585521221161 val_loss: 0.35887402296066284\n",
      "val\n",
      "f1_score: 0.30318471337579617 confusion matrix:\n",
      " [[4925  505]\n",
      " [  42  119]]\n",
      "\n",
      "iter: 7300 train loss: 0.44546571373939514 val_loss: 0.35967811942100525\n",
      "val\n",
      "f1_score: 0.3076923076923077 confusion matrix:\n",
      " [[4931  499]\n",
      " [  41  120]]\n",
      "\n",
      "iter: 7400 train loss: 0.37959107756614685 val_loss: 0.3590119481086731\n",
      "val\n",
      "f1_score: 0.31620553359683795 confusion matrix:\n",
      " [[4952  478]\n",
      " [  41  120]]\n",
      "\n",
      "iter: 7500 train loss: 0.44621753692626953 val_loss: 0.3568924069404602\n",
      "val\n",
      "f1_score: 0.32432432432432434 confusion matrix:\n",
      " [[4971  459]\n",
      " [  41  120]]\n",
      "\n",
      "iter: 7600 train loss: 0.43063709139823914 val_loss: 0.3564024269580841\n",
      "val\n",
      "f1_score: 0.3183023872679045 confusion matrix:\n",
      " [[4957  473]\n",
      " [  41  120]]\n",
      "\n",
      "iter: 7700 train loss: 0.42315173149108887 val_loss: 0.353436678647995\n",
      "val\n",
      "f1_score: 0.32727272727272727 confusion matrix:\n",
      " [[4993  437]\n",
      " [  44  117]]\n",
      "\n",
      "iter: 7800 train loss: 0.40063974261283875 val_loss: 0.3553200364112854\n",
      "val\n",
      "f1_score: 0.3269230769230769 confusion matrix:\n",
      " [[4982  448]\n",
      " [  42  119]]\n",
      "\n",
      "iter: 7900 train loss: 0.43123266100883484 val_loss: 0.35857489705085754\n",
      "val\n",
      "f1_score: 0.31578947368421056 confusion matrix:\n",
      " [[4951  479]\n",
      " [  41  120]]\n",
      "\n",
      "iter: 8000 train loss: 0.37524354457855225 val_loss: 0.3572203814983368\n",
      "val\n",
      "f1_score: 0.3119266055045871 confusion matrix:\n",
      " [[4947  483]\n",
      " [  42  119]]\n",
      "\n",
      "iter: 8100 train loss: 0.4548075795173645 val_loss: 0.35380929708480835\n",
      "val\n",
      "f1_score: 0.32911392405063294 confusion matrix:\n",
      " [[4997  433]\n",
      " [  44  117]]\n",
      "\n",
      "iter: 8200 train loss: 0.43735837936401367 val_loss: 0.35632526874542236\n",
      "val\n",
      "f1_score: 0.3147632311977716 confusion matrix:\n",
      " [[4986  444]\n",
      " [  48  113]]\n",
      "\n",
      "iter: 8300 train loss: 0.41024598479270935 val_loss: 0.3516923487186432\n",
      "val\n",
      "f1_score: 0.33628318584070793 confusion matrix:\n",
      " [[5027  403]\n",
      " [  47  114]]\n",
      "\n",
      "iter: 8400 train loss: 0.47249677777290344 val_loss: 0.35706034302711487\n",
      "val\n",
      "f1_score: 0.320109439124487 confusion matrix:\n",
      " [[4977  453]\n",
      " [  44  117]]\n",
      "\n",
      "iter: 8500 train loss: 0.42249593138694763 val_loss: 0.3565208911895752\n",
      "val\n",
      "f1_score: 0.3259668508287293 confusion matrix:\n",
      " [[4985  445]\n",
      " [  43  118]]\n",
      "\n",
      "iter: 8600 train loss: 0.43293648958206177 val_loss: 0.35484930872917175\n",
      "val\n",
      "f1_score: 0.33048433048433046 confusion matrix:\n",
      " [[5005  425]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 8700 train loss: 0.40867185592651367 val_loss: 0.35334911942481995\n",
      "val\n",
      "f1_score: 0.32900432900432897 confusion matrix:\n",
      " [[5012  418]\n",
      " [  47  114]]\n",
      "\n",
      "iter: 8800 train loss: 0.478767067193985 val_loss: 0.35590749979019165\n",
      "val\n",
      "f1_score: 0.33001422475106684 confusion matrix:\n",
      " [[5004  426]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 8900 train loss: 0.4421311318874359 val_loss: 0.35323065519332886\n",
      "val\n",
      "f1_score: 0.3367198838896952 confusion matrix:\n",
      " [[5018  412]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 9000 train loss: 0.4464874267578125 val_loss: 0.36194437742233276\n",
      "val\n",
      "f1_score: 0.30708661417322836 confusion matrix:\n",
      " [[4946  484]\n",
      " [  44  117]]\n",
      "\n",
      "iter: 9100 train loss: 0.3918026089668274 val_loss: 0.3598302900791168\n",
      "val\n",
      "f1_score: 0.3091149273447821 confusion matrix:\n",
      " [[4951  479]\n",
      " [  44  117]]\n",
      "\n",
      "iter: 9200 train loss: 0.37922629714012146 val_loss: 0.3547680079936981\n",
      "val\n",
      "f1_score: 0.33048433048433046 confusion matrix:\n",
      " [[5005  425]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 9300 train loss: 0.40874043107032776 val_loss: 0.3553338646888733\n",
      "val\n",
      "f1_score: 0.3263598326359832 confusion matrix:\n",
      " [[4991  439]\n",
      " [  44  117]]\n",
      "\n",
      "iter: 9400 train loss: 0.4361668527126312 val_loss: 0.3587583303451538\n",
      "val\n",
      "f1_score: 0.3213296398891967 confusion matrix:\n",
      " [[4985  445]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 9500 train loss: 0.4721772372722626 val_loss: 0.3582797646522522\n",
      "val\n",
      "f1_score: 0.31436314363143636 confusion matrix:\n",
      " [[4969  461]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 9600 train loss: 0.4430111050605774 val_loss: 0.35451486706733704\n",
      "val\n",
      "f1_score: 0.32947976878612717 confusion matrix:\n",
      " [[5013  417]\n",
      " [  47  114]]\n",
      "\n",
      "iter: 9700 train loss: 0.37570738792419434 val_loss: 0.3529732823371887\n",
      "val\n",
      "f1_score: 0.3300423131170663 confusion matrix:\n",
      " [[4999  431]\n",
      " [  44  117]]\n",
      "\n",
      "iter: 9800 train loss: 0.3950841426849365 val_loss: 0.35973337292671204\n",
      "val\n",
      "f1_score: 0.3068783068783069 confusion matrix:\n",
      " [[4951  479]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 9900 train loss: 0.47089725732803345 val_loss: 0.3554669916629791\n",
      "val\n",
      "f1_score: 0.3198887343532685 confusion matrix:\n",
      " [[4987  443]\n",
      " [  46  115]]\n",
      "\n",
      "iter: 10000 train loss: 0.40996724367141724 val_loss: 0.35991573333740234\n",
      "val\n",
      "f1_score: 0.31241655540720964 confusion matrix:\n",
      " [[4959  471]\n",
      " [  44  117]]\n",
      "\n",
      "iter: 10100 train loss: 0.4596453607082367 val_loss: 0.3540721535682678\n",
      "val\n",
      "f1_score: 0.33770014556040756 confusion matrix:\n",
      " [[5020  410]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 10200 train loss: 0.426196426153183 val_loss: 0.3588235080242157\n",
      "val\n",
      "f1_score: 0.32275862068965516 confusion matrix:\n",
      " [[4983  447]\n",
      " [  44  117]]\n",
      "\n",
      "iter: 10300 train loss: 0.3868827819824219 val_loss: 0.35666728019714355\n",
      "val\n",
      "f1_score: 0.3222222222222222 confusion matrix:\n",
      " [[4987  443]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 10400 train loss: 0.5300291180610657 val_loss: 0.3521023690700531\n",
      "val\n",
      "f1_score: 0.3421828908554572 confusion matrix:\n",
      " [[5029  401]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 10500 train loss: 0.4319007992744446 val_loss: 0.3486856520175934\n",
      "val\n",
      "f1_score: 0.34441087613293053 confusion matrix:\n",
      " [[5043  387]\n",
      " [  47  114]]\n",
      "\n",
      "iter: 10600 train loss: 0.3937314450740814 val_loss: 0.35340261459350586\n",
      "val\n",
      "f1_score: 0.32907801418439714 confusion matrix:\n",
      " [[5002  428]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 10700 train loss: 0.4410587251186371 val_loss: 0.351967990398407\n",
      "val\n",
      "f1_score: 0.3421828908554572 confusion matrix:\n",
      " [[5029  401]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 10800 train loss: 0.3989948630332947 val_loss: 0.35434234142303467\n",
      "val\n",
      "f1_score: 0.327683615819209 confusion matrix:\n",
      " [[4999  431]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 10900 train loss: 0.4289778172969818 val_loss: 0.3513393998146057\n",
      "val\n",
      "f1_score: 0.3347763347763348 confusion matrix:\n",
      " [[5014  416]\n",
      " [  45  116]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "# ANN model training\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "model.train()\n",
    "performace = {}\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        \n",
    "\n",
    "        optimizer.zero_grad() # Clear gradients\n",
    "        outputs = model(Variable(X.float().to(device))) # Forward propagation\n",
    "        #print(outputs)\n",
    "       # print(y.float())\n",
    "        #print(outputs)\n",
    "        loss = error(outputs,y.float()) # Calculate softmax and cross entropy loss\n",
    "        loss.backward() # Calculating gradients\n",
    "        optimizer.step() # Update parameters\n",
    "       \n",
    "        count += 1\n",
    "        \n",
    "        if count%100 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            predict = []\n",
    "            true = []\n",
    "            model.eval()\n",
    "            # Predict val dataset\n",
    "            for X, y in val_loader:\n",
    "                #print(X.float())\n",
    "                outputs = model(X.float()) # Forward propagation\n",
    "                val_loss = error(outputs,y.float())\n",
    "                outputs = outputs.cpu().detach().numpy()\n",
    "                y = y.cpu().detach().numpy()\n",
    "                \n",
    "                for pred in outputs:\n",
    "                    predict.append(np.argmax(pred))\n",
    "                for label in y:\n",
    "                    true.append(np.argmax(label))\n",
    "                \n",
    "            #print(true)\n",
    "           # print(predict)\n",
    "            performace[count] = (tools.get_performance(true,predict))\n",
    "            \n",
    "            \n",
    "            print(\"iter:\",count,\"train loss:\",loss.data.item(),\"val_loss:\",val_loss.data.item())\n",
    "            print(\"val\")\n",
    "            print(\"f1_score:\",performace[count]['f1_score'],'confusion matrix:\\n',performace[count]['confusion matrix'])\n",
    "            print()\n",
    "            performace[count]['train_loss'] = loss.data.item()\n",
    "            performace[count]['val_loss'] = val_loss.data.item()\n",
    "                \n",
    "                \n",
    "            model.train()\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(pd.DataFrame(performace).T)    \n",
    "pd.DataFrame(performace).T.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_performance = {}\n",
    "predict = []\n",
    "true = []\n",
    "model.eval()\n",
    "for X, y in val_loader:\n",
    "    #print(X.float())\n",
    "    outputs = model(X.float()) # Forward propagation\n",
    "    val_loss = error(outputs,y.float())\n",
    "    outputs = outputs.cpu().detach().numpy()\n",
    "    y = y.cpu().detach().numpy()\n",
    "    \n",
    "    for pred in outputs:\n",
    "        predict.append(np.argmax(pred))\n",
    "    for label in y:\n",
    "        true.append(np.argmax(label))\n",
    "final_performance['val'] = tools.get_performance(true,predict)\n",
    "predict = []\n",
    "true = []\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size)\n",
    "\n",
    "for X, y in train_loader:\n",
    "    #print(X.float())\n",
    "    outputs = model(X.float()) # Forward propagation\n",
    "    val_loss = error(outputs,y.float())\n",
    "    outputs = outputs.cpu().detach().numpy()\n",
    "    y = y.cpu().detach().numpy()\n",
    "    \n",
    "    for pred in outputs:\n",
    "        predict.append(np.argmax(pred))\n",
    "    for label in y:\n",
    "        true.append(np.argmax(label))\n",
    "final_performance['train'] = tools.get_performance(true,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>confusion matrix</th>\n",
       "      <td>[[5000, 430], [44, 117]]</td>\n",
       "      <td>[[20249, 1397], [102, 616]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.915221</td>\n",
       "      <td>0.932973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.213894</td>\n",
       "      <td>0.306011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.330508</td>\n",
       "      <td>0.451117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.726708</td>\n",
       "      <td>0.857939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matthews_corrcoef</th>\n",
       "      <td>0.364488</td>\n",
       "      <td>0.488685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        val                        train\n",
       "confusion matrix   [[5000, 430], [44, 117]]  [[20249, 1397], [102, 616]]\n",
       "acc                                0.915221                     0.932973\n",
       "precision                          0.213894                     0.306011\n",
       "f1_score                           0.330508                     0.451117\n",
       "recall                             0.726708                     0.857939\n",
       "matthews_corrcoef                  0.364488                     0.488685"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(final_performance)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "758b741b386b57519efd53b073ac35bdb1f696dd4ad70fef9c572829f656d496"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
