{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_excel(\"Data/tr.xlsx\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_missing_sample = []\n",
    "row_value_count = train_data.apply(pd.Series.value_counts,axis=1,dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools\n",
    "#Data transform\n",
    "train_y = pd.DataFrame(train_data['outcome']) \n",
    "train_X = pd.DataFrame(train_data.drop(['outcome'],axis=1))\n",
    "\n",
    "train_X = tools.data_transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[879, 51280]\n",
      "[879, 27076]\n"
     ]
    }
   ],
   "source": [
    "threshhold =len(train_X.columns)*0.25\n",
    "over_missing = row_value_count[np.nan]<=threshhold\n",
    "class_0 = train_y['outcome']==1\n",
    "\n",
    "print(sorted(train_y.value_counts()))\n",
    "train_X = train_X[over_missing|class_0]\n",
    "train_y = train_y[over_missing|class_0]\n",
    "print(sorted(train_y.value_counts()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[718, 21646]\n",
      "[161, 5430]\n"
     ]
    }
   ],
   "source": [
    "# Data split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(\n",
    "    train_X ,\n",
    "    train_y,\n",
    "    test_size=0.2,\n",
    "    random_state=42)\n",
    "\n",
    "print(sorted(train_y.value_counts()))\n",
    "print(sorted(val_y.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[718, 21646]\n",
      "[718, 7180]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler as RUS\n",
    "\n",
    "print(sorted(train_y.value_counts()))\n",
    "\n",
    "rus = RUS(sampling_strategy=0.1,random_state=42)\n",
    "train_X,train_y = rus.fit_resample(train_X,train_y)\n",
    "\n",
    "print(sorted(train_y.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7898, 66)\n",
      "(7898, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold as VT\n",
    "\n",
    "vt= VT(0.2)\n",
    "\n",
    "vt.fit(train_X)\n",
    "print(train_X.shape)\n",
    "\n",
    "train_X = pd.DataFrame(vt.transform(train_X)) \n",
    "val_X =  pd.DataFrame(vt.transform(val_X))\n",
    "\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled continuous missing value with median\n",
      "filled nominal missing value with  constant\n"
     ]
    }
   ],
   "source": [
    "# Missing value imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import tools\n",
    "feature_kind = tools.init_feature_kind(train_X)\n",
    "cont,cate = tools.get_feature_kind(train_X,feature_kind)  \n",
    "\n",
    "strategy = 'median'\n",
    "\n",
    "imp_mean = IterativeImputer(max_iter=100,random_state=0)\n",
    "imp_mean.fit(train_X[cont])\n",
    "\n",
    "train_X[cont] = imp_mean.transform(train_X[cont])\n",
    "val_X[cont] = imp_mean.transform(val_X[cont])\n",
    "\n",
    "print(\"filled continuous missing value with \"+strategy)\n",
    "\n",
    "strategy = 'constant'\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy=strategy,fill_value=10.0)\n",
    "imp.fit(train_X[cate])\n",
    "\n",
    "train_X[cate] = imp.transform(train_X[cate])\n",
    "val_X[cate] = imp.transform(val_X[cate])\n",
    "\n",
    "\n",
    "print(\"filled nominal missing value with \",strategy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "cont,cate = tools.get_feature_kind(train_X,feature_kind)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(train_X[cont])\n",
    "train_X[cont] = scaler.transform(train_X[cont])\n",
    "val_X[cont] = scaler.transform(val_X[cont])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import matplotlib.pyplot as plt\\nimport numpy as np\\nfrom sklearn.linear_model import RidgeCV\\n\\nridge = RidgeCV(alphas=np.logspace(-6, 6, num=5)).fit(train_X, train_y)\\nimportance = np.abs(ridge.coef_)\\nfeature_names = np.array(train_X.columns)\\nplt.bar(height=importance[0], x=feature_names)\\nplt.title(\"Feature importances via coefficients\")\\nplt.show()\\n\\n\\ntrain_X=train_X[feature_names[importance[0]>0.004]]\\nval_X = val_X[feature_names[importance[0]>0.004]]\\nprint(train_X.shape)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "ridge = RidgeCV(alphas=np.logspace(-6, 6, num=5)).fit(train_X, train_y)\n",
    "importance = np.abs(ridge.coef_)\n",
    "feature_names = np.array(train_X.columns)\n",
    "plt.bar(height=importance[0], x=feature_names)\n",
    "plt.title(\"Feature importances via coefficients\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "train_X=train_X[feature_names[importance[0]>0.004]]\n",
    "val_X = val_X[feature_names[importance[0]>0.004]]\n",
    "print(train_X.shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_pandas_display_options() -> None:\n",
    "    display = pd.options.display\n",
    "    display.max_columns = 100\n",
    "    display.max_rows = 100\n",
    "    display.max_colwidth = 199\n",
    "    display.width = None\n",
    "set_pandas_display_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(class_weight={1:1,0:0.1},max_iter=10000) \n",
    "\n",
    "parameters = {\n",
    "    'penalty':('l1', 'l2','elasticnet', 'none'),\n",
    "    'C':[1, 10,0.1,100],\n",
    "    'solver':('newton-cg','lbfgs', 'liblinear', 'sag', 'saga'),\n",
    "    \n",
    "    }\n",
    "\n",
    "GS = GridSearchCV(clf, parameters,n_jobs=5,scoring='f1')\n",
    "#GS.fit(train_X, train_y['outcome'])\n",
    "\n",
    "\n",
    "#sorted(GS.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(GS.best_params_)\n",
    "#print(pd.DataFrame(GS.cv_results_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        train                        val\n",
      "confusion matrix   [[4894, 2286], [266, 452]]  [[3669, 1761], [61, 100]]\n",
      "acc                                   0.67688                   0.674119\n",
      "precision                            0.165084                   0.053735\n",
      "f1_score                             0.261574                   0.098912\n",
      "recall                               0.629526                   0.621118\n",
      "matthews_corrcoef                     0.18795                   0.105332\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "best_parameters = {\n",
    "    'C': 1, 'penalty': 'l1', 'solver': 'saga'\n",
    "}\n",
    "\n",
    "clf = LogisticRegression(**best_parameters,class_weight={1:1,0:0.1},max_iter=10000) \n",
    "\n",
    "clf.fit(train_X, train_y['outcome'])\n",
    "result = clf.predict(val_X)\n",
    "\n",
    "\n",
    "print(pd.DataFrame({\n",
    "    'train':tools.get_performance(train_y,clf.predict(train_X)),\n",
    "    'val':tools.get_performance(val_y,result)\n",
    "    }\n",
    "    ))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "758b741b386b57519efd53b073ac35bdb1f696dd4ad70fef9c572829f656d496"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
