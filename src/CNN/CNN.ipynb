{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_excel(\"Data/tr.xlsx\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_missing_sample = []\n",
    "row_value_count = train_data.apply(pd.Series.value_counts,axis=1,dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools\n",
    "#Data transform\n",
    "train_y = pd.DataFrame(train_data['outcome']) \n",
    "train_X = pd.DataFrame(train_data.drop(['outcome'],axis=1))\n",
    "\n",
    "train_X = tools.data_transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools\n",
    "tools.set_pandas_display_options()\n",
    "#train_X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[879, 51280]\n",
      "[879, 27076]\n"
     ]
    }
   ],
   "source": [
    "threshhold =len(train_X.columns)*0.25\n",
    "over_missing = row_value_count[np.nan]<=threshhold\n",
    "class_0 = train_y['outcome']==1\n",
    "\n",
    "print(sorted(train_y.value_counts()))\n",
    "train_X = train_X[over_missing|class_0]\n",
    "train_y = train_y[over_missing|class_0]\n",
    "print(sorted(train_y.value_counts()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[718, 21646]\n",
      "[161, 5430]\n"
     ]
    }
   ],
   "source": [
    "# Data split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(\n",
    "    train_X ,\n",
    "    train_y,\n",
    "    test_size=0.2,\n",
    "    random_state=42)\n",
    "\n",
    "print(sorted(train_y.value_counts()))\n",
    "print(sorted(val_y.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled continuous missing value with median\n",
      "filled nominal missing value with  constant\n"
     ]
    }
   ],
   "source": [
    "# Missing value imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import tools\n",
    "feature_kind = tools.init_feature_kind(train_X)\n",
    "cont,cate = tools.get_feature_kind(train_X,feature_kind)  \n",
    "\n",
    "strategy = 'median'\n",
    "\n",
    "imp_mean = IterativeImputer(max_iter=100,random_state=0)\n",
    "imp_mean.fit(train_X[cont])\n",
    "\n",
    "train_X[cont] = imp_mean.transform(train_X[cont])\n",
    "val_X[cont] = imp_mean.transform(val_X[cont])\n",
    "\n",
    "print(\"filled continuous missing value with \"+strategy)\n",
    "\n",
    "strategy = 'constant'\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy=strategy,fill_value=10.0)\n",
    "imp.fit(train_X[cate])\n",
    "\n",
    "train_X[cate] = imp.transform(train_X[cate])\n",
    "val_X[cate] = imp.transform(val_X[cate])\n",
    "\n",
    "\n",
    "print(\"filled nominal missing value with \",strategy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "cont,cate = tools.get_feature_kind(train_X,feature_kind)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(train_X[cont])\n",
    "train_X[cont] = scaler.transform(train_X[cont])\n",
    "val_X[cont] = scaler.transform(val_X[cont])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "end =OneHotEncoder()\n",
    "onehot_train_X = pd.DataFrame(end.fit_transform(train_X[cate]).toarray())\n",
    "onehot_val_X = pd.DataFrame(end.transform(val_X[cate]).toarray())\n",
    "\n",
    "train_X = train_X.reset_index(drop=True)\n",
    "val_X = val_X.reset_index(drop=True)\n",
    "\n",
    "train_X = pd.concat([train_X[cont],onehot_train_X],axis=1,ignore_index=True)\n",
    "val_X = pd.concat([val_X[cont],onehot_val_X],axis=1,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>...</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.816766</td>\n",
       "      <td>-0.149116</td>\n",
       "      <td>0.326534</td>\n",
       "      <td>0.174376</td>\n",
       "      <td>0.987036</td>\n",
       "      <td>0.033720</td>\n",
       "      <td>-0.048645</td>\n",
       "      <td>-0.111790</td>\n",
       "      <td>-0.031080</td>\n",
       "      <td>0.009028</td>\n",
       "      <td>0.061228</td>\n",
       "      <td>-0.254103</td>\n",
       "      <td>-0.678105</td>\n",
       "      <td>-0.146323</td>\n",
       "      <td>0.474443</td>\n",
       "      <td>-0.959558</td>\n",
       "      <td>0.085735</td>\n",
       "      <td>1.952211</td>\n",
       "      <td>-0.777544</td>\n",
       "      <td>0.061762</td>\n",
       "      <td>-1.286230</td>\n",
       "      <td>0.510489</td>\n",
       "      <td>0.053968</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.461019</td>\n",
       "      <td>0.549548</td>\n",
       "      <td>-0.473576</td>\n",
       "      <td>-0.582417</td>\n",
       "      <td>0.265156</td>\n",
       "      <td>0.876995</td>\n",
       "      <td>0.350120</td>\n",
       "      <td>0.492818</td>\n",
       "      <td>-0.979046</td>\n",
       "      <td>-0.978990</td>\n",
       "      <td>-0.366887</td>\n",
       "      <td>-0.687642</td>\n",
       "      <td>1.060124</td>\n",
       "      <td>-1.001496</td>\n",
       "      <td>-0.642221</td>\n",
       "      <td>0.328820</td>\n",
       "      <td>0.038968</td>\n",
       "      <td>0.841940</td>\n",
       "      <td>0.821795</td>\n",
       "      <td>-0.403654</td>\n",
       "      <td>0.236108</td>\n",
       "      <td>-0.084837</td>\n",
       "      <td>2.459291</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.185804</td>\n",
       "      <td>1.597544</td>\n",
       "      <td>0.326534</td>\n",
       "      <td>0.174376</td>\n",
       "      <td>0.366394</td>\n",
       "      <td>0.005818</td>\n",
       "      <td>-0.039303</td>\n",
       "      <td>-0.081876</td>\n",
       "      <td>-0.023800</td>\n",
       "      <td>0.005536</td>\n",
       "      <td>0.042112</td>\n",
       "      <td>0.108333</td>\n",
       "      <td>0.053045</td>\n",
       "      <td>0.050813</td>\n",
       "      <td>-0.825683</td>\n",
       "      <td>-0.948270</td>\n",
       "      <td>-0.065076</td>\n",
       "      <td>0.434458</td>\n",
       "      <td>-0.777544</td>\n",
       "      <td>-0.766138</td>\n",
       "      <td>-1.428566</td>\n",
       "      <td>-1.220110</td>\n",
       "      <td>0.550192</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.091981</td>\n",
       "      <td>0.549548</td>\n",
       "      <td>-0.473576</td>\n",
       "      <td>-0.582417</td>\n",
       "      <td>1.915743</td>\n",
       "      <td>1.552617</td>\n",
       "      <td>1.671741</td>\n",
       "      <td>1.612364</td>\n",
       "      <td>-0.170401</td>\n",
       "      <td>0.125865</td>\n",
       "      <td>0.816450</td>\n",
       "      <td>-0.626208</td>\n",
       "      <td>0.977116</td>\n",
       "      <td>-0.592952</td>\n",
       "      <td>1.726898</td>\n",
       "      <td>1.554656</td>\n",
       "      <td>-0.063921</td>\n",
       "      <td>-0.215461</td>\n",
       "      <td>1.048651</td>\n",
       "      <td>0.561046</td>\n",
       "      <td>1.270329</td>\n",
       "      <td>2.476449</td>\n",
       "      <td>0.665577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.333576</td>\n",
       "      <td>0.200216</td>\n",
       "      <td>1.126643</td>\n",
       "      <td>1.687963</td>\n",
       "      <td>1.187543</td>\n",
       "      <td>0.475274</td>\n",
       "      <td>0.470268</td>\n",
       "      <td>0.323830</td>\n",
       "      <td>-0.546515</td>\n",
       "      <td>-0.114321</td>\n",
       "      <td>0.934784</td>\n",
       "      <td>-0.677403</td>\n",
       "      <td>-0.500425</td>\n",
       "      <td>-0.144767</td>\n",
       "      <td>-0.801125</td>\n",
       "      <td>0.016610</td>\n",
       "      <td>0.095089</td>\n",
       "      <td>0.525977</td>\n",
       "      <td>0.193258</td>\n",
       "      <td>-0.219724</td>\n",
       "      <td>0.393330</td>\n",
       "      <td>0.564153</td>\n",
       "      <td>-1.128137</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22359</th>\n",
       "      <td>-1.058361</td>\n",
       "      <td>-0.498448</td>\n",
       "      <td>-0.473576</td>\n",
       "      <td>-0.582417</td>\n",
       "      <td>-1.433977</td>\n",
       "      <td>0.931775</td>\n",
       "      <td>-1.151721</td>\n",
       "      <td>-0.964704</td>\n",
       "      <td>-3.799900</td>\n",
       "      <td>-3.572999</td>\n",
       "      <td>-1.313557</td>\n",
       "      <td>-0.472622</td>\n",
       "      <td>0.412662</td>\n",
       "      <td>1.168907</td>\n",
       "      <td>-0.093279</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>-0.082628</td>\n",
       "      <td>-0.638422</td>\n",
       "      <td>0.051467</td>\n",
       "      <td>-0.155786</td>\n",
       "      <td>0.053220</td>\n",
       "      <td>-0.552470</td>\n",
       "      <td>-0.855674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22360</th>\n",
       "      <td>0.954930</td>\n",
       "      <td>-0.498448</td>\n",
       "      <td>-0.473576</td>\n",
       "      <td>-0.582417</td>\n",
       "      <td>-0.026124</td>\n",
       "      <td>2.447360</td>\n",
       "      <td>-0.430837</td>\n",
       "      <td>0.070347</td>\n",
       "      <td>-4.081985</td>\n",
       "      <td>-4.149445</td>\n",
       "      <td>-2.378561</td>\n",
       "      <td>-0.359992</td>\n",
       "      <td>1.292547</td>\n",
       "      <td>1.891784</td>\n",
       "      <td>0.025671</td>\n",
       "      <td>0.241261</td>\n",
       "      <td>-0.085269</td>\n",
       "      <td>-0.158267</td>\n",
       "      <td>0.614075</td>\n",
       "      <td>0.688987</td>\n",
       "      <td>0.749169</td>\n",
       "      <td>0.267080</td>\n",
       "      <td>0.143356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22361</th>\n",
       "      <td>1.679715</td>\n",
       "      <td>3.344204</td>\n",
       "      <td>-0.473576</td>\n",
       "      <td>-0.582417</td>\n",
       "      <td>-0.064844</td>\n",
       "      <td>-0.009338</td>\n",
       "      <td>-0.007491</td>\n",
       "      <td>-0.006795</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.003536</td>\n",
       "      <td>0.023690</td>\n",
       "      <td>0.700989</td>\n",
       "      <td>-0.603864</td>\n",
       "      <td>0.481881</td>\n",
       "      <td>0.482145</td>\n",
       "      <td>0.288278</td>\n",
       "      <td>-0.021536</td>\n",
       "      <td>-0.272679</td>\n",
       "      <td>-0.230904</td>\n",
       "      <td>-0.238286</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.266915</td>\n",
       "      <td>1.234911</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22362</th>\n",
       "      <td>-1.299956</td>\n",
       "      <td>0.549548</td>\n",
       "      <td>-0.473576</td>\n",
       "      <td>-0.582417</td>\n",
       "      <td>-1.628164</td>\n",
       "      <td>0.164853</td>\n",
       "      <td>0.350120</td>\n",
       "      <td>0.387200</td>\n",
       "      <td>0.224519</td>\n",
       "      <td>0.173902</td>\n",
       "      <td>0.106448</td>\n",
       "      <td>-0.656925</td>\n",
       "      <td>-0.666441</td>\n",
       "      <td>-0.817016</td>\n",
       "      <td>0.080071</td>\n",
       "      <td>0.375645</td>\n",
       "      <td>-0.063921</td>\n",
       "      <td>0.192874</td>\n",
       "      <td>0.329374</td>\n",
       "      <td>0.350450</td>\n",
       "      <td>0.336306</td>\n",
       "      <td>-0.283242</td>\n",
       "      <td>-0.219928</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22363</th>\n",
       "      <td>-0.253045</td>\n",
       "      <td>-0.149116</td>\n",
       "      <td>-0.473576</td>\n",
       "      <td>-0.582417</td>\n",
       "      <td>0.512995</td>\n",
       "      <td>-0.041645</td>\n",
       "      <td>-0.066471</td>\n",
       "      <td>-0.087287</td>\n",
       "      <td>-0.009477</td>\n",
       "      <td>-0.013218</td>\n",
       "      <td>0.005659</td>\n",
       "      <td>-0.259300</td>\n",
       "      <td>0.086240</td>\n",
       "      <td>-0.281171</td>\n",
       "      <td>1.066723</td>\n",
       "      <td>-0.871998</td>\n",
       "      <td>-0.073275</td>\n",
       "      <td>-0.638422</td>\n",
       "      <td>-0.516659</td>\n",
       "      <td>0.256295</td>\n",
       "      <td>-0.571031</td>\n",
       "      <td>0.302817</td>\n",
       "      <td>-0.265338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22364 rows Ã— 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "0     -0.816766 -0.149116  0.326534  0.174376  0.987036  0.033720 -0.048645   \n",
       "1     -1.461019  0.549548 -0.473576 -0.582417  0.265156  0.876995  0.350120   \n",
       "2     -2.185804  1.597544  0.326534  0.174376  0.366394  0.005818 -0.039303   \n",
       "3     -0.091981  0.549548 -0.473576 -0.582417  1.915743  1.552617  1.671741   \n",
       "4     -0.333576  0.200216  1.126643  1.687963  1.187543  0.475274  0.470268   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "22359 -1.058361 -0.498448 -0.473576 -0.582417 -1.433977  0.931775 -1.151721   \n",
       "22360  0.954930 -0.498448 -0.473576 -0.582417 -0.026124  2.447360 -0.430837   \n",
       "22361  1.679715  3.344204 -0.473576 -0.582417 -0.064844 -0.009338 -0.007491   \n",
       "22362 -1.299956  0.549548 -0.473576 -0.582417 -1.628164  0.164853  0.350120   \n",
       "22363 -0.253045 -0.149116 -0.473576 -0.582417  0.512995 -0.041645 -0.066471   \n",
       "\n",
       "            7         8         9         10        11        12        13   \\\n",
       "0     -0.111790 -0.031080  0.009028  0.061228 -0.254103 -0.678105 -0.146323   \n",
       "1      0.492818 -0.979046 -0.978990 -0.366887 -0.687642  1.060124 -1.001496   \n",
       "2     -0.081876 -0.023800  0.005536  0.042112  0.108333  0.053045  0.050813   \n",
       "3      1.612364 -0.170401  0.125865  0.816450 -0.626208  0.977116 -0.592952   \n",
       "4      0.323830 -0.546515 -0.114321  0.934784 -0.677403 -0.500425 -0.144767   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "22359 -0.964704 -3.799900 -3.572999 -1.313557 -0.472622  0.412662  1.168907   \n",
       "22360  0.070347 -4.081985 -4.149445 -2.378561 -0.359992  1.292547  1.891784   \n",
       "22361 -0.006795  0.000513  0.003536  0.023690  0.700989 -0.603864  0.481881   \n",
       "22362  0.387200  0.224519  0.173902  0.106448 -0.656925 -0.666441 -0.817016   \n",
       "22363 -0.087287 -0.009477 -0.013218  0.005659 -0.259300  0.086240 -0.281171   \n",
       "\n",
       "            14        15        16        17        18        19        20   \\\n",
       "0      0.474443 -0.959558  0.085735  1.952211 -0.777544  0.061762 -1.286230   \n",
       "1     -0.642221  0.328820  0.038968  0.841940  0.821795 -0.403654  0.236108   \n",
       "2     -0.825683 -0.948270 -0.065076  0.434458 -0.777544 -0.766138 -1.428566   \n",
       "3      1.726898  1.554656 -0.063921 -0.215461  1.048651  0.561046  1.270329   \n",
       "4     -0.801125  0.016610  0.095089  0.525977  0.193258 -0.219724  0.393330   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "22359 -0.093279  0.003599 -0.082628 -0.638422  0.051467 -0.155786  0.053220   \n",
       "22360  0.025671  0.241261 -0.085269 -0.158267  0.614075  0.688987  0.749169   \n",
       "22361  0.482145  0.288278 -0.021536 -0.272679 -0.230904 -0.238286  0.009050   \n",
       "22362  0.080071  0.375645 -0.063921  0.192874  0.329374  0.350450  0.336306   \n",
       "22363  1.066723 -0.871998 -0.073275 -0.638422 -0.516659  0.256295 -0.571031   \n",
       "\n",
       "            21        22   23   24   25   26   27   28   29   30   31   32   \\\n",
       "0      0.510489  0.053968  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  1.0   \n",
       "1     -0.084837  2.459291  1.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0   \n",
       "2     -1.220110  0.550192  1.0  0.0  0.0  0.0  1.0  0.0  1.0  1.0  0.0  1.0   \n",
       "3      2.476449  0.665577  0.0  1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0   \n",
       "4      0.564153 -1.128137  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  1.0   \n",
       "...         ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "22359 -0.552470 -0.855674  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  1.0   \n",
       "22360  0.267080  0.143356  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  1.0   \n",
       "22361  0.266915  1.234911  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  1.0   \n",
       "22362 -0.283242 -0.219928  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  1.0   \n",
       "22363  0.302817 -0.265338  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  1.0   \n",
       "\n",
       "       33   34   35   36   37   38   39   40   41   42   43   44   45   46   \\\n",
       "0      0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0   \n",
       "1      0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "2      0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0   \n",
       "3      0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4      0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "22359  0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "22360  0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "22361  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0   \n",
       "22362  0.0  0.0  1.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "22363  0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "\n",
       "       47   48   49   ...  74   75   76   77   78   79   80   81   82   83   \\\n",
       "0      0.0  0.0  1.0  ...  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0   \n",
       "1      0.0  0.0  1.0  ...  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0   \n",
       "2      0.0  0.0  1.0  ...  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0   \n",
       "3      0.0  1.0  1.0  ...  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0   \n",
       "4      0.0  0.0  1.0  ...  0.0  1.0  1.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "22359  0.0  0.0  1.0  ...  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0   \n",
       "22360  0.0  0.0  1.0  ...  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0   \n",
       "22361  0.0  0.0  1.0  ...  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0   \n",
       "22362  0.0  0.0  1.0  ...  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0   \n",
       "22363  0.0  0.0  1.0  ...  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0   \n",
       "\n",
       "       84   85   86   87   88   89   90   91   92   93   94   95   96   97   \\\n",
       "0      1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "1      1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
       "2      1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "3      1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
       "4      1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "22359  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
       "22360  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
       "22361  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
       "22362  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
       "22363  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
       "\n",
       "       98   99   100  101  102  103  104  105  106  107  108  109  110  111  \\\n",
       "0      1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0   \n",
       "1      1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0   \n",
       "2      1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0   \n",
       "3      1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0   \n",
       "4      1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "22359  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0   \n",
       "22360  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0   \n",
       "22361  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0   \n",
       "22362  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0   \n",
       "22363  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0   \n",
       "\n",
       "       112  113  114  115  116  117  118  119  120  121  122  123  \n",
       "0      0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  \n",
       "1      0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  \n",
       "2      0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  \n",
       "3      0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  \n",
       "4      0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "22359  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  \n",
       "22360  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  \n",
       "22361  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  \n",
       "22362  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  \n",
       "22363  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  \n",
       "\n",
       "[22364 rows x 124 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_onehot(y):\n",
    "    mapped = []\n",
    "    \n",
    "    for ind,lab in y.iterrows():\n",
    "        if(lab[0]==0):\n",
    "            mapped.append([1,0])\n",
    "        elif(lab[0]==1):\n",
    "            mapped.append([0,1])\n",
    "        else:\n",
    "            print(lab)\n",
    "            print('error')\n",
    "    return mapped\n",
    "map_train_y = y_onehot(train_y)\n",
    "map_val_y = y_onehot(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self,X,y) -> None:\n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, index) :\n",
    "        return torch.tensor(self.X.iloc[index]).to(device),torch.tensor(self.y[index]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import dataloader\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "train_dataset = TrainDataset(train_X,map_train_y)\n",
    "val_dataset = TrainDataset(val_X,map_val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    21646\n",
      "1      718\n",
      "Name: outcome, dtype: int64\n",
      "0    0.000046\n",
      "1    0.001393\n",
      "Name: outcome, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "def balance_prob(y):\n",
    "    print(y.value_counts())\n",
    "    prob = 1/y.value_counts()\n",
    "    print(prob)\n",
    "    dataset_element_weights = [] # each element prob\n",
    "    for label_id in y:                \n",
    "        dataset_element_weights.append(prob[label_id])\n",
    "    return dataset_element_weights\n",
    "\n",
    "balance_prob = balance_prob(train_y['outcome'])\n",
    "sampler = WeightedRandomSampler(weights=balance_prob,num_samples=len(map_train_y),replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# Create CNN Model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 6, 1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(6, 16, 1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=1)\n",
    "        self.fc1 = nn.Linear(1984, 480)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(480, 120)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(120,32)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(32, 2)\n",
    "        self.softmax = nn.Softmax(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.softmax(self.fc4(x),1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of Net(\n",
       "  (conv1): Conv1d(1, 6, kernel_size=(1,), stride=(1,))\n",
       "  (relu1): ReLU()\n",
       "  (pool1): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(6, 16, kernel_size=(1,), stride=(1,))\n",
       "  (relu2): ReLU()\n",
       "  (pool2): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=1984, out_features=480, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc2): Linear(in_features=480, out_features=120, bias=True)\n",
       "  (relu4): ReLU()\n",
       "  (fc3): Linear(in_features=120, out_features=32, bias=True)\n",
       "  (relu5): ReLU()\n",
       "  (fc4): Linear(in_features=32, out_features=2, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Net().modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "import torch.nn as nn\n",
    "# Hyper parm\n",
    "# batch_size, epoch and iteration\n",
    "batch_size = 100\n",
    "n_iters = 11000\n",
    "num_epochs = 50\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, sampler=sampler)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "model = Net()\n",
    "model.to(device)\n",
    "# Cross Entropy Loss \n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 100 train loss: 0.5407660639286042 val_loss: 0.4897757369492735\n",
      "val\n",
      "f1_score: 0.20300751879699247 confusion matrix:\n",
      " [[4396 1034]\n",
      " [  26  135]]\n",
      "\n",
      "iter: 200 train loss: 0.4758015489578247 val_loss: 0.3812179373843329\n",
      "val\n",
      "f1_score: 0.3616352201257862 confusion matrix:\n",
      " [[5070  360]\n",
      " [  46  115]]\n",
      "\n",
      "iter: 300 train loss: 0.46571595549583433 val_loss: 0.3985318083848272\n",
      "val\n",
      "f1_score: 0.32570659488559894 confusion matrix:\n",
      " [[4969  461]\n",
      " [  40  121]]\n",
      "\n",
      "iter: 400 train loss: 0.46345084846019746 val_loss: 0.39329408055969645\n",
      "val\n",
      "f1_score: 0.3394109396914446 confusion matrix:\n",
      " [[4999  431]\n",
      " [  40  121]]\n",
      "\n",
      "iter: 500 train loss: 0.46040013372898103 val_loss: 0.3711638871048178\n",
      "val\n",
      "f1_score: 0.40630472854640975 confusion matrix:\n",
      " [[5136  294]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 600 train loss: 0.46523674339056015 val_loss: 0.41769231483340263\n",
      "val\n",
      "f1_score: 0.29917550058892817 confusion matrix:\n",
      " [[4869  561]\n",
      " [  34  127]]\n",
      "\n",
      "iter: 700 train loss: 0.46013553291559217 val_loss: 0.44266385797943386\n",
      "val\n",
      "f1_score: 0.25742574257425743 confusion matrix:\n",
      " [[4711  719]\n",
      " [  31  130]]\n",
      "\n",
      "iter: 800 train loss: 0.4535423466563225 val_loss: 0.3944636072431292\n",
      "val\n",
      "f1_score: 0.34269662921348315 confusion matrix:\n",
      " [[5001  429]\n",
      " [  39  122]]\n",
      "\n",
      "iter: 900 train loss: 0.4470217373967171 val_loss: 0.4074925184249878\n",
      "val\n",
      "f1_score: 0.31155778894472363 confusion matrix:\n",
      " [[4919  511]\n",
      " [  37  124]]\n",
      "\n",
      "iter: 1000 train loss: 0.44490113586187363 val_loss: 0.3988936846809728\n",
      "val\n",
      "f1_score: 0.3310719131614654 confusion matrix:\n",
      " [[4976  454]\n",
      " [  39  122]]\n",
      "\n",
      "iter: 1100 train loss: 0.4492269000411034 val_loss: 0.388310364314488\n",
      "val\n",
      "f1_score: 0.3588235294117647 confusion matrix:\n",
      " [[5033  397]\n",
      " [  39  122]]\n",
      "\n",
      "iter: 1200 train loss: 0.44767427921295166 val_loss: 0.3804280034133366\n",
      "val\n",
      "f1_score: 0.3794212218649518 confusion matrix:\n",
      " [[5087  343]\n",
      " [  43  118]]\n",
      "\n",
      "iter: 1300 train loss: 0.44570632874965666 val_loss: 0.40409593071256367\n",
      "val\n",
      "f1_score: 0.3211488250652742 confusion matrix:\n",
      " [[4948  482]\n",
      " [  38  123]]\n",
      "\n",
      "iter: 1400 train loss: 0.4453019613027573 val_loss: 0.3734059961778777\n",
      "val\n",
      "f1_score: 0.3938356164383562 confusion matrix:\n",
      " [[5122  308]\n",
      " [  46  115]]\n",
      "\n",
      "iter: 1500 train loss: 0.4371351084113121 val_loss: 0.3818625382014683\n",
      "val\n",
      "f1_score: 0.370253164556962 confusion matrix:\n",
      " [[5076  354]\n",
      " [  44  117]]\n",
      "\n",
      "iter: 1600 train loss: 0.4304127088189125 val_loss: 0.37412099859544207\n",
      "val\n",
      "f1_score: 0.40202702702702703 confusion matrix:\n",
      " [[5118  312]\n",
      " [  42  119]]\n",
      "\n",
      "iter: 1700 train loss: 0.4363518151640892 val_loss: 0.37690189853310585\n",
      "val\n",
      "f1_score: 0.389351081530782 confusion matrix:\n",
      " [[5107  323]\n",
      " [  44  117]]\n",
      "\n",
      "iter: 1800 train loss: 0.43553036749362944 val_loss: 0.36661168560385704\n",
      "val\n",
      "f1_score: 0.4214417744916821 confusion matrix:\n",
      " [[5164  266]\n",
      " [  47  114]]\n",
      "\n",
      "iter: 1900 train loss: 0.4325296366214752 val_loss: 0.39078470904912266\n",
      "val\n",
      "f1_score: 0.3527696793002915 confusion matrix:\n",
      " [[5026  404]\n",
      " [  40  121]]\n",
      "\n",
      "iter: 2000 train loss: 0.428402561545372 val_loss: 0.38518109704766956\n",
      "val\n",
      "f1_score: 0.3686635944700461 confusion matrix:\n",
      " [[5060  370]\n",
      " [  41  120]]\n",
      "\n",
      "iter: 2100 train loss: 0.42833931267261505 val_loss: 0.3697305252509458\n",
      "val\n",
      "f1_score: 0.4171122994652407 confusion matrix:\n",
      " [[5147  283]\n",
      " [  44  117]]\n",
      "\n",
      "iter: 2200 train loss: 0.42547211349010466 val_loss: 0.3980280038501535\n",
      "val\n",
      "f1_score: 0.3360655737704918 confusion matrix:\n",
      " [[4982  448]\n",
      " [  38  123]]\n",
      "\n",
      "iter: 2300 train loss: 0.4306114101409912 val_loss: 0.37414164787956644\n",
      "val\n",
      "f1_score: 0.4034188034188034 confusion matrix:\n",
      " [[5124  306]\n",
      " [  43  118]]\n",
      "\n",
      "iter: 2400 train loss: 0.42577488988637924 val_loss: 0.36552303177969797\n",
      "val\n",
      "f1_score: 0.4315196998123827 confusion matrix:\n",
      " [[5173  257]\n",
      " [  46  115]]\n",
      "\n",
      "iter: 2500 train loss: 0.42361232042312624 val_loss: 0.3556342178157398\n",
      "val\n",
      "f1_score: 0.4851063829787233 confusion matrix:\n",
      " [[5235  195]\n",
      " [  47  114]]\n",
      "\n",
      "iter: 2600 train loss: 0.4217040264606476 val_loss: 0.36625751320804867\n",
      "val\n",
      "f1_score: 0.43622920517560076 confusion matrix:\n",
      " [[5168  262]\n",
      " [  43  118]]\n",
      "\n",
      "iter: 2700 train loss: 0.41932712197303773 val_loss: 0.3652613546167101\n",
      "val\n",
      "f1_score: 0.4341372912801484 confusion matrix:\n",
      " [[5169  261]\n",
      " [  44  117]]\n",
      "\n",
      "iter: 2800 train loss: 0.4222894859313965 val_loss: 0.3686916471592018\n",
      "val\n",
      "f1_score: 0.418018018018018 confusion matrix:\n",
      " [[5152  278]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 2900 train loss: 0.4228627720475197 val_loss: 0.3724902357373919\n",
      "val\n",
      "f1_score: 0.4131944444444445 confusion matrix:\n",
      " [[5134  296]\n",
      " [  42  119]]\n",
      "\n",
      "iter: 3000 train loss: 0.42941725343465803 val_loss: 0.36151607760361265\n",
      "val\n",
      "f1_score: 0.4514851485148515 confusion matrix:\n",
      " [[5200  230]\n",
      " [  47  114]]\n",
      "\n",
      "iter: 3100 train loss: 0.41598650574684143 val_loss: 0.36115108909351484\n",
      "val\n",
      "f1_score: 0.4566929133858267 confusion matrix:\n",
      " [[5199  231]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 3200 train loss: 0.41331087082624435 val_loss: 0.3682298761393343\n",
      "val\n",
      "f1_score: 0.42258652094717664 confusion matrix:\n",
      " [[5158  272]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 3300 train loss: 0.4180245536565781 val_loss: 0.37202537219439236\n",
      "val\n",
      "f1_score: 0.409090909090909 confusion matrix:\n",
      " [[5136  294]\n",
      " [  44  117]]\n",
      "\n",
      "iter: 3400 train loss: 0.4230456733703613 val_loss: 0.36402211072189467\n",
      "val\n",
      "f1_score: 0.4397705544933079 confusion matrix:\n",
      " [[5183  247]\n",
      " [  46  115]]\n",
      "\n",
      "iter: 3500 train loss: 0.4214779683947563 val_loss: 0.3668873480388096\n",
      "val\n",
      "f1_score: 0.42962962962962964 confusion matrix:\n",
      " [[5167  263]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 3600 train loss: 0.41801429450511934 val_loss: 0.3819255775638989\n",
      "val\n",
      "f1_score: 0.3791469194312796 confusion matrix:\n",
      " [[5078  352]\n",
      " [  41  120]]\n",
      "\n",
      "iter: 3700 train loss: 0.41781726956367493 val_loss: 0.36516026673572405\n",
      "val\n",
      "f1_score: 0.4444444444444444 confusion matrix:\n",
      " [[5178  252]\n",
      " [  43  118]]\n",
      "\n",
      "iter: 3800 train loss: 0.4162872016429901 val_loss: 0.3574428180498736\n",
      "val\n",
      "f1_score: 0.4754098360655738 confusion matrix:\n",
      " [[5219  211]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 3900 train loss: 0.42128209680318834 val_loss: 0.34869756549596786\n",
      "val\n",
      "f1_score: 0.5258215962441315 confusion matrix:\n",
      " [[5277  153]\n",
      " [  49  112]]\n",
      "\n",
      "iter: 4000 train loss: 0.41832108825445175 val_loss: 0.35074373920048985\n",
      "val\n",
      "f1_score: 0.5181818181818182 confusion matrix:\n",
      " [[5265  165]\n",
      " [  47  114]]\n",
      "\n",
      "iter: 4100 train loss: 0.41599404394626616 val_loss: 0.34895386759723934\n",
      "val\n",
      "f1_score: 0.5290023201856149 confusion matrix:\n",
      " [[5274  156]\n",
      " [  47  114]]\n",
      "\n",
      "iter: 4200 train loss: 0.4155112937092781 val_loss: 0.3522722098444189\n",
      "val\n",
      "f1_score: 0.5033707865168539 confusion matrix:\n",
      " [[5258  172]\n",
      " [  49  112]]\n",
      "\n",
      "iter: 4300 train loss: 0.4171978709101677 val_loss: 0.3561542433287416\n",
      "val\n",
      "f1_score: 0.47379454926624737 confusion matrix:\n",
      " [[5227  203]\n",
      " [  48  113]]\n",
      "\n",
      "iter: 4400 train loss: 0.41201023042201995 val_loss: 0.35323584558708326\n",
      "val\n",
      "f1_score: 0.5054466230936818 confusion matrix:\n",
      " [[5248  182]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 4500 train loss: 0.4152461785078049 val_loss: 0.3567333349159786\n",
      "val\n",
      "f1_score: 0.4779874213836478 confusion matrix:\n",
      " [[5228  202]\n",
      " [  47  114]]\n",
      "\n",
      "iter: 4600 train loss: 0.4175276279449463 val_loss: 0.35214381984301973\n",
      "val\n",
      "f1_score: 0.5088495575221239 confusion matrix:\n",
      " [[5254  176]\n",
      " [  46  115]]\n",
      "\n",
      "iter: 4700 train loss: 0.41355939507484435 val_loss: 0.35556323932749884\n",
      "val\n",
      "f1_score: 0.48851774530271397 confusion matrix:\n",
      " [[5229  201]\n",
      " [  44  117]]\n",
      "\n",
      "iter: 4800 train loss: 0.4098354342579842 val_loss: 0.363351081098829\n",
      "val\n",
      "f1_score: 0.4522417153996101 confusion matrix:\n",
      " [[5194  236]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 4900 train loss: 0.41418260246515276 val_loss: 0.3406524322926998\n",
      "val\n",
      "f1_score: 0.5698630136986301 confusion matrix:\n",
      " [[5330  100]\n",
      " [  57  104]]\n",
      "\n",
      "iter: 5000 train loss: 0.4156892707943916 val_loss: 0.34588360680001123\n",
      "val\n",
      "f1_score: 0.5454545454545454 confusion matrix:\n",
      " [[5295  135]\n",
      " [  50  111]]\n",
      "\n",
      "iter: 5100 train loss: 0.40803800642490384 val_loss: 0.3480319928910051\n",
      "val\n",
      "f1_score: 0.5238095238095237 confusion matrix:\n",
      " [[5281  149]\n",
      " [  51  110]]\n",
      "\n",
      "iter: 5200 train loss: 0.4112271085381508 val_loss: 0.34168412749256405\n",
      "val\n",
      "f1_score: 0.5833333333333333 confusion matrix:\n",
      " [[5319  111]\n",
      " [  49  112]]\n",
      "\n",
      "iter: 5300 train loss: 0.4100371810793877 val_loss: 0.36679243030292646\n",
      "val\n",
      "f1_score: 0.43253234750462105 confusion matrix:\n",
      " [[5167  263]\n",
      " [  44  117]]\n",
      "\n",
      "iter: 5400 train loss: 0.41372586607933043 val_loss: 0.3434542736836842\n",
      "val\n",
      "f1_score: 0.5685279187817259 confusion matrix:\n",
      " [[5309  121]\n",
      " [  49  112]]\n",
      "\n",
      "iter: 5500 train loss: 0.40604996263980864 val_loss: 0.34108610451221466\n",
      "val\n",
      "f1_score: 0.5842105263157895 confusion matrix:\n",
      " [[5322  108]\n",
      " [  50  111]]\n",
      "\n",
      "iter: 5600 train loss: 0.40629996836185456 val_loss: 0.33922155680400984\n",
      "val\n",
      "f1_score: 0.6037735849056605 confusion matrix:\n",
      " [[5332   98]\n",
      " [  49  112]]\n",
      "\n",
      "iter: 5700 train loss: 0.4076080718636513 val_loss: 0.347077519765922\n",
      "val\n",
      "f1_score: 0.5263157894736842 confusion matrix:\n",
      " [[5283  147]\n",
      " [  51  110]]\n",
      "\n",
      "iter: 5800 train loss: 0.4154788067936897 val_loss: 0.3422186103250299\n",
      "val\n",
      "f1_score: 0.5699481865284973 confusion matrix:\n",
      " [[5315  115]\n",
      " [  51  110]]\n",
      "\n",
      "iter: 5900 train loss: 0.41533501833677294 val_loss: 0.34569775951760157\n",
      "val\n",
      "f1_score: 0.5502392344497608 confusion matrix:\n",
      " [[5288  142]\n",
      " [  46  115]]\n",
      "\n",
      "iter: 6000 train loss: 0.4044234848022461 val_loss: 0.34805718064308167\n",
      "val\n",
      "f1_score: 0.5260663507109005 confusion matrix:\n",
      " [[5280  150]\n",
      " [  50  111]]\n",
      "\n",
      "iter: 6100 train loss: 0.4056815558671951 val_loss: 0.34858475838388714\n",
      "val\n",
      "f1_score: 0.5324074074074074 confusion matrix:\n",
      " [[5274  156]\n",
      " [  46  115]]\n",
      "\n",
      "iter: 6200 train loss: 0.41236567348241804 val_loss: 0.3520629235676357\n",
      "val\n",
      "f1_score: 0.5111111111111111 confusion matrix:\n",
      " [[5256  174]\n",
      " [  46  115]]\n",
      "\n",
      "iter: 6300 train loss: 0.4142354330420494 val_loss: 0.3404190923486437\n",
      "val\n",
      "f1_score: 0.5857519788918205 confusion matrix:\n",
      " [[5323  107]\n",
      " [  50  111]]\n",
      "\n",
      "iter: 6400 train loss: 0.40543123811483384 val_loss: 0.3467083860720907\n",
      "val\n",
      "f1_score: 0.5480769230769231 confusion matrix:\n",
      " [[5289  141]\n",
      " [  47  114]]\n",
      "\n",
      "iter: 6500 train loss: 0.4035642573237419 val_loss: 0.3446208132164819\n",
      "val\n",
      "f1_score: 0.56 confusion matrix:\n",
      " [[5303  127]\n",
      " [  49  112]]\n",
      "\n",
      "iter: 6600 train loss: 0.40572466850280764 val_loss: 0.3434206263295242\n",
      "val\n",
      "f1_score: 0.5670886075949367 confusion matrix:\n",
      " [[5308  122]\n",
      " [  49  112]]\n",
      "\n",
      "iter: 6700 train loss: 0.4138416397571564 val_loss: 0.34437803870865275\n",
      "val\n",
      "f1_score: 0.5572139303482587 confusion matrix:\n",
      " [[5301  129]\n",
      " [  49  112]]\n",
      "\n",
      "iter: 6800 train loss: 0.41058617532253266 val_loss: 0.35345442007694927\n",
      "val\n",
      "f1_score: 0.49015317286652077 confusion matrix:\n",
      " [[5246  184]\n",
      " [  49  112]]\n",
      "\n",
      "iter: 6900 train loss: 0.40669078409671783 val_loss: 0.3470224711511816\n",
      "val\n",
      "f1_score: 0.5463182897862233 confusion matrix:\n",
      " [[5285  145]\n",
      " [  46  115]]\n",
      "\n",
      "iter: 7000 train loss: 0.40993816703557967 val_loss: 0.3408984456743513\n",
      "val\n",
      "f1_score: 0.5885416666666666 confusion matrix:\n",
      " [[5320  110]\n",
      " [  48  113]]\n",
      "\n",
      "iter: 7100 train loss: 0.40858586996793744 val_loss: 0.3403826520911285\n",
      "val\n",
      "f1_score: 0.5910290237467019 confusion matrix:\n",
      " [[5324  106]\n",
      " [  49  112]]\n",
      "\n",
      "iter: 7200 train loss: 0.4072129103541374 val_loss: 0.3397780731320381\n",
      "val\n",
      "f1_score: 0.5962059620596206 confusion matrix:\n",
      " [[5332   98]\n",
      " [  51  110]]\n",
      "\n",
      "iter: 7300 train loss: 0.41284205168485644 val_loss: 0.34836321803075926\n",
      "val\n",
      "f1_score: 0.5348837209302325 confusion matrix:\n",
      " [[5276  154]\n",
      " [  46  115]]\n",
      "\n",
      "iter: 7400 train loss: 0.4064891222119331 val_loss: 0.33818882597344263\n",
      "val\n",
      "f1_score: 0.6174863387978143 confusion matrix:\n",
      " [[5338   92]\n",
      " [  48  113]]\n",
      "\n",
      "iter: 7500 train loss: 0.40612528294324873 val_loss: 0.339503105197634\n",
      "val\n",
      "f1_score: 0.5994550408719346 confusion matrix:\n",
      " [[5334   96]\n",
      " [  51  110]]\n",
      "\n",
      "iter: 7600 train loss: 0.40587974280118944 val_loss: 0.3433144065950598\n",
      "val\n",
      "f1_score: 0.5764411027568923 confusion matrix:\n",
      " [[5307  123]\n",
      " [  46  115]]\n",
      "\n",
      "iter: 7700 train loss: 0.40390504598617555 val_loss: 0.3381350631160395\n",
      "val\n",
      "f1_score: 0.6145251396648045 confusion matrix:\n",
      " [[5343   87]\n",
      " [  51  110]]\n",
      "\n",
      "iter: 7800 train loss: 0.40058035016059873 val_loss: 0.3411506377160549\n",
      "val\n",
      "f1_score: 0.5789473684210527 confusion matrix:\n",
      " [[5321  109]\n",
      " [  51  110]]\n",
      "\n",
      "iter: 7900 train loss: 0.4045225244760513 val_loss: 0.3394827204091208\n",
      "val\n",
      "f1_score: 0.608 confusion matrix:\n",
      " [[5330  100]\n",
      " [  47  114]]\n",
      "\n",
      "iter: 8000 train loss: 0.40564239144325254 val_loss: 0.34457794736538616\n",
      "val\n",
      "f1_score: 0.5454545454545454 confusion matrix:\n",
      " [[5303  127]\n",
      " [  53  108]]\n",
      "\n",
      "iter: 8100 train loss: 0.40289030849933627 val_loss: 0.36037304624915123\n",
      "val\n",
      "f1_score: 0.4658634538152611 confusion matrix:\n",
      " [[5209  221]\n",
      " [  45  116]]\n",
      "\n",
      "iter: 8200 train loss: 0.4039687043428421 val_loss: 0.34809027346117155\n",
      "val\n",
      "f1_score: 0.5317647058823529 confusion matrix:\n",
      " [[5279  151]\n",
      " [  48  113]]\n",
      "\n",
      "iter: 8300 train loss: 0.40882848262786864 val_loss: 0.3453370157097067\n",
      "val\n",
      "f1_score: 0.553921568627451 confusion matrix:\n",
      " [[5296  134]\n",
      " [  48  113]]\n",
      "\n",
      "iter: 8400 train loss: 0.40674987494945525 val_loss: 0.33939906156488825\n",
      "val\n",
      "f1_score: 0.596774193548387 confusion matrix:\n",
      " [[5330  100]\n",
      " [  50  111]]\n",
      "\n",
      "iter: 8500 train loss: 0.4053484445810318 val_loss: 0.3357888103595802\n",
      "val\n",
      "f1_score: 0.6312684365781711 confusion matrix:\n",
      " [[5359   71]\n",
      " [  54  107]]\n",
      "\n",
      "iter: 8600 train loss: 0.4108951500058174 val_loss: 0.33956847872052875\n",
      "val\n",
      "f1_score: 0.6005361930294906 confusion matrix:\n",
      " [[5330  100]\n",
      " [  49  112]]\n",
      "\n",
      "iter: 8700 train loss: 0.40799634099006654 val_loss: 0.3396965478147779\n",
      "val\n",
      "f1_score: 0.5853658536585366 confusion matrix:\n",
      " [[5330  100]\n",
      " [  53  108]]\n",
      "\n",
      "iter: 8800 train loss: 0.40417173206806184 val_loss: 0.3385889620653221\n",
      "val\n",
      "f1_score: 0.6005509641873279 confusion matrix:\n",
      " [[5337   93]\n",
      " [  52  109]]\n",
      "\n",
      "iter: 8900 train loss: 0.4027888149023056 val_loss: 0.33480886476380484\n",
      "val\n",
      "f1_score: 0.6352941176470589 confusion matrix:\n",
      " [[5359   71]\n",
      " [  53  108]]\n",
      "\n",
      "iter: 9000 train loss: 0.41098440796136854 val_loss: 0.3454322963953018\n",
      "val\n",
      "f1_score: 0.5476772616136919 confusion matrix:\n",
      " [[5294  136]\n",
      " [  49  112]]\n",
      "\n",
      "iter: 9100 train loss: 0.40482645958662034 val_loss: 0.3437816346330302\n",
      "val\n",
      "f1_score: 0.5606060606060606 confusion matrix:\n",
      " [[5306  124]\n",
      " [  50  111]]\n",
      "\n",
      "iter: 9200 train loss: 0.4131702893972397 val_loss: 0.34614665114453863\n",
      "val\n",
      "f1_score: 0.5480769230769231 confusion matrix:\n",
      " [[5289  141]\n",
      " [  47  114]]\n",
      "\n",
      "iter: 9300 train loss: 0.40701848119497297 val_loss: 0.3359319216438702\n",
      "val\n",
      "f1_score: 0.6235294117647059 confusion matrix:\n",
      " [[5357   73]\n",
      " [  55  106]]\n",
      "\n",
      "iter: 9400 train loss: 0.4055498605966568 val_loss: 0.343789490205901\n",
      "val\n",
      "f1_score: 0.5561224489795918 confusion matrix:\n",
      " [[5308  122]\n",
      " [  52  109]]\n",
      "\n",
      "iter: 9500 train loss: 0.4068132025003433 val_loss: 0.34211880820138113\n",
      "val\n",
      "f1_score: 0.5729166666666666 confusion matrix:\n",
      " [[5317  113]\n",
      " [  51  110]]\n",
      "\n",
      "iter: 9600 train loss: 0.4091323652863503 val_loss: 0.3500087500682899\n",
      "val\n",
      "f1_score: 0.5219399538106236 confusion matrix:\n",
      " [[5271  159]\n",
      " [  48  113]]\n",
      "\n",
      "iter: 9700 train loss: 0.40168612509965895 val_loss: 0.3441533217472689\n",
      "val\n",
      "f1_score: 0.5541561712846348 confusion matrix:\n",
      " [[5304  126]\n",
      " [  51  110]]\n",
      "\n",
      "iter: 9800 train loss: 0.4029844543337822 val_loss: 0.3345603958836624\n",
      "val\n",
      "f1_score: 0.6303030303030304 confusion matrix:\n",
      " [[5365   65]\n",
      " [  57  104]]\n",
      "\n",
      "iter: 9900 train loss: 0.4035591819882393 val_loss: 0.3368835635483265\n",
      "val\n",
      "f1_score: 0.6288951841359772 confusion matrix:\n",
      " [[5349   81]\n",
      " [  50  111]]\n",
      "\n",
      "iter: 10000 train loss: 0.4064528056979179 val_loss: 0.34047542033450945\n",
      "val\n",
      "f1_score: 0.5973333333333332 confusion matrix:\n",
      " [[5328  102]\n",
      " [  49  112]]\n",
      "\n",
      "iter: 10100 train loss: 0.409769352376461 val_loss: 0.34675004173602375\n",
      "val\n",
      "f1_score: 0.5419664268585133 confusion matrix:\n",
      " [[5287  143]\n",
      " [  48  113]]\n",
      "\n",
      "iter: 10200 train loss: 0.3956497460603714 val_loss: 0.34385942029101507\n",
      "val\n",
      "f1_score: 0.5614035087719297 confusion matrix:\n",
      " [[5304  126]\n",
      " [  49  112]]\n",
      "\n",
      "iter: 10300 train loss: 0.40204647064208987 val_loss: 0.3347725234925747\n",
      "val\n",
      "f1_score: 0.6371681415929203 confusion matrix:\n",
      " [[5360   70]\n",
      " [  53  108]]\n",
      "\n",
      "iter: 10400 train loss: 0.4056513592600822 val_loss: 0.3484023910548006\n",
      "val\n",
      "f1_score: 0.52803738317757 confusion matrix:\n",
      " [[5276  154]\n",
      " [  48  113]]\n",
      "\n",
      "iter: 10500 train loss: 0.40364132940769193 val_loss: 0.3505051854465689\n",
      "val\n",
      "f1_score: 0.5125858123569794 confusion matrix:\n",
      " [[5266  164]\n",
      " [  49  112]]\n",
      "\n",
      "iter: 10600 train loss: 0.4014305257797241 val_loss: 0.3386054166725704\n",
      "val\n",
      "f1_score: 0.5994550408719346 confusion matrix:\n",
      " [[5334   96]\n",
      " [  51  110]]\n",
      "\n",
      "iter: 10700 train loss: 0.4020242488384247 val_loss: 0.33946136278765543\n",
      "val\n",
      "f1_score: 0.5978260869565218 confusion matrix:\n",
      " [[5333   97]\n",
      " [  51  110]]\n",
      "\n",
      "iter: 10800 train loss: 0.40419923543930053 val_loss: 0.3479162928249155\n",
      "val\n",
      "f1_score: 0.5386416861826698 confusion matrix:\n",
      " [[5279  151]\n",
      " [  46  115]]\n",
      "\n",
      "iter: 10900 train loss: 0.4062969172000885 val_loss: 0.33973785436579157\n",
      "val\n",
      "f1_score: 0.6 confusion matrix:\n",
      " [[5332   98]\n",
      " [  50  111]]\n",
      "\n",
      "iter: 11000 train loss: 0.4104010859131813 val_loss: 0.33700232048119816\n",
      "val\n",
      "f1_score: 0.6104651162790697 confusion matrix:\n",
      " [[5352   78]\n",
      " [  56  105]]\n",
      "\n",
      "iter: 11100 train loss: 0.40892805099487306 val_loss: 0.34104628914168905\n",
      "val\n",
      "f1_score: 0.5894736842105263 confusion matrix:\n",
      " [[5323  107]\n",
      " [  49  112]]\n",
      "\n",
      "iter: 11200 train loss: 0.4066104465723038 val_loss: 0.33381406164595057\n",
      "val\n",
      "f1_score: 0.6484848484848486 confusion matrix:\n",
      " [[5368   62]\n",
      " [  54  107]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "# ANN model training\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "model.train()\n",
    "performace = {}\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        \n",
    "\n",
    "        optimizer.zero_grad() # Clear gradients\n",
    "        outputs = model(Variable(X.float().to(device))) # Forward propagation\n",
    "        #print(outputs)\n",
    "       # print(y.float())\n",
    "        #print(outputs)\n",
    "        loss = error(outputs,y.float()) # Calculate softmax and cross entropy loss\n",
    "        loss.backward() # Calculating gradients\n",
    "        train_loss.append(loss.data.item())\n",
    "        optimizer.step() # Update parameters\n",
    "       \n",
    "        count += 1\n",
    "        \n",
    "        if count%100 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            predict = []\n",
    "            true = []\n",
    "            model.eval()\n",
    "            # Predict val dataset\n",
    "            for X, y in val_loader:\n",
    "                #print(X.float())\n",
    "                outputs = model(X.float()) # Forward propagation\n",
    "                loss = error(outputs,y.float())\n",
    "                val_loss.append(loss.data.item())\n",
    "                outputs = outputs.cpu().detach().numpy()\n",
    "                y = y.cpu().detach().numpy()\n",
    "                \n",
    "                for pred in outputs:\n",
    "                    predict.append(np.argmax(pred))\n",
    "                for label in y:\n",
    "                    true.append(np.argmax(label))\n",
    "                \n",
    "            #print(true)\n",
    "           # print(predict)\n",
    "            performace[count] = (tools.get_performance(true,predict))\n",
    "            \n",
    "            \n",
    "            print(\"iter:\",count,\"train loss:\",np.average(train_loss),\"val_loss:\",np.average(val_loss))\n",
    "            print(\"val\")\n",
    "            print(\"f1_score:\",performace[count]['f1_score'],'confusion matrix:\\n',performace[count]['confusion matrix'])\n",
    "            print()\n",
    "            performace[count]['train_loss'] = np.average(train_loss)\n",
    "            performace[count]['val_loss'] = np.average(val_loss)\n",
    "                \n",
    "            train_loss = []\n",
    "            val_loss = []    \n",
    "            model.train()\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAC69UlEQVR4nOyddXwcZfrAv7Oe3Ww27kmTtGlqqQultGiLFSha3F0PO+SHHXDcHXaHOxTucEpxSp0Kdde4u+1m3WZ+f8xu3Fpa2t7t9/PJZ7Mz78y8M7v7vM/72CtIkkSIECFChDj6URzuDoQIESJEiINDSKCHCBEixH8JIYEeIkSIEP8lhAR6iBAhQvyXEBLoIUKECPFfgupwXTg2NlbKyMg4XJcPESJEiKOSzZs3N0qSFNfTvsMm0DMyMti0adPhunyIECFCHJUIglDW275+TS6CILwvCEK9IAi7etkvCILwsiAIhYIg7BAEYfzv6WyIECFChDgwBmJDnwec1sf+04HswN+NwBu/v1shQoQIEWJ/6VegS5K0Emjuo8k5wEeSzDogUhCEpIPVwRAhQoQIMTAOhg09Bajo8L4ysK2ma0NBEG5E1uJJT0/vdiKv10tlZSUul+sgdCvE0YpOpyM1NRW1Wn24uxIixFHFH+oUlSTpbeBtgIkTJ3YrIlNZWYnRaCQjIwNBEP7IroU4QpAkiaamJiorK8nMzDzc3QkR4qjiYMShVwFpHd6nBrbtNy6Xi5iYmJAw/x9GEARiYmJCs7QQIQ6AgyHQvwOuDES7HANYJEnqZm4ZKCFhHiL0HQgR4sAYSNjip8BaIEcQhEpBEK4TBOFmQRBuDjT5CSgGCoF3gFsPWW9DhAhxxGJ2eBhIOW5JkmiyuQfUNth+f3F5/WyrMFNrcSGKAz/e4vDS6vLu9/UGis3t4+8/76Oi2XFIzt+vDV2SpEv62S8Btx20HoUIcRjw+UXKmx2E61TEG3WHuzv94vL6abJ7iDFo0KmVbdub7R4+31iBXqMkIUJLVlw42fHhbbOekkY78zdXkh6tZ+aIBKIMGiRJorLFCUBatH6/+tHq8vLD9hq+2lzBlnIzadFhnDMmhdNGJRIfoSVCp8YvSlSZnVS2OFhV0Mii3XVUmZ1cNDGVZ87NRaXsXa/8YUc1j3yzi4snpXP3zGy0KmWvbYNUtji44aPN7K1pBUCrUjAiOYKTcuI5eXgCw5OMPc4Cl+fV86fPthGpV7Pg1mlEGzTd2ri8fnZXWxAEAZVCICsunHBtuxiVJImtFWa2lpvZXmHG7fNzyvAEZo5I4Nf8Bp75aS91rW5SosK44phBA3nE+4VwuBa4mDhxotQ1U3Tv3r0MHz78sPQnxJHFQL8LT3y3G7PDwxVTBzE+ParTD9XrF/lobRlun59bTxjS6bjNZc2sL2lmX42VvForJY12PH4RnVrB03NyuWBCKgAtdg+L99QxPCmCUSkRAzYHfbO1is83VnDx5DTOzE1qE1pun59mu4cWuxeb20e0QU1ChI5wrarHc3t8Igu2VvLlpkrMTi8Otw+ry4fV7QMgJTKMVy8dx7j0KCqaHVz1/gaKG+2dzpEZa+C0UYmUNtpZuLuW4E9eqRAYkRRBebMDi1PWSs/ITeSOk7IZnhTR5/3VW128t6qE/6wrw+7xkx0fzmmjEtlWYWZNYSO9KcUalYIZ2bHEGbV8uqGCU4Yn8Oql49CpldjcPvyihClMjm56f3UJT/24h2RTGFVmJ8MSjfzfmcOxuXwUN9pJjQrj7DHJnZ7bxtJmbv73Zjx+kYfPGI5PlChrtLOxrIXtFWYApmRG8+Q5o8hJNALgFyVeXlrAy8sKGBIXTlmzgzGpJv5z/ZROA4jF4eWK99ezo9LSti0hQsu/5o5j6uAYmu0e/vzVdpbsrQcg2aRDEASqzE4EASQJRqVE8OQ5oxifHtXn8+0LQRA2S5I0scd9IYHenTlz5lBRUYHL5eKuu+7ixhtvZOHChTz88MP4/X5iY2NZunQpNpuNO+64g02bNiEIAo8//jjnn3/+4e7+fwUD+S78VtjIpe+uR6UQ8IkSI5IiOGlYPOMHRSIg8Nef9lJYbwPglz/NaPsBbyhp5qK31gKyQMxJNJKdEM7guHC+3lLJuuJmLpqYiilMzcfry3F4/ACkRoVxyvAERqeaGJYYQWp0GFqVAo1S0UmofPhbKY9/txuDRond4yc1KowxqZHk1ckDh78HaZcWHcYrl4xnbFokIAuZLzZV8OqywjZhlhVnIEytwqhTERuuISJMzdsri6lrdXHTjMF8vqkCt9fPO1dOJCsunLpWF9srzSzcVctvRU0YNEqunJrBlccOos7i5qddNWwpayErLpyRyRHUWlx8+FspVrePm47P4qHTOz//wnoba4saWVvcxJK99fj8ImeNSebaaZmMTjW1PYN6q4u1RU20Or20unwIgvycU6PCGJYYgSGg0X60Vn5OaVF6vH6RGovsCM+MNZAcqWNNYROnjkzgpYvH8VtRI3/+aieNNnenPh2TFc3fzhuNy+vn3VUlfLutivRoPe9cNZHBceGd2tZbXfy4o4aXlhZgdfk4d1wKzXYPm0qbaXX5OH98Kk/PGcXivXXc+elWzhuXwgsXjUEQBMwOD5e/t578Wht/OWckSSYddrefFxbnUdJo5/Ipg1i0p5YWu5f7T83hnLHJxEfokCSJnVUWFu+pIy1Kz/kTUlEqfp+P6KgU6H/5fjd7qlsP6jVHJEfw+Fkj+23X3NxMdHQ0TqeTSZMmsXTpUiZOnMjKlSvJzMxs2//AAw/gdrv517/+BUBLSwtRUQc+8v430GRzU9fqRqkQ0KoUKBUCHp+Ixy+iVAiEa1Xyn06Fog9tN/hdaLC6idSrUXeZlouixDmvraHZ7uGHO47j5121fL6xnF3VrW0CMz1az72zhvLg/J2ckZvECxeNAeDyd9ezr9bKortndJtW+/wi/1ySz2vLi1AIcPaYZK48NoPCehsLd9WyurARj0/sdIwgwJC4cI7LjkUpCLy7uoSZIxJ45ZJxrCpo5J1VxdRYnOQkRDAs0UhyZBjRBjUGrYpmu4dai4t/ryuj3urmH+fnkpMQwUMLdrK9wszYtEjuOiWbE4bG9ajBWxxe7v1yO0v21pFs0vHhtZPJTjB2a9fq8qJRKjqZZ3rC4vDy15/28MWmSv45dwznjktFkiSe+yWP11cUAbLmedLweK4/LouMWEOf5+uPn3fW8MFvpaRGhjEkIRxJgh2VZvbUtDJrRCIPnzG8TQC22D2sL2kmNSqMQTF6ftxRw19/2ovT48cnSoSplVw0MZV7ZuZg0veew9Bi9/Dcojw+31jBoBg9kzOiOXFYPLNGJLQ945eWFPDPJfmkRIYxNCGcyhYnZc0O3rp8AicOi287l93t4/HvdvPV5koyYw28csk4RqWYftcz6Y+QQA8wUIH+xBNPsGDBAgBKS0u577772LdvHx9//HGndhMmTOCzzz4jOzv7oPZzIHh8IqIk9fsD/aMQJYlqs5NmuweDVoVKIeD2ifhFCY1SgUalwOsXcXj8iJKESqEgJlxDZJgam9uH2eHF6xcxhqkx6VTk5e3jH+tsbChpJtqg4fRRiZwzNoVJGbJZ5Ycd1dz+yVZeuHAM5wfMIwAOj4/tFRbqrS5OHZmITq3kie928/H6Mlb9+SSqLU7Oe/03Hj5jGDfOGNzr/WyvMBOl15Ae09mm7POLlDbZ2VNjpb7Vhdsn4vT42V5pZkNJM26fyHnjUnj2gtF92oa70mz3cMt/NrO+pBmFAFF6DY+dNaKbSaEnJEnil911jE+PJD7i99v/fX6Ry95dz/ZKMwtuncb326t5fUURF01M5fYTs0mLDjtiIpHqW128vqKI+Agtl00e1Kcg74pflHrVliVJ4j/ry9lY0kxBvY1Wp5dnzsvl+KE9Fjlke4WZ7IRw9JpDn9pzVAr0w8WKFSt45JFHWLRoEXq9nhNOOIF7772Xzz777IgR6A6Pj9JGB35JIj0qDJO+u/Pmj8Tp8VNlduLw+Ig3akmI0PX6gxdFCZvHR5PNg7VDNIFWpUSrUmBz+xAlibryYp5abeHccSkUNdhYsrcOl1dkSmY0952aw31fbidMreTHO6f3O4WtaHZw/HPLuWFGFvm1VrZVmFn9wEltU/+Dhcvrp7LFQVZsOIoDmFZ7/SLP/ZKHy+vnnplDiTyMn2u91cXsl1fj8PixuX1cOiWdp88ZdUD3FeLg0pdAP2zlc49ULBYLUVFR6PV69u3bx7p163C5XKxcuZKSkpJOJpeZM2fy2muv/aEmF6vLS1mTA5VSQKNQUt7sIEWiR498Vzw+OZLD7fODBAgQY9ASb9T2+EN1+/wIgLqLjTiIzy9S1+qi2e5BqRBIj9b3K4QUCoEInZoInRqX14/V5SNcq0SnViIIAn5RkoV6s4YV953Q1i+728f8LZW8vLSAC9+U7d8fXD1pQPbItGg9p+cm8eFvpbi8IvefmnPQhTmATq1kSHx3c8dAUSsVPHzG4fchAcQbdbx+2Xgue3c9l01J56mQMD8qCGnoXXC73cyZM4fS0lJycnIwm8088cQTOJ1OHn74YURRJD4+nsWLF2Oz2bjtttvYvHkzSqWSxx9/nPPOO6/Xc9vcPtQKAe0BmEkkSaLJ7qHG4kKrUpAZa0AhCJQ12bG5fW1TPQEI0ygJ16kwaFRtAs/l9VPSaEcUJSINGgRkjdDi9KJRKUgyhRGhkyMtRFGittXV5oBSKxUYNCqSInVttmxRlChssOH2isSEa4g3avfLxNAfvX0X7G4fH6wpwery8eDpwwY89d9RaebsV9cQoVOx5sGTMOpCdWIGgsPj+0PMCCEGzv+sycUviri84iHRxvYHSZIFZIPVjValZGhCeI+CqMHqxu3zkxrV2W7r8YlUtjiwuX0YdWrSosNQKQKCVZKotbhwef2Ba4HD60eSJAQEdBoFerUKs9ODgEBmrJ6wDj9Qm8tLldmF2+dHGdCeHR4/bp+fGIMWrVqBw+On1elFp1aSFScPJDUWJw1WNxkxBiLCDr5wPBSD+xPf7WZEUgQXTUrrv3GIEEco/7MmlyqzC4vDw/CkiIOqPXak3upCFOlktrA4vbTYPWhUclSBxenF6vJi0Kqwu32YnV6iupgmLA4PNRY5uSPaoGnTirw+kYJ6K5IEKVFhROs1nQYDhSCQHBnW6VyiKGH3+LC7fdg9flocHtRKBRmx+m6JGeE6NdkJKqyBELNWlxelIJAVayC8gxZrdngob3ZQY3ERGaamweom2qA5JML8UPHE2f07xEOEOJr5rxXoLq8fs8MDyKaO3+tg8okiNpcPU5i6TaB6/SJ1FjcSEhanlySTDrPDi9kpC9Cgg09AICUyjGiDhoJ6G/WtslAMnsfl9VPR4kSvUckZgDYP+mj5o2mwuRFFyE4IH3BEi0IhYNSp28wKwVlYb+YJhSBg0msw6TW9to3Ua3B6/DTY3JgdnjYzTYgQIY4cjmqB3ur04hclonpwCNa1utrinH+vQHd4fJQ3OfD4RVKiwogxaAE51ExCIjUqjHqrm9ImO4IgkBChI86oRQDcPhGFAJqAZpwYoaO0yU6Lw0u0QYPHJ1LWZEehEBgUo6fe6qbZ7iHJLyIFrhGlV/+u8MT9CTHrq22iSYfD68fu9pERY/jdCRIhQoQ4uBzVAr3B6sbu8aFRKTrZyZ0ePxanl3ijDldAAB0IkiTRaPNQ2+pCrRDQqZQ0tLqJ0stOxRa7h3CtimiDFlOYhma7B6NO1Un4dhXERp2KMI2S+lYXTo+PZoccupcVa0CtVBBj0NBkc9Ps8ODzS0gSxEVoD6j/BxtBEMiIMeDxiYRpjoz49xAhQrRzaAzLfxBeUc7Yq2h24Bfbs/fqrS6UgkBsuAaDVoXbJ3bL7gsi9uIUFiWJqhYnNRYnRq2KIfHhJEbq8PhFWhwerC4fHr/YFi6oVAjEGbX9atJBDd7jF2l2eInSq8lJCG8bkHRqJeFaFU02D812D5F69YAKEv1RKBVCSJiHCHGEctRq6JIk4fNLGLQqHG4/1WYXcUYtjTY3FqeXhAgdKqWCcJ0KLLLZJVrV2ezi8PgoarCTFhXWySQTrLxnc/uIj9CRYNQiCAJGhYBeo6Kh1Y1WrUSlUByQU9CoVZERY0CnVqJRdR9TY8K1lDXJBZbijEeGdh4iRIgjn6NWQ/eLEqIkEaFTEx+hpcXhIb/O2mabjg2XBaFOpUClkB2UXbG6fG2lQx0eeb/L66eowY7d4yctSk9ih6xHQRCIj9Di8YtYXV6iDeo+65EE2bRpE3feeWfbe0EQiAhTtwnz6upqLrjggrb9EToVWpWSKL3miEntDxEixJHPUauh+wIFmNRKAVOYBq9fRK1UEG3QdCrkJAhyQSibWxbeHZ1+drcPrUqBBJQ2Okg06aixOBGQw/Z6il83alVolQJuvzSg7EyAiRMnMnFij2GjACQnJ/PVV1916nN2fLicJRQiRIgQA+So1dC9ftkmHkxLT43SkxCh61aVDyBcp8TnF3F3sKNLkoTD4ydcqyYjxhDQ1B3UVVVw7kmTufHaqxg+fDgXXHABDoeDjIwMHnjgASZMmMD6pT9SuGUNx08/jvHjx3PhhRdis8llWjdu3Mixxx7LmDFjmDx5MlarlRUrVjB79mwAfv31V8aOHcvYsWMZN24cVquV0tJSRo0aBcjrql5zzTWMGTOaCePHs3z5cgDmzZvHeeedx2mnnUZ2djZ//vOfD+nzDREixNHHkauh//wg1O7sdbdOFMnyBqIt+jF7REoSGo8fKXk0nP0cAE6vXPXPEKgjMijWICf/eAzk5+Xx/nvvMW3aNK699lpef/11AGJiYtiyZQuNjY2cd955LFmyBIPBwD/+8Q9efPFFHnzwQebOncvnn3/OpEmTaG1tJSysc6z2888/z2uvvca0adOw2WzodJ2r47322msIgsDOnTvZt28fs2bNIj8/H4Bt27axdetWtFotOTk53HHHHaSlhbIeQ4QIIXPUaujB4JSBhFgrBAGF0K7VA9jdcqq8IZCRGa5VkWQKQ6kQSEtLY9q0aQBcfvnlrF69GoC5c+cCsG7dOvbs2cO0adMYO3YsH374IWVlZeTl5ZGUlMSkSZMAiIiIQKXqPGZOmzaNe+65h5dffhmz2dxt/+rVq7n88ssBGDZsGIMGDWoT6CeffDImkwmdTseIESMoKysb8PMKESLEfz9HroZ++t/73N3Q4sTs9DAyeWDF5C0WJ41WDzk+EY1KgSMQv67uIcqka3JN8L3BIBfzlySJmTNn8umnn3Zqt3Nn7zOKIA8++CBnnnkmP/30E9OmTeOXX37ppqX3hlbbHvGiVCrx+Q4svj5EiBD/nRy1GnrQCTpQ5OxOiSa7vNq43e1v0867Ul5eztq1conWTz75hOOOO67T/mOOOYY1a9ZQWFgIgN1uJz8/n5ycHGpqati4cSMAVqu1m9AtKioiNzeXBx54gEmTJrFv375O+6dPn95Wdz0/P5/y8nJycnIGfJ8hQoT43+WoFeg+UUK1H6nnGpUcM95s9+Dy+vGJInptzyGBOTk5vPbaawwfPpyWlhZuueWWTvvj4uKYN28el1xyCaNHj2bq1Kns27cPjUbD559/zh133MGYMWOYOXMmLper07H/+te/GDVqFKNHj0atVnP66ad32n/rrbciiiK5ubnMnTuXefPmddLMQ4QIEaI3jtryuXtrWgnXqkiL1vffOIDd7aOowYZeo8Lh8TE0wdgtzru0tJTZs2eza9euAZ83xMHnSKiNHyLEkUhf5XOPSg09mCWqVu5foLZeoyRMrcTh8aFSKND2YD8PESJEiKOVo1Ki+UQJCWm/a5wLgkBMIINUr1H2WFkwIyMjpJ2HCBHiqOToFOgdkor2l8gwNXqNisj9WB08RIgQIY4GjtywxT7w+tvT/vcXhUJgSHz4we5SiBAhQhx2jkoNPZggFFxXM0SIECFCHK0CPVCYS3UAGnqIECFC/LdyVAp0n19EpVQMqHRtiBAhQvyvcNQJdNHjQWm3oT5E61m+/PLLDB8+nPPPP5+pU6ei1Wp5/vnnD8m1QoQIEeJgctQ5RUWLhUhzPZ6EQYfk/K+//jpLlixBo9FQVlbGN998c0iu0xc+n69b0a4QIUKE6I8jVmr8Y8M/2Ne8r9t2yedDcrvxlWjRqPev+8Oih/HA5Ad63X/zzTdTXFzM6aefzrXXXsvdd9/Njz/+2O957XY7F110EZWVlfj9fh599FHmzp3Lxo0bueuuu7Db7Wi1WpYuXYpareaWW25h06ZNqFQqXnzxRU488UTmzZvH119/jc1mw+/389NPP3HHHXewa9cuvF4vTzzxBOecc85+3W+IECH+tzhiBXqvBJeDOwSnfvPNN1m4cCHLly8nNjZ2wMctXLiQ5OTkNuFvsVjweDw91kZ/6aWXeq13vmXLFnbs2EF0dDQPP/wwJ510Eu+//z5ms5nJkydzyimntFV8DBEiRIiuHLECvTdN2m13IpYU4YlLxJQwcKF7KMnNzeXee+/lgQceYPbs2UyfPp2dO3d2q40Ocr3zO+64A+he73zmzJlER0cDsGjRIr777rs2+73L5aK8vDxU3yREiBC9csQK9N7wKRQoAKUk9tv2j2Lo0KFs2bKFn376iUceeYSTTz6Zc889d7/P01H7liSJ+fPnh0rnhggRYsAcdVEuPklAQkAp+g93V9qorq5Gr9dz+eWXc//997Nly5Zea6MPtN75qaeeyiuvvEKwGubWrVv/uBsKESLEUcmANHRBEE4DXgKUwLuSJP29y/504EMgMtDmQUmSfjq4XZXxihIKhQKN/8BX65F8PlD2XJwrSG1tLRMnTqS1tRWFQsG//vUv9uzZ02Y66cjOnTu5//77USgUqNVq3njjjU610Z1OJ2FhYSxZsoRbb72VW265hdzcXFQqVa/1zh999FH+9Kc/MXr0aERRJDMzkx9++OGA7zlEiBD//fRbD10QBCWQD8wEKoGNwCWSJO3p0OZtYKskSW8IgjAC+EmSpIy+znug9dBbnV4oL0WrVaPN6PMSPSK63biLilDFxaGOi9vv40P8MYTqoYcI0TO/tx76ZKBQkqRiSZI8wGdA1/g5CQiqriag+kA72x8RYWp0Oi14vft9rCRJeKuqQBQRbbZD0LsQIUKEOHwMxOSSAlR0eF8JTOnS5glgkSAIdwAG4JSeTiQIwo3AjQDp6en729d21Cokh32/D/O3tCA6HAgaDaLDiSSKCPtR4KupqYmTTz652/alS5cSExOz3/0JESJEiIPJwYpyuQSYJ0nSC4IgTAX+LQjCKEnqHIoiSdLbwNsgm1wO9GKCSoXk9++XQBa9Xny1tSgMBlTR0XgqKhBdLpT6gS9hFxMTw7Zt2w6w1yFChAhxaBmINKwC0jq8Tw1s68h1wBcAkiStBXTAIQsSFwJp8ZJv4I5RX10dkiShTk5GEQgPFO37r+WHCBEixJHKQAT6RiBbEIRMQRA0wMXAd13alAMnAwiCMBxZoDcczI52JCjQ2Q+BLtrtKCMiUGi1CCoVglaL6HAcoh6GCBEixB9PvwJdkiQfcDvwC7AX+EKSpN2CIDwpCMLZgWb3AjcIgrAd+BS4WuovfOZ3IKjk5eMGqqFLfj+S14ug07VtU+j1SHYHh7CbIUKECPGHMiAbeiCm/Kcu2x7r8P8eYNrB7VofqPfP5CK6XAAoOgp0gwF/SwuSy4UQFnbw+9iBefPmsWnTJl599VWeeOIJwsPDue+++w7pNUOECPG/x1GXKQogKJUASN4Bauhut3xchwQeRcAZKtpls4vfbsdbV4cktvtxJUlCFI+cEgMhQoQI0RdHp0BXKBCUqoGbXFwu+Ri1um2bQqNBUKsRHXb8Nhue0lJ8DQ0UrFtHTk4OV155JaNGjeKpp55i0qRJjB49mscff1w+nygy7/33GT16NGPGjOGKK64A4Pvvv2fKlCmMGzeOU045hbq6ugO+R8nrRfIfOeUNQoQIceRzxBbnqn3mGdx7u9dDDyI6naAQUGh1vbZpaxswuYSNG0viww+3bVcYDIitrfhtNgSNBmVEBGJVFQUFBcybNw+r1cpXX33Fhg0bkCSJs88+m5UrVxLh9/PXJ5/kt40biYuLo7m5GYDjjjuOdevWIQgC7777Ls8++ywvvPDCft+7JEm4i4tR6PVo0tL6PyBEiBAhOIIFer8IAgzAoSkBiCL0sAKQQq/HbzYjaDRoMzIQ1GqUMTGkJyczLiaGh959j19+Wci4MWNAocBms5Gfl0draSnnzppFTCD8MVjytrKykrlz51JTU4PH4yEzM/OAbk10OJC8XvytrUg+X3tUT4gQIUL0wRErKTpq0j3hqaxEtNvRBSoV+m02JI9H3qlQoDSZEAQB0evFnZeHOikJVZdsTqXJhOTxoIyObjPHqGJiCDcaUeh0SAqB+2+4gRsuvQzNkMEIgoCvpYWXn30WkAWvokNi0h133ME999zD2WefzYoVK3jiiSd67b/fZpNDKDuYgYKIra2APGD5zWZU+7HYRogQIf53OSpt6BDIFvX5kCQJyefDU1qGt7pa/qusxG82A7L9HOgUsth2DqUSdWIiCo2mfZsggFKJJj2dMy68kI++/57WlmZEq5WqqipqCgo44bjjWLB4MQ2Vcn5V0ORisVhISUkB4MMPP+y175LXi6e0FFd+Ad7a2k6+AEmS8Le2ojSGowgLw9fSEgqtDBEixIA4qgU6kgR+P36rFZDQZGSgzclB0Gjxt7QA7QJd0UOJ2v6YNWsWl15+OSdefgVjJk3igvPPp7WpidGTJ/PgXXdxyoUXMGbMGO655x4AnnjiCS688EImTJjQ5xJ2wZmE0hiOr7ERd0EBYiASR3K5kLxeFBERKKOikNxuJKdzv/t+qPC1tHTqb4gQIY4c+i2fe6g40PK5QfwWC56KCrRDhuCrq0N0udAOHSqbRRoa8NbVoc3OxtfQgGizoxt24Cv/+Jqb8VZXo9DrER1OdDlD8dtseKuq0A4Z0im+HWQN3G+xoIyKagux7Ii7tBTJ60WXnY3ocuEpLkHQ6dBkZuCrr8fX0Cj3VxBw5eWhNJnQBDT/A8Fvt4Pfj7KHWu77gySKuPPzZbu+Wo0mM7PT7OZgEiqfGyJEz/ze8rlHJsF6Lm43fpsNZURE24IVyshIQGhPHNLtv3beEWVkJIJKjehwoDSGI6jVvdaDkXw+3KWleGtr8VRUdIprB1koinY7yvBwQE52UiUmyOGTLS34W1tRGPRyeQKlUo68sVj6DGGURLFXs4zk9eItL8dbWfm7wyD9ZjOSz4c6MRFEEU9JKeIBlDEOESLEoeGoFejByA9fSwtIEooO2qegVqM0GvGbzYhudzcNer+vpVCgipUdqsqoqLZrBIV8ENmWX4rk8aKKjUW02fB2Eeqi3S73NyDQg+dUGAx4a2qR3O5OmrQyKgpJFNtMSF2RRBF3QQHu/Pwe7e3emtq2ypT+1tYDfgaSKOJraEARFoYyJgbNoEHg9+EpKUEKCfUQIY4IjnqBLtpsCCpVp2gTAGVUpOxslKROGaIHijImBk1GBgqjUb6+IKAw6BHtdtkx6/fjKStDdLvRpKejTkxEnZyM32rFW1XVJmhFmw0EoU3DD55LnZxMIMiy0+Ck0OtRGI146+sRg1E8HfC3tMgCVVDgrarCXViI32Jpc676Wy2o4uM7+RV6Q/L58NbV4W1o6DYw+C0WJK8XVVycfO96PepBg9oHsf0olHYguPLyqX7gAezr1h/wOZrefRfrsmUHsVchQhxZHLFhi/0hKJUICgWSKKLoYG4JojAa2yJhfq+GDrLQVXbQqiEQx26xILndeKurEV0uNGlpKI1yO1V0NJLfj6+uDoXRiCoyEtFmQ2EwdKvjrtBqUScnI7ndKDqEMgqCgDopCU9hId7qajSDBrXdqySK+Bob5QSkzEzE1la89fV4KirksMvAvatiYxEEAW9dnTxj0WrlsgYOJwQW2xadTvyNje2zCb8fVUICgiAgSRK+hkYUOl3bgAagNBjQpKfjKSvDU1qKJiPjgGPmJVGUncE9DL7u4mLKr7kGf3Mzlm+/Qz/1GBLuvx/diBEDPr+3upr6F15EnZ5G+Ikn9rmebIh2XHn5aAdnhXIhjhKOWg0daLOj9+TsEwRBdkoqFAdFQ++JoJbtKSlBdDjQpKZ264sqNlYOP6ypQXQ6Ed1ulIbwnk6HKipKtk93vY5GgyohAdFmw2+xtG3vqjUrTSa0Q4agTk2VBaTfjzo5BUGh6OxXkCR8dXV4SoplYVxWhq++HkV4ONohQ1BGReNrbMTX0IDfYsFdUIjkcbddpyPK8HA06emIbjfeAyx1IEkSnvJyeXbRxSzkKS+n/OprQKEg85sFxD/4AO59eZTfdNN+hXOaFywAScJbVo5j48YD6uf/Gt6qKkrmzKHu7/843F0JMUCOaoEedBx2NbcEUcXHo83O3q9l5vbr+lotglIpC87UVJQmU/c2goA6JQVJFPGUlQGgMPYs0PtCGR2NQq/HV1Mj28qDNm2drpM9XhAEVJGRaIcMQTt0KAq9XElS9iuE4zeb5UiaxkaUUVFos7Lkv+xsNOnpKHQ61MlJKCMj8QW0fUEATXp6j/cHoDQaUUZFyT6LA7Cn+y0W2XSmVOKpqJDDUCUJy/c/UHbFlUgeD+nvv4du2DBirr6a2Ftvxd8gDzgDQRJFLF8vIGz8eBTh4Vjmz9/vPgLY12+g7Kqr8dvaHeGSKFJxy60UnjKTwlNmUnTGmbjy8g7o/B0RnU4qbrqZls8+77et5PFQcettmL9e0Gubur/9nca339mvPtg3bARJouXjj3Fs3bpfx/4vIbpclF1zDbY1aw53V45uga6Ki0OdnNyrwBYEocdMzINF0PatSU9HFRnZa7ug2SOYxn8gM4bgwCCoNbKtPD8fyePpUWsG2ZGr6HLvyqgoJJ8PX0MDyshIefUmvV7+69Cn4LVU8fGoU1PRDBnSb8ijKjYWJPA3NrZtEz0eWdMP/Ik9xNNLPh++mhoUYXo5BFSrxVNejrehger770cZGUn6B++jGzq07Rjt4CwAPMXFA3p2jvXr8VZVEXXppUSceSatvywK5C7sH03vvINj/XrMn3/Wts26ZAm25cvRDM5CP2E8voYGGl55pdNxrvx8nNu379e1Gl55Fduvv1L7xBO0fP5Fn22ty5ZjW7aMmv/7P8zffNNtv7emhuaPPqLprbd6XdTFU1nVzT/h2LwJhcmEKimRmkce7dGHc6iwrVmDt/qQrTV/ULEuWoRj7Trqn33usCcBHtUCXWk09qo1/mF9MJnahN22bdv46af2svErVqzgt99+A+TB58bHHuObVasO2H6r0GrRDM5Ck54uz0zCwjo5UPs93mhEodXKwjwlpc9+CIKAOj4eVWTkgPqr0GhQRprwNctOWtHjwVNSgre2tu3PXVwix8QH2LdvH2PHjGHKeedR7nYhqFSy4zkwuKS8+AKZC75G1yUeXTN4MADuoqIB3bf5q/koTCaMM08h8oLzkVwuWn/8qf8DO+CtqcG+Zg2o1TR9MA/R5UKSJBrffBPNoEGkvf46yf/4B9FXXoltyVJcefmAHIVVfs21lF52Odblywd0LefOXTTPm4fpvPMwHD+D2ieewPLtt73f3/z5qBITMUw9hpqH/4/Wn3/uvD9gbhLtdlp/WdTjOaoffICKG2/sNPtwbtyEfsIEkp54Ak9REU1vvono8SB6PN3CcQ8mzu3bqbj+BhpeemlA7Q+3EDXP/xrUatx5ediWrzisfTmqBfqRRl8CXVAoUEZEoAqEPR4ogiCgjIiQTSRZWfs1OAiCgGbIEDSpqQM+ztcleqXr+46o4uJAEvHW1eEpLQVRRJuVhW74cDnpS6PGU1aG3+FA9HiY/+GHzDnpJDb9+ivZAQenoFKhGTwYdXw8EWec0ePsSxUfj8JgwFPUv4but1iwLl6MafZsFFotulGj0A4dink/zS5BoZj05JP4GxsxfzUf+6pVuPfsJebGG9oSyKKvuByFXk/T228DUP+PZ/FbLGgzM6m6865+p+WS10vNo4+iiokh4cEHSH3pJfRTplD90MPUPPoY3pqaTu29NTXYV6/GdO4cUl99lbDx46i6/884A4uZB81N+ilT0GRkYJ7/VbdrOjZuxLlpM5LHg33lr/J56+vxlJWhnziR8BkziDjrLBpff4O80WPIGz2G4rPOPmCfSZ/37/FQ88ijIEk4Nm7qt73fYqF49lk0vvnmgK/hra6m+pFHyJtyTI/PFMBvs1N4ykzKr78B585dvZ7LU16OY/16Ym+6CXVqKo1vvXlYB5gj1nW96ot8GitsB/WcsWnhTL9oaJ9tSktLOe200zjmmGP47bffmDRpEtdccw2PP/449fX1fPzxxwDcdddduFwuwsLC+OCDD8jMzOSxxx7D6XSyevVqLrnkEt58802USiX/+c9/eCUwDV+5ciUvvvgitbW1PPvss1xwwQUAPPfcc3zxxRe43W7OPfdc/vKXv/Dcc8+h1Wq58847ufvuu9m+fTvLli1j2bJlvPfee3z00Udcd911bNq0CUEQuPbaa7n77rt7vK/CwkJuvvlmGhoaUCqVfPnll2RlZfHnP/+Zn3/+GUEQeOSRR5g7dy4rVqzg0UcfJSoqin379vH22293er93714eeOABFi5ciEKh4IYbbuCOO+5g+erV3HvXXfjcbibk5vLme++h0OvZvHkz99xzDzarlWiDgbeefprte/bw8jvvoFKrWblrF8s7aK/9DTaCIKAZPBj3AEwu5gULkDweIi84v+3YyAvOp+6Zv2FdvhzjiScCsiC1fPc9ktdL5NyLOvVBEkUs879Gf8wxRJ47B/P8r2h6913UCQmokpMwnXVWW1tlZCRRl15C0/sfEDZ+HJZvviHmppuIueZqyq6+hsrbbifizJ4HKgBvbR3ufftIffWVtplf2uuvUf/iPzF//jmWb74h+qoribv7bgSlEss334AkEXneeSj0etLeeIPis8+h5tFHyZw/H8eWLXgrK4m76y68tTU0vPAi7pIStB0qgTa++RbKQOG61kWLiTjjDJybNwOgnyQnJCY+/jhhubmITieSz0vz+x9QfvU1DPr3R92Kx3nr6jDPn0/sjTf2Gx3jqazC8vV8Is8/H3VKCo3vvIO7oADD8TOw/7oSb1UV6j6ypOueew5PURENr7yKYfp0wkaO7LWtr6GBxrfexvy57JcwTJuG5Ztv5Gd63bXE/+lPbW2tC39uqwlVeuGFGGfOJOmpJwPBBe2Yv/4aFAoiLzgfVVwctY8/jmPtWgzHHtupXetPP6GMjsFwzJQ+n8fv5YgV6IeTwsJCvvzyS95//30mTZrEJ598wurVq/nuu+945pln+Oijj1i1ahUqlYolS5bw8MMPM3/+fJ588sm2peYAnE5np+Xm3nvvPWpqali9ejX79u3j7LPP5oILLmDRokUUFBR0q7s+ffp0XnjhBe688042bdqE2+3G6/WyatUqZsyYwbZt26iqqmLXLlmDMAcKkvXEZZddxoMPPsi5556Ly+VCFEW+/vprtm3bxvbt22lsbGTSpEnMmDEDgC1btrBr1y4yMzNZsWJFp/dvvPEGpaWlbNu2DZVKRXNzMy6Xi6uvvprFP/9Mpl7P9Y88wlsffshtt93GHXfcwbfffktcXByffvwxf3n1Vd556SVurq7GaDId0HJ82qws2QTSAV9Li5wxHNCWbatW0/DCi+inTOlktjGdfTbN8z6k8pZbMRx7LOEnn0TzRx/hLSuXz9PcRNytt7a1d2zYgLeqirjADz72ppupuOEGfLW1JDz6CEKX8gfRV19N87//Q91TT6PJyCD21ltQaLWkv/8eVX+6G/uq1X3eW9SVV2A85ZS29wq9nsRH/o+Ya66m4dXXaHr3PXwtLSQ9+STmwEATrJuvNBpJfPwxKm++hca338FTWooiIgLjzFPwt7bS8K+XsHy9gPh75fpDzh07sK9ZQ/x99+KpqMTy/feILheOjZsQ9Pq256YMNxB95RVtfTIccwzl199A+bXXkf7hvE4zz6a33qLlk09RJycTOWdOn/da/49/YF28mMZ33sV09lm0fvc9EWecQcwN11Py60ocmzdj6kWg29etw/LVfCIvnot16VJ5EPvii26DiN9ioemdd2j+z8fygH3eecTecjPq5GS8VVXUPf88TW++Rfi0aegnTQJkM51m8GAyPv9M9j+88Sbl199A+gfvowyE7kp+P5YF32A4bhrqxERM586h8fXXaXzzrU4CXZ51PYYqNpashT8f0pDZI1ag96dJH0oyMzPJzc0FYOTIkZx88skIgkBubi6lpaVYLBauuuoqCgoK5Pju/YjsmDNnDgqFghEjRrStaLRo0SIWLVrEuHHjALDZbBQUFHDllVeyefNmWltb0Wq1jB8/nk2bNrFq1SpefvllkpKSKC4u5o477uDMM89k1qxZPV7TGqgUee655wKgC8TlB2cSSqWShIQEjj/+eDZu3EhERASTJ0/uVM+94/slS5Zw8803owr8cKKjo9m+fTuZmZkMGzUKgKuvu47XXnuNU045hV27djFz5kwA/H4/SUlJaJKTe6xzM1A0g7OwfPMNfqsVpdGIt66Oopmz0AxKJ/aOO1BGRFB5++1ohgwh9eXOtlhlZCRZP/1Iyyef0vTOO9h/+w1tTg6pr72KddFiGl9+BYVWR8x11wIBG3xAKAIYjpuGLjcXb20Nkeef361vqthYIudeRMtH/ybpqSfbfAKq6GgGfdR7Fc7+UKekkPy3Z1AnJdH4+ut4K6sC2vedndoZTziBiDPPpPGtt9pmJAqdDoVOR/iMGVi++Ya4u+5EUKlofPMtFCYTkRdfgnP7Nsyff479t99wbN6MfuzYXjVs/YQJpL3+GhU33UztY4+T+srLgBzxYfnhRwCa3n4H01ln9fo5uwsKsC5eTOTFc0GUMH/9NUqDgYT/exhlZCQKoxHHps2Yzj6727Gi00nNY4+jHpROwoMPYph6LFV33UXzvHnEXH99p7ZV992PffVqImbPJu722+Qs547P9JlnKNywkcY33yJ90iTcRUU4t20j/v77UYaHE3frreiGDafyzjupuPEm0t99B4XBgH3NGnx1dSQESn0rNBpirr2Gur/9HdeePW15Es7t2xHtdjx2O87Nm9FP7LEMy0HhiBXohxNtx7VHFYq29wqFAp/Px6OPPsqJJ57IggULKC0t5YQTTjigcwdtbZIk8dBDD3HTTTd1a5+Zmcm8efM49thjGT16NMuXL6ewsJDhw4cjCALbt2/nl19+4c033+SLL77g/fffP8C77oyhQyZrT+8HiiRJjBw5krVr1x6MbrWhDThGPUVFhI0di33VKiSPB9HuoOrOu+Q22UNIf/+9Hh3nCp2OmGuvIfKii/AUFaLLzUVQKAg//nhEj5v6557DumgRqFS4duwg8sIL2hLUBEEg7fXXEF2uXpPWEu6/n6i5c9v6eTCJveN2RLeL5vfeR2E0YgwMlp2u//BD2Fevxm+xYOow6ERecD6Vy5dTetFcBJ0O55YtxN5+O8pwA4bJk1GYTJi//Ap3fj4Rd97RZz8MU6cSc/31NL7+Ou6CArTZ2VgXL0FsbSVy7lzMn3+OdfFiIk47rcfjG99+B0GvJ+6uu1BFRRF7041Ifn/bugX68eNxbOpuR/fW1VP3t7/hLS8n/cMPUeh0RJw6i9aZp9DwyqsYTzsdTaqs1fttduxr1xJ97TUk3H9/j/1QhIURffVVNLzwIs6dO2n9eSGoVJjmnNPWxnjSiaQ8/zxV99xD8bnnoYqLw1tVhTI6GuOJJ7S1izj7bOqefY7WRYvaBLpt9WpQKlHodJi/mn9IBXrIKXoAdKx7Pm/evLbtRqMRa4dwuK7ve+PUU0/l/fffx2aTfQZVVVXU19cDMH36dJ5//nlmzJjB9OnTefPNNxk3bhyCINDY2Igoipx//vk8/fTTbNmypcfzG41GUlNT+SYQ0uZ2u3E4HEyfPp3PP/8cv99PQ0MDK1euZPLkyf32d+bMmbz11lttDtLm5mZycnIoLS2lsLAQgH//+98cf/zx5OTk0NDQ0CbQvV4vu3fv7vca/aHNkkMX3QHHqG3NGlTx8Qxe9AtJf/8bEbNnk/7++/06oZXhBsLGjGmzaQsqFSnPPkv0VVcihIUhqNXojzmG6Kuu6nScKi6uz+UBBbX6kAhzkAeU+PvuI/6+e0l4+OEeBxVVTAzJz/6D6Kuv7mRXDp8xA9M5Z8vZ1RoNxpmntJlSBLUa44knYlu+HCRpQIIn6orLEfR6Gt+SncDm+fNRp6aS+OgjaDIzaXzzrTbFxbl7d1sooqe8nNYffyRq7ty2z0idkoImPb3t3GETJ+ApLsbX1ATIwrnu2ecomjUL65IlxN5xO4Yp7d/XhAcfRHK7af3h+7Ztjg0bwOcjfPr0vu/jkktQmEw0vPoqlm+/xXjiCd0WxIk47VRS/vVPNKkpcrXRjAzi7723k8lNFRWFfvIkrIsWt22zr15D2OjRgZDZX/DbDq5vsCMhDf0A+POf/8xVV13F008/zZlnntm2/cQTT+Tvf/87Y8eO5aGHHuKss87iggsu4Ntvv21zivbErFmz2Lt3L1OnTgUgPDyc//znP8THxzN9+nT++te/MnXqVAwGAzqdjumBL2dVVRXXXHMNYiCE7G9/+1uv1/j3v//NTTfdxGOPPYZarebLL7/k3HPPZe3atYwZMwZBEHj22WdJTExk377e13IFuP7668nPz2f06NGo1WpuuOEGbr/9dj744AMuvPBCfD4fkyZN4uabb0aj0fDVV19x5513YrFY8Pl8/OlPf2JkH86rgaBOTUXQaHAXFyH5/dh/W4vxpJMQVCoi58zp13bbF4JaTcJDD/2u/h1qBEHoZlroSvjxxxN+/PGdj1OrSf5H75mfxlkzsXzzDYJajW706H77oYqKIuqSi2n+YB6mc+fgWLeO2DvvQFCpiLnxRmoeeoimt97GvnYtjvXrQa0m8oLz5aUfVSqir7m613MHBxTH5s1EzJpF7WOP0frzz5jOPovY22/vNqCqU1IIGzMG66LFxN58MwD21asRwsIIGz++z/tQhocTfcUVNAb8X6bzzuuxXcSsWUT0YtoMYpw5k7onn8JdVIQyOhrX7t3E3n4b4dOnY/7iC1p//ImouRf1eY4DRpKkw/I3YcIEqSt79uzpti3E/yYD+S4UnXW2VH7jTZJj2zZpT84wyfzDD39Az/678Tud0t5x46WSSy8b8DHe+nppb+5oad+EidKeYcMlT3W1JEmSJHo8UsFJJ0t7coZJecdOkxrf/0Cqfuxxac/IUdKenGFSzV/+0ud5Rbdb2jtmrFTz179KrcuWSXtyhkn1r77a5zGN774r7ckZJrkrKiVJkqTCWadKZTfeOKD78LW0SPvGjZfyj5suiV7vgI7pCU9tnbQnZ5jU8MYbkvmHH6Q9OcMkx7ZtkiiKUtHss6Tiiy464HNLkiQBm6Re5GpIQw9x1KIZnIVr1245tlsQuoWKhdh/FDodyX//G6rYuAEfo4qLI/KCC2j55BMM06ejTkoCArOB557FtWu37JgNlOiIuf46LN99R9Qll/R5XkGjIWzMGOyr12BdtBhtdjaxN9zQ5zHGmTOpf+55rIsXY5x5Cp6yMqIuu2xA96GMjCT5+ecRNJrfVYxMnRBP2Nixsh192HAUJhO6UaMQBAHT+edR//d/tPkcDjYhG/p/Gbfddhtjx47t9PfBBx8c7m4dErRZg/FWVmJbugzdyJG/O2krhEzErFnox4/br2Nirr8OVWIi0Vde2Wm7fvx4oq+8olO9JU1aGnG33YYqOrrf8+onTpTt6HV1JD39VLcQ0a5o0tPRDhuGdfFi7KvlsFbDcccN+D6MJ51I+HHTBty+1/PMnIl7z16sixdjmDq1LdLHdM45CBoN9kNUIC6kof+X8dprrx3uLvxhaAdngSTh2r2bmB4ihEL8caiTk8leMbDSBvtDMC48+sorCBszZkDHGGeeQuOrr4EkoUpOQpOZcdD71W8fZs2k/rnnEK3WTgOEKiqKIb+uOGTKR0hDD3HUoukQRXIwtKoQRx76KZNJefkl4gILsQ+EiFmzQJJwbt1K+LTjDkvte01aGtpAUpZhWufv5qGcSYYEeoijFk1GBigUKPT6AWtvIY4uBEEgYtasHhc+6Q3NkCHyd4PuwvSPJOa66zBdcH6bTwHA6XNy1oKzWFiy8JBcMyTQQxy1KLRatEOGYJg+vV/baoj/HQRBIOKM0xG0WgxTjzls/TDNPpPkp5/utC2vOY/S1lI0ykPzfQ3Z0EMc1aS9+85BWWIwxH8XMTffjOncc/e7vLbVY0UhKDCoDywzuj92Ne5mdPWJpPmGHJLzhzT0DpjNZl5//fX9Pu6MM87oszBWb1x99dV89VX3cqYhBo46Pr7fxTdCHFlYPVbuWXEPFa0Vh+waCo2mz0ze3rhnxT08uubRQ9AjmfySYo4tm4OnsLX/xgdASKB3oDeB3lcNcICffvqJyD5WLAoR4r+dVk8rVy+8mp0NO/ttu6h0EYvLFrOqatUh609BSwFP/PYEr2x9ha/yvxrQ4CFJErsbd1NkHtjCKQdCQ4ksyBOlnst0/F6OWJPL8nlvU182sCXGBkr8oCxOvPrGXvc/+OCDFBUVMXbsWNRqNTqdrq0GeH5+PnPmzKGiogKXy8Vdd93FjTfK58rIyGDTpk3YbDZOP/10jjvuOH777TdSUlL49ttvCQsL67dvS5cu5b777mtLm3/jjTfQarU8+OCDfPfdd6hUKmbNmsXzzz/Pl19+yV/+8heUSiUmk4mVK1cetGcUIsSBsLh0MZvrNvPB7g948YQX+2z7c/HPpJpzqDBXDujcPtGHSrF/ompB4QLmF8xHISgQJZFMUybfnvNtnxEvTa4mBpdOQqE+NHquw+tAaAgHhZOotNj+DzgAQhp6B/7+978zePBgtm3bxnPPPceWLVt46aWXyM+XlxN7//332bx5M5s2beLll1+mKVA0qCMFBQXcdttt7N69m8jISOYPYGWcYC3xzz//nJ07d+Lz+XjjjTdoampiwYIF7N69mx07dvDII48A8OSTT/LLL7+wfft2vvvuu4P7EEKEOAB+Lv6ZjOZcVpaupsnZ/XcRpMHRQGV+C7P33krr3v5X9qm0VjLl4ylsq9+2X/0pNhczJmwiy2at5s9DHqGiuYrtDX2v61psLmZk7Qwya8di8xz8Alp7m/cSb8vAoClCYUo46OeHI1hD70uT/qPoWhP85ZdfZsECeWX1iooKCgoKiOlSkS0zM5OxY8cCMGHCBEpLS/u9Tl5eHpmZmQwNLIR81VVX8dprr3H77bej0+m47rrrmD17NrNnzwZg2rRpXH311Vx00UWc10sRoRD/mzQ6G3l5y8vcNf4uYsJi+j/gINDgaKAiv5mz825nc8ov/FD8A1eNvKrHtovKFpHdIBfdcjX22KQTuxp34RE9bKrbxNj4sQPv1K4opubN5LNlG4E4zo64jW+GfdPnOYrqSzF6YlGLGuocdYRrwgd+vYF0qWYP0Y5k0g0bILx7Hf2DQUhD74OONcBXrFjBkiVLWLt2Ldu3b2fcuHG4XK5ux3Ssd65UKvu1v/eFSqViw4YNXHDBBfzwww+cFqgr/eabb/L0009TUVHBhAkTepwphPjf5Lfq31hQuICn1z3d49qWVo+Vk784mZ9Lfu7h6APjl9JfyGmQy9iObpjBN/u+7XVdzV8KFzGkRS4rIFi0iFLfi00XNRczseI0CuoGbn51+pzomqJAaeGUy9IZdXwK8a0ZbNi5A6fP2etxFWXygjM6n4Gqlu7rjO4vkiTh8Xva3hcVVqKUlGSq8iE8/nefvycGJNAFQThNEIQ8QRAKBUF4sJc2FwmCsEcQhN2CIHxycLv5x9BX/XKLxUJUVBR6vZ59+/axbt26g3bd3mqJ22w2LBYLZ5xxBv/85z/Zvl2eMhYVFTFlyhSefPJJ4uLiqKg4dNECIY4uyipqmLPzT2zM284vZb9027+yciX1znq+yu8cXVXQUsAvpd3bD4RfCpYwpHkcManhqD1hKIujezRvVNmqaM0XUfk0CGEiRmcMDY6GPs9dW2BlYuXp2PYNXPcsay0jypGEXltMTvh6ppydhUIFmVXjWFK2pNfjmmscbf/X1A5g+tAHFreF6xddz1kLzsLutQPQUiErgAkRDaBU/67z90a/T0kQBCXwGnA6MAK4RBCEEV3aZAMPAdMkSRoJ/Ongd/XQExMTw7Rp0xg1ahT3d1nd5LTTTsPn8zF8+HAefPBBjjnm4CUs6HS6tlriubm5KBQKbr75ZqxWK7Nnz2b06NEcd9xxvPii7Gy6//77yc3NZdSoURx77LGMCWVJHhS21G1hUemiw92N30VzoZtEWyZnlF/LM2v/1s2evbx4BWfvuoOavFYane1C66l1T/HQqofwigNfThGgwlqBM1+F0q/m+EtyiErWM6b2RObnd/cdLSxZSHbjRHQRSmIG1WFyxVFuKe/z/LbaQH8atHj9A+tbcUsJUc4E4pTlsPd7dAY1QyclMrRpEt/v/bHX4zwdxpam+gMPK6yyVXHlz1eypX4L1fZq3tnxDlaPFXVjBGjN6KMOrimnIwOxoU8GCiVJKgYQBOEz4BxgT4c2NwCvSZLUAiBJUv3B7ugfxSef9Dy50Gq1/Pxzz9PUoJ08Nja2bcFmoN/FjzuudnTyySezdevWTvuTkpLYsGFDt+O+/vrrPs8bYv+xuC3cveJuAGZl9L2AwZGMq1E2dZiak0mpHMEz65/hhRNeAMDtd1O5s5Xp1iH4qj0sLlvMJcMuIa85D/+2SE4130CxuZic6JwBX29hyUKG1U8hPFZF4k8zGTv2RVp+SmLh9u9pGN9AnF4uw+v1e/l57yKON9/AsClK/Pu+o1G8idKaKiYlT+rx3H7RD02yCTPankyxZWB9KymvQillkaEohaK14LYyakYq+9bW0rpboOqEKlLCOy88bffa0bWaQN0M3mham3s2zeS35PND0Q8kGhJJNaYyLn4cRo2xbX+NrYbLfrwMj+jhH+mvs6FoCx/teY9BEYOIt2YQaSgH46FxiMLATC4pQMc5fWVgW0eGAkMFQVgjCMI6QRB6XERQEIQbBUHYJAjCpoaGvqdaIUL8kby05SUSyoYxJH8qFrflcHenT0RJZE3VGu5cdifzds1r2y5JEgqzDn+sjZScKI6rOI81+evbIkTW16wns3YsAKmWYSzN+xWAL/Z8ybiqk0m15LCrsu/Vqrry6+61JFkHM2qkiNCUx9Cw1aj1CkZUT+PeX+9t06qf3fgsypIoFJKCnMQSBglyyGJNVe/+n2p7NVF2uQ5KjCOZvKb8AfWpvlL+/BLCLeB3Q8Ei4jOMmFK0jKibxk/F3RWzUksp0Y4kTGG7EQUfTnPPvq9P9n7CB7s/4G8b/sZtS2/jkdWPdNq/rGIZLouPPzU+T8GnTqI2DGdw0zj+tepVjJ4oBqvyITxxQPdxIBwsp6gKyAZOAC4B3hEEIbJrI0mS3pYkaaIkSRPj4gZeQP9o53+pRvnRyI6GHSzZtorpJReQW3M8JZaSw92lbtTZ61hStoR/bf4Xc76dw81LbmZ5xXK+zP+yrU2TqwmTPQ5dnIITL89BKak4qfxSXt7yMpIksXzvalIs2WSNi0UhKbDvVVJiKWHnxlLCfLKWWVxUNeA+1dpr0RTGgSCRkyg7LVUtexk9I430phFUFTXx3Kbn+LbwWz7b9znHWc8kOtlAjGczsSr5Oua63p2URc3FRDoTUKstqEUtReV9m2eC2Oq9SIhEDhsBhjjY+z2CIDDuhAx5YNhb1u2YgupiwnxGkhWF+NTNiK3KHs/dWGHjnNobeT3mc87hCvZWFXRyABcUl3Hx9odpzvdwzJwsEjIjOKH4YlLq5cqLGeKWQ6qhD8TkUgV0zKFNDWzrSCWwXpIkL1AiCEI+soA/NFXcjzL+l2qUH234RB9PrX2KU0ovRyEpUUhKCivK9i9ErgfMLjPbG7ZzfNrx/Tfuhx0NO7j8p8uRkFCjYbJmBhcJt2Ep8LFZsxLrbCtGjZGiulIM3khik5SY4vRMOWsw/q8l9u5ez9rctVRvtROLgmPPy6ahtpXsxgnc/+v95NTMRGNU4LGKNFYMPP76t6q1DG2cSEy2jnDnXnljQx5jr04nb0Mtc8pu44Owx/hS/SXntFyHotHAmCvSEPbsQK9owa/w4G7qPcqlqKQSpZREtnYpe7znUVtm7rdPftGP0KxD0jSgNkXDsDNhx5fgdZE9KYHln+3Bmx+GJEmdkozKy+pRkkmWUMJOdRNKW8+1XPR5KSRVj2RHSS1JTGRsZBh1jjoSDbLW3ZoHcX4dcx+dRFSigSET4vns6Q1MLZuDpBCJVRUedg19I5AtCEKmIAga4GKgazbLN8jaOYIgxCKbYA5ummeIEAfAV/lf8fhvj/e6/4NdH6DYG0OMJY1h0+QfWmX57zcHfpb3Gbcvu51SS+nvPtfSvF85bd8N/CnvFa5f/zy5v55F61o1SmsYw+qPYW+TLExLy6oBSEuXQ+LGnJJGfKaRGSUX8eTSZ0irHoUuVcQUF0busekk2DJwFalJbs1m/MkZ+MNdiA2afkMJg2zctQOjO4Yxx2RCQ568sakQnQ5mXTsSpU3HubW3MNY2naS8XIYfm8TwKXFQtxtBACmsCVp7L4tbX2EGIFe7Cknw4artv0819hpMjnjC1BWgj4XhZ4PXDkXL0OhUaJL9RJlTqLR2zlJtrpYjUeJV5WiVDehdJhxeR6c2Hr8HrdUISQ5u+OcM4sdqSGodzK6G3YDso1DXRyBFuYhKlAcEU5ye4y/JQSEpiEtUoRK8YDyMAl2SJB9wO/ALsBf4QpKk3YIgPCkIwtmBZr8ATYIg7AGWA/dLkhQKjg5x2Pllx3K2bc/rcd+Gmg18sP7fHFd5LqnDoph2nrzGo7nG0WP7/aGyoImZ+VezpGTp7z5X+SYzg1pGkpIRw7hZ6ZxyzQiuefY4xs5OweA1saekAIDaqhYAsjJTAVAoBE65agQaScex2y4mypXA+OnyoiDZExMAiZMKLwOFxPBjk9EnKoi0JnYTdj3hE32Y9/mRBJHM0XHQmA9qPYheaC4haUgkk2ZnEl2RyeTd55KQGcGMS4YitBSDTw7f0+oaMNijaPX0HFFiq/UjKnxEq8pRhjejt0T3698obCoi0hknR7gYYiFjOuhMsPd7ANKGxhBrT2Fb1Y5Ox7kbJHwaJ2EKC+HKegxeE9WtnUeQSlslJmc84fFqNGEqRowdhEbUsSdPrv2S35RPvHUQkemdB6mcKYlMPDOD8eMCdvnDKdABJEn6SZKkoZIkDZYk6a+BbY9JkvRd4H9JkqR7JEkaIUlSriRJnx2yHocIMUD8op+orTlM23NRt5C3BkcDDy37P2YX3IJG0HLCZTnoDGp8Oheept+/wo2vwMDgpnFs21T4u85T76gnvDIZIc7NaTfmMnXOYHKmJBJm1DBkmBybUFEg607WOg9+hY+ouPawuKhEA8ecnUWMIxlR6WfkZNl6Gh6lJXFoBFq/nqxxcegjNCRlRBHpimd3zd5++7WrcRfJDcMISwOdygHWGsieKe9skB2rE07PICUnkrBwNafdmItKrYTaQPGu6MFEquowuqMpa+luG5ckCaFZh2hoRiGIRBrqibGnkNcsD85b67eyvmZ9t+OKy6pQoGSQshT0MaDSQNaJULoagBGjMhFQsG9P+zW9ohe1xYjCaEEQIEYpB+lV1nYW6KV1FYT5wolLkkvyDsqRZ0J1RbKZamdhPjq/gaycwIIWxStg5fMIgsCUs7LITgkkK4Uf3iiXECGOWF7Z+gpf5H3R474SSwmxrWnovRE0O1ratouSyJ9XPMDkXecSaUvgtBtzMcXJixgrYnyoLeFt8dgWt4UbFt3A7qbdA+6TX/SjaZadjLqiBGrtPdsK6ux1vWZUBlm59zcSbZlkjeseRBCdbMCv8uKolM/hb1biNdpQKDoPSONmZpAywkTujFQ0Ye1us1HHypr8mBNkIZ+TPQiA/ML+nY9rdm8k2plI7qRB0CjPEBh2lvwaEOgKhcDZd47l0r8cQ3hUQGut3QFKDaRPJVEoQ4GCkoruM4JmVzMmWwJh4fJgNUgjC9O8iiIqrZXcsuQWHlvzWLfj6irlzzlNUSabXADSJoOlHKy1JA+OQhT8NJe0Z3lXtFYQ5UgkwignFSYiZ4zW1nY2MlSUy9vT02WBHB6lxRfuRKzWIkkS5QWyqW74CPk5suoFWP5X8ARmfNbA9yAk0I9MwsN7TxAoLS1l1KhRf2Bv/jf5uuBrnt/0PGaXudu+naX7MHhNCCiob27/cZa2lqJfl0VqyzCOvySHQaPaa55EJGiIdCRQ2SoLmVVVq8gvLOeJVX/BJw6sjENlayVR9iQkhUi6eSRL9q3otL+8tZzblt7GzC9n8Ze1f+kzYWb3JjlieMq04d32KRQCyiQ3+qYYHF4HutYIVDH+HtvNuXMCJ8ztfI6hUxK5+LHJJGfLa1wmZciv9eX9J9WUbW8GYMTENNncApA8DiLT2wQ6gEKpQKPrEHtRuxPihoExkUyfPBDUVDV3O39eVSF6r5E4vSwkM5DPWVZcx4MrH2TS3rPJ3n58t8HSVutFFPxEqqpBHy1vTA3EuVduQq1RQrwTdZ2pLS2/oKIUjV9HosEMQJogn7OlobODuLFGFvhp6e0C2ZAmEGNOo9pWjb1SwqdxEZmgB7cNytaCJELd7mDnQBcJ6kO3IEtIoIc4avGJPnS10egt0fx777+77S/Kbw/Gamxq19CrqhoYUX8s8ceoGDm9c0pFYmoUGlFHQYUcurhpx24u2vEAKRsn8dm+zwfUr31lxWhEHSnH6FFKSnavk4WyKIm8vu11LvviKjQrB3HjhuepWOri+oU30OzqLtR8og+xKBxvlI2ohJ6jLuIyw4l2JLN87yrC3dFEJAxAWNibQBQRBIGY5HalxGDS4g9z46nrWyyYXWbCKuIhzkl4lE52iCo1EJUhC+uGnn0WSBLU7IDE0aCPIVEhD5rmOlmD/bbwW97d+S6SJFFcLDt4s9TyZxjr3YqERHFRNb6dEQxrOIahjRPZXNk5GU9s1iDqLSgFn2xDB/l6CjVUykF3sVkGYm1p7KqVcyMLi+UZSba2HlQ6ohRNiIjYWtydzm2r9+JX+IiIbi+HPWhYHGG+cDbt24muIQoh0S1Hz5Sukv0JALWBMgjWWjAmcSg5Yqstmr8vwhPwPB8sNMkGIs8a3Ov+Bx98kLS0NG677TYAnnjiCVQqFcuXL6elpQWv18vTTz/NOeecs1/Xdblc3HLLLWzatAmVSsWLL77IiSeeyO7du7nmmmvweDyIosj8+fNJTk7moosuorKyEr/fz6OPPsrcuXN/133/t9LobOT4wktQSWq+MrzElSOuxKRtX3KspdxN8KfX3NJeo6exwQyoSR/VffX1wZmpFJJHeXkd0iiJpr0e4oDspgmsXrCcUzPasx97o7ykDohn7LRMqgo2E1aURLOzmVc3v0bZMgdzax9GKahIyjYh5M2i1lrCja238fnc/6BUtMc/byreTnzrIGKmd9e6gwwbOYiGlWVsWVlMNDkkpPazorzLAv/KhdP+BhO6V0TUJkgY6+JocPR+n6vy1hJvH0TGsbKZisZ8iB4MSpUs0It/Bb9Pft8RWx04GiExF/TRaBUOPBoHriaRBQULePPnf2PwRGBxWRAqYtFiIluQtXiNZEWMcJLZOIYodwIRcTpaG1zs2lHAmYHk0RZXC0ZbDLpIsyzAtYGVrNQ6SBoNlZsAGDEqg9Vry9ixK5+0qBR27ioil3RSFKUQMwRl3S48Wisec2dzmGhW4YtwIHQwaY0ZnU3+gi1sXpdHgiuX6MzALK5wCagN8jOo2dF+/4cwBh1CGnon5s6dyxdftNtjv/jiC6666ioWLFjAli1bWL58Offee2+/ds+uvPbaawiCwM6dO/n000+56qqrcLlcvPnmm9x1111s27aNTZs2kZqaysKFC0lOTmb79u3s2rWrrcJiiO7UtdYT7okkzGtkXP7pfLK3vWyDT/ShbAjHFybbSq3m9gQWc3MgRC2ue3nZ1EDIX2O1lfyWfOLrs9Ck+UibbCS34kTe+PzTfvvVXOFAFPykpycw9JgEYhzJPPTRM/gXpDG+eibDJqVw2ZPHMOfu8cy8dgRJzkFMWnsh5ZbORdY2/iY7J6fNGN3rtYblDEJERF0gC9/BKdHw26vtdtuu1O+Tw/hKfu1xd0J6BFHORHbX7elxP8DGdbIGfsyxI+UNDXkQJ5d+Jm6YnJ1p7p680+YQDQh0AMlow9+i5NNvfuasPbdycuGVVC9QUF9kxa2zoXdXQJg8SMUnKol2JmEwajn3ngmISh/mwnZz1c7aXUS4Y4gxtMgO0Y6LWaROguot4PcxbMQgJESqCsz8a9EbDK88joQRerSuCnmWISgQdVYka/uA5Bf9aK1GVNGdB9e4RBMerQNjfgYAOcPT5JlIwWLInAFJY2S/AYC17pDGoMMRrKH3pUkfKsaNG0d9fT3V1dU0NDQQFRVFYmIid999NytXrkShUFBVVUVdXR2JiQP/YFavXs0dd9wBwLBhwxg0aBD5+flMnTqVv/71r1RWVnLeeeeRnZ1Nbm4u9957Lw888ACzZ89m+vTph+p2j3qq6xoQUGBIUJFdN4EVKz/hihE2wjXhFDUXE2NNJmK0hGM7OCzt02dbixsFkBTffdUYnUGNR+vAWS+yZs9Gop3JDBufwLGzhvNG9Q9EbhjOxmO3MSlnbK/98jYocRlbUaoVTD9+DPt+XMHorWcgafycdtMoBo9rL506dHIiFdZK9n2pYHdBAZmTM9r2te4DjbGFtLTetTqNToUrqgVjSwyi4CfLkw+L/g9aSuDMF7of0BgwhwS01a5kZ6dTtbKQfYWlnJDZPSlqS9U29HtSINZFTJIRfG75WqMCdfnjhsmvDfsgpstvOCjYEkdBs5ymoo1wEluazvGtmaQMN5E2LAbpWxFBVOBMagBnMwyaBqWrGJ6qYU2hwKk35BIepUWR4iK8LhGrR06sWrJ5DQlMZpS2CTRdPtvUSbD+TajfjTZpDJ6oVjxlanRFQ1CFCZx5zXh4vQEyjgOdCaXYitrSbh6paa3F6IohPL5zyWxBEBAT7ejL4vALPkYNHyLfm7kMjr0DWkphw9vg88g29JCG3hlRFPG63f03PEAuvPBCvvrqKz7//HPmzp3Lxx9/TENDA5s3b2bbtm0kJCT0WAf9QLj00kv57rvvCAsL44wzzmDZsmUMHTqULVu2kJubyyOPPMKTTz55UK7130hDvRmAieemYUxWMSn/LD7c/DEAO/bloZI0DB2ZikfpxGVtd2i6LT48Khe6ME2P5xWiPCjNegq3y86x0ROzUCoVzL15OiDyyzebe+2TJElozSaUcbLmGBauIW6iCnWqhysendZJmAfJHSELvrKiurZtjZZmTM2JGIb2n+SjTZHbOAxm1M5AXbyN70JBD6Vig/ZtcxnYu5eITcuSNf3aUnOP9zb/sxUY3TGcftl4eWNTkez4iw3YPYKaegfHaBu1O2UNWGeSNWggO1qJUlKSMTGas24bx4RTMzj/vgkQ62TU2Hj53AlycMGorFqu/OtUkodEyn0dHk2kK54N+VuxeWw4tmoR1T6ywna1O0SDtDlGZTu6IV1BvHUQUc4EzrhuLGF6QR48wuNBZyJMayHMHYHDI8/sCsvKUaAgIbm7SSs2SzY9OSNb0GjVsrkFYMjJkDQW/B6oWC+/HmIN/agT6A5zC02V5YjiwLLZ9pe5c+fy2Wef8dVXX3HhhRdisViIj49HrVazfPlyysp6mEr2w/Tp0/n4Y1nQ5OfnU15eTk5ODsXFxWRlZXHnnXdyzjnnsGPHDqqrq9Hr9Vx++eXcf//9bNlyaBaT/W/A0iCbFVJS4jnz+vHoRAOFCy00OBooK5QF28jhWXh0Tny29um3zybg0fXun9HHKzHaY1GUReCPcmCKky3xcbFRqEfaiShNY3Pxjh6PraivQe+JICql3XF2ybUnceMjp7WFRnYlLjESr8qNubJdUdm0fTcCCoaMTO73OaQMkYWMFOmStUBBCXHD4dvbwNHF2dqYD8H1Oau6D0zGaB0+jRtvfXfRsHjbryQUjkA73EXW8IBgCmr8QUGuNUJEanfHqOiHys1twjkYUnhidjNn3DqaM64dg1IlXzMpK4rbnj6T044N3HuCbNpROmpkJ2yAiRPlqJ0928r4efsSBjXmkjYlHI2ruj1kMUhkOhji2+3ouRnytY7VkDkyHhyBKChDLOgiiVSZUUpKKmpl52xlhfx9ykjv7tQcPjIdAE1ywBxTuBSis+S/pIC5rCBQlvkQJhXBUSjQVYEVgXyeQ6Oljxw5EqvVSkpKCklJSVx22WVs2rSJ3NxcPvroI4YNG7bf57z11lsRRZHc3Fzmzp3LvHnz0Gq1fPHFF4waNYqxY8eya9currzySnbu3MnkyZMZO3Ysf/nLX9rWEQ3RHUeLD1EQMUWHEZMcTvbxMQypm8hbiz/CVunHo3VgitXj17mRHB2+6nYVot7T/YSNBVC+jvgUExpRR1LrEJJGdA5NnXPBDAQEflogL3Ai+kVWLtxFZYms7e7Nl6NjUjMHXnxOEAR8MVZoaBdWxfvqEPEzMXdkv8ePHiVnuIbFKwJ22ng4721ZSP14b5d7zIchp4Cg6Gx2cZqhsRBBEBBi3WhaTJ1KAPj8PtZ/VYao9HHR1R1MMQ35gAAx2e3b4nK6a+hbPpRjwUcFll7T6EEVhtrdQObo2E6OxjbsgRIMplRZq7fVddqdlBqNW2fDUuRj57JqECROOXO8fN/6Lv4RQZC19ICGPu3YMZx600jmXDZN3m8LzGwM8RAWSaxK/jyrauTtTbVyCGNWmBUWPwY7v4LmEpAkxg4bTsuIAo45eRh4XXKEy5BT5PPFDJEzaAsWy+8PsUA/Ym3ovaHWBAW6B40urJ/WB8bOnTvb/o+NjWXt2rU9trPZei9klJGR0VYbPbiARVcefPBBHnyw8wJQp556KqeeeuqBdPuIRZIkLGY7SqUCY0TPWuqB4DMLeMJsKJSysD7xnFzyNyzBvzIOjV+HIkEOIRP0PhRN7d8VlTMMf3SXFHJJgi+vAbeFjBPnU4UcUjd5aqe1XEhKjEUx1IaxIJ3v1y8i/4dWdA3RbNGXcuszp1FZ0gBEMGJo1n7diz5ZgWZbHFaHDaM+HFuFH19EI9HGyN4Pqt4KKh1DUobxy5krmDnhWFi2QE5cSRoNU2+FNS/D7Bdlx6LXCS1lMOYSsFR21tB/uBtKVsL9hYQnqaAmkZrWWlJMspb808qVRDelETfLT4SpQwhlYz5EpskCOkjcMNj0PogiKBTyLGHpUzDoOBh5boebjuk+g+hI0CRkiJVNFdbOy8IJgoAy3YmhKIFwSYEqx054hBJc5vaQxY6kToS8H8HRjEIfzZBxHezZwcHDEAc6E8lSDflAfb0c7ups9KPStaLb+QNseq/9uMk3oTnjWR658yb5ffGv4HXA4JPl9wqlPMMIDCSHMqkIjkINXaFSoVAq8B1CO3qIA8fr81JT10ir1YYkSYh+kcbaVjytIo4WL35/7yF4+4tg0+APb/8eaHQqjr8wh1h7KiZXLLEZsnatNIDGLQsc0S+idevRRHT56hevgLqdYKkie5Acm+7VOknP6q5pn33BNFSiitIPFCibwqnJ3oXaoef7T9fRWu3Bpm0hOXr/frgpGdEoJRU78vPw+fxomyJRJvUwiwhStxs+OAN+uh9BELj9rGsYkZwjm1yCQmPITECCisAiKU2F8vvYbEiZIAt0SZIF597v5ZBCay3Jgb7sLWqvr1e2pwGf4OWsM7o46RvzIHZol5sZDz4nfHOznGCz/BlZyJ7+j86RJ/rodlNHTziCAj1O1mytdd2apI+MRePXoRY1nHz2OHAG8g26aujQbkfvwdTUJtDD40EXySBfOT7BS/lmC36/iNSixh/hlGcJsUPhppVyBEtFl/IDTYGs2aQOq4h1/D9kcumMIAioNFq8h8jksr/s3LmzW63zKVOmHO5uHTYsrXaULg2uZpH6ylYaq62IHnBr7QgImFsGXp61PzR2AypTZ19K7pQMlKmy03rE8AwAtEYlKr8Gj9NLU3MrCpToTV3WdPztFflV8mMQzCgj/aSNjezRFJCWFo9pjARRbmbfN4r/u+sGilI3UbPejaLKiDvK0qk060AYPlzW6IsKq9iXX4JKVJM02NRzY2cLfHaZrAl2DQ+0doh1Tpkg28vLAzPMoF07NkfWVl1m2am57ZP2JJiGfWRnyzZhebYh46pWYItsJEzXIXHJ75NNLnFdzJAjz4MT/w92fAFvzZA12knXy9EtHdHH9C3Q7U3t7YyJ7anzHThm4ihE/FgSKxmaNahdq+9JoCePA4S+BbohFsIiCfc0EDbDgqE2gffe/R6dzYQmRpJNM8YkWUgnjZVnOh0xl8tJVh018cSAHV1jBE3PCWIHiyPO5NK1TnFPqDRanNbWAbU91OTm5rJt27bD2ocjCZ9LRFKIKAx+fA4QJAVEeEmJTKCmpgnJrsEfJaJU9q5LDCTO3+F0EuY1oojqPLALgsDFN57A2l/2tdmW9SYNHqCppZXGFnmKHxHVwURQuwuKlkL6VFn4tVZx7eMnolT33sfLbz6l03fv+POHs/cNM0ZPFJqE/ctTABiSms73qp24y+zskooBFbmjegjdFf0w/wZZkGSdIBedEv3y1N7vkwVTMJJCo5eFTllAoDfmy7bzmCHtmnLVJtjykWwDbyqAhjwyJx2PV7mTlko5wsPvFdE2m/AN6yK8WkrkmPOELnZ+hQKO/7NcQ2X+9bK554SHut+LIVYO6+sNR6NsO1eqZYFuq5VnFB2ee1JMAvpzmpgWDCPt6NzsijZcNg8Fa890xFYPSq2cjKSLBL+HG86fzTNVnxC5NQsNoIvXQX09pE6Wj4lMk/vocbSbnMwVEJEiP4O2TgYE+iHWzuEI09B1Oh1NTU39/qBVGg2SKOL37t+CtiEOLaIoIXiVoPGTEB1HdGI4YXEKkiITUAgK9BFqBAQs5u5aut8n4nH6kCSJpqYmdDodHpeP717eRtGW7kvUllfL9tSIWL38I+9AZLye068Y3yaQjZGy/byuoYmGRjMA0TER7QesfU12XJ0UcEBbKtGEqdqiLnqiqyJx1rAzKR27FhGR2Mz99+0oFApcUS346tXUFVmxapsZldFF8zWXw+dXQOFi2Xwx/GwQfe2aq70BkDrHOg+aKifUeF0Be/cgOXMybhhowuV7byqA4+6WBW/DPhRKBY6IZrz1ctZqSXENSklF7KAu2mWwRkl89zozgDzg3L4Rbl7dPYwQBqChN7ZHq4QnymF/QZNKB647/WLGZwWEpqMPDR3kjNbmop6vZYiTBwudPDMSXBZuv+0iGmPkWVBSSrQs+MMDoacmeSbTSUu3VMiCviPxI+SZ0h8g0I8oDT01NZXKykr6W2/U7/Nib2mh3mpDrT10hW5C7B8etxe3zY+g92Nubo9xrkUWOJIkYbHYUIgqjJG6TuYMp9WDzyNiiNSiN4SRmprKzlUVVOxppjK/mbkJk4lJaY84qa6Rzx9b/jX88huc9kyv/YqKNNKESHNzKy2BEgDxcQEB01oNO7+EidfKGYwArQNfhi2IQlBw45mXcqt0O6+NewWKlsGvz8GV38olXAeANlFCu9OE3+nBFVeNWhEwC4kirHwOVr8ICDDzSbm/wcgJSyWYUtqjQDrGOqdPlc1J1VsD5pFAvLhCKZsgSlfJWunIObD1321mGSHOg7YoBlGU2LunFIDsYV2WEq7fI2v8XU0uHQmLasv07IY+BtytctJNT8/I0diuaQeFobW258Gh7ZigmaYHDR3k2cmOL7pp+tjrITzgLwmLlF9dZkwRSVx02zQ+/e4nLs29AJY52s0pQcFtKW8P2zRXtEe4BFFp5cGt60zmEHBECXS1Wk1mZma/7XweDy9fdQFT5lzItLlX/AE9CzEQPnx1EY173Zz6eBbDe9Ha/r3yS1o/iSH1BC3nXCyHjNnNbua9vBokgeHTEznpskwkUWLj4iKa9LUYfEZ+enMHFz08GW2g/GtDnQVQkuTcCQU7ehfo9iZi1HYKCcNstmFtceIX1CTGBH7w698CyQ/H3CJrZhojWPZfoAOMTxjP8quWEqYKgx2PQflv0LC3s1OsD+IHGbHuVKLwhGFM77CmZdEyWPEMDD8LTvu7HMYH7a+WCmBKB4HeQUNPO0Z+LV0tO0WHnNS+L2W8LNBzL5Rtu3E5sOdbkCRMyRqkfA0NtWZqisxYNU5GDTqhc4frdsux1uoDjDYLCmZnc8/aq70RogLyoE2g10DCiO5t244JCvRehH7MYHBb5HOHd3B42xvan5suUn51yZFQw5OH8uTNQ2V/A7S3MwUEujlQssHnls1CXTV0gMvn997ng8gRZXIZKCqNhujkVOpLQ6vcHSmIokRrgURNdAHDY3vX2C44djaVMXspW2PD45SzN3evqQJJoMK0l72/1eBo9VC+pxlfi4J96WtYmP0+rU1Ols7b02aOa2104hM8pLnLZZOBq5eSr0seI37lI4j4sZmdOCxeHBoL0fpo+ZhN78OIcyA6IDhMKdDa/4o9vRGmCgi31kCIXc32AR+bPTS97f/BwzokFFUHKgqe83q7EIcOAj3Q36DppaPJxRAjO0F3fC7bu4MZnSBrjQqVrO2DrGk7W8DeSFKGLBDz8spwVQu0RFYTG9ZF663fK5sTDpSgFt2b2cXeQUMPClFb90iXTjia2u3uPREzRH7tanaxNcgx6NAu0J3mLm2CA2agnTFJTuIK1uAJfg6mHgT6H8RRKdAB4gZl0lBWeri7ESJAXbEFhVuNMtPZqWJgV8JUYcROA6VXzbol+UiixLaVpVRG5LMx+wckP2xfWs76RfnY1WZOOH48Y0cPZcOgHyjZ3kjFXtmp6TT7sOlaiAwsZ9ar4KzbTZS1HqfairPVi9cKLq0NrVIrJ7u4W+HYO9vbR6QcsIbeidbqQL96zijtiZGDhuJQW3ErnYwf1kFQ1u2UNVVdROcDdBGy8AoKlJ40dJDt6MFwurgOAn3wSfDn4vbok+C+hn1kZ6XjF3yU7mhC6dChSOwSVeZxyDVLfpdAD9i5exLooihv72ZyCQyUtob2Z9wRR2Pv9nOQZxTQrm1DIHSzof1aHUwunegq0JUq+fsS1NCDn0NPGvofxFEn0N1lrVgWlRKXnom1qQGnzdr/Qf+FbPi+mB9fH7iwONTkba3CL/jJyu0//vq8aWdQHrmHnUurKNneiNcCFak7uGn6NRTHbGPbsnIa8p3sSVrDOUPP5t6J95KXvA6/xsO+tbIW6rcocOuttFlBq3sokSBJ0FhAuMeGQ2PFYxORbAq5AqPPA+vekNecTBnffowppXsoWt2ebo7XfrEGhE3twD+jCG0EtQn5VMTvJi2ig1Co3dk95K+tv2mdNfSwKNlm25H0qe3/d40Z13UIjexQWCsrKpMmfTXWYKRjRheHaMM+QOrb/NEfQcHbQ00ZXGbZFBbU4jUG2dZvrZOjeT48S3YQd8XR1Lv9HGSnsEIViMnvcC3R2y6oe9XQA875jgNmZFq7IA8K9pCGPnA8FVasyyqIT8oAoLGs5PB26DAgSRK7fqukdEcjlgZn/wf8Af0p3F5HTUQhE9LG9ts+05SJc3QluJQs+XA3LpWd0ZMzOXvw2RRlbED0gl/hxTRWIsGQQKIhkWvHXMPeqHUUba3D7fCisGqRDB2KpAXNEh2x1oDHhgD4dE78NgGFQ4tg8MOu+bLzc9pdnY+JSJUdZL6ARlq/D96YKpssBv5A2rXH2p1yWOEAGXSGlrTZqvYoGrdVTjEPxjJ3paNAt/VSnjU9YEcPT2jXPnvCmCQLzYY89Go9dlMTiAI+wcOQIamd29YH1h2N/x2Ovr409J7CD42BbNGtH8m+ifo9sibfEXsPaf8dUarkAmEdTS5tGakBm3pwkHN1ySa21ckmlrAO9nlTWmcNXVDIWvth4qgT6EqT7A2PipRtjA3/gwLdUu/E2SLbn4u2dg/p+6OpyjfjboTS2J3kxuUO6Jgzjj2BSlMeXpdIXtwG5uScg06l4+QJ09gbv5atyUs5e9SZbe0vGnoRBQmbEH2we1U1Kq8WdXhAoOsioaoHDb1DvLGoc6O06lD61aiMkhz5ET+ie0SCKfBjDArkYMp23k8Dui9AtkP7XJCQKyf/NBX1f0yAO8ffyT0T7mnfULcHWRPuTUNP7WxyCWqZHYkcBMbk7tp5VwShUx2WYMXIhvAKhnW0vYMsTFW6dt/DgRB0XPaU/t9TglB4gvwslz8jL2DhdXSPSHI0yX6Dvoge3PkzaavjEhDoSpUc0tmTySU8vnOMeWSaPBvze2XBbkwacFTToeAoFOjydFIj6dCbIqkv/d8T6OV7Ze3Frjazd9OBO/AOBpIksfGHEtw6O5rhTtk2PQBOTjuZfYNX0aptxD2slqFRsrC5eNjFrBnyFSXZG5iROqOtfaQuksFDUrAaGtm6WF4yTB8eSI3POl7OmOypsmAARZgHhU92lOn0XqjfLTsDuyamBbWroKCo2Sa/Fi2Xf7QDITgY5AQWJ+nJvr/nO3h1knzevmirId7LQGlKlTVJV2sgS7QHDV0Q4Px3YNbT/fc9LqctdNGUIgumBmM5maYugrtut9y2D39JvyjVsjbck4beMXMziDFJ/tzsDXByYIHopvZBG0kK2ND7MLmA7BhtLm43o3Ws4xJEF9mzyaXrgGlKk0v8tlbLA+thNLfAUSjQVQGB7re4ScrOIX/daoo2r+/nqP8u8ndW0aptYnfiaszlbmwtB6c++4FQlW+musDM5qRfGJ88dsDHqZVqTpg4hU/GP8VpY9pD6eL18dw/6X4emPxAexx2gFkZs9gZuxqXTRasJkPALJJ1ovza1ezSwU6q1rUL43BDwAQSOah7x9oiR4ICfbucQehu7V63ozeCjrusE+VjazsIdEmSY8q/uEIWKl9cGdDCe6FulyxcTKk97+8YutixjktXMo6DgXw+sTmyycnRTEpGLPmxG3EMrkGj7KJ11u/5feaWIB2Ti6q2tA9wbQlCHQV64N5yL4LRF8n/d8z69Njk5KO+TC4AMVmydh/8nDrWcQkSFtmLht7l+bbFolfIiV+H0SEKR6FAVxg1oAC/2c0p191KdEoq3zz3NJt+WLDfS8MdjYh+kfoCO5WmPCpiZUFQvK3vRKyueD1+Nv1cyn8eW0t9Wf8rvPdGUDsXDH52x6/htIz9Wy7v8uGXc/nwyzl78Nmdtl86/FJOzzy9W/uT0k+iOG4rkiDbTeP0gYEs6wT5tatjtDFfNgsAurB2gR6lDwj0nuzJbRp6pex8q90lCw+Fur2mdX8EtfvIdNlpGIx0kST49nZY9rQslG7bIGeofnJRj3VKgIBDNLf7TCJIZCDUsXaXLMx+bzZim2M0j8zoDJZl/4fU9C4FyuxNsnD7PQ7RIPoYWXi7bfDZpXKNGkdzezx5Rw09YRRoTbJ2Hp4g5wx0FOgdqzP2RTB0MTjgt5R2t43rInuwoTf0oKEHnn9Lmfy5hzT0/UNQCCiNGvwWN+HRMcx94u8MnXwsv/77Pd6783q+e+EZ1s3/jMo9u/B5vfh9XvLWrmb+M4/x9d8ep3DTesT9cFIdadSVWpE8Ao2xZUwYlkuroYGirQMX6IWb6/nk8XWs/7aY1kZXm/niQAhq5/sGrWFYXA450Tn9H9SBmLAYHpj8AAb1wAoWRemiGJU+jPLIvbiUdhKUAZNLZLr8I63e1vmAxsJAQSYI17WH3cWEBY7rKYNRo5d/2JYqeUDwOeVImEFT2zMz+6O1GhBk4Zo4WtbyJQnyF8K2/8hp9ue9LSe5XPq5rKF+dln3SBrRL2vvvZlboF1DDxac+r3lWTuELgbNLDlRPdjPofeU//1BHyvf/+p/yhqz1y4v2eZolB20HSN2xlwM9xfIWrAgyFUjO5pcgrbw/jT06ECNnKYiOdppxxeQPbPzotY6U2eTiygGskm7PN/g86/cKJdhOMwa+hGVKTpQlCYt/lb5R6nW6pj9pwfYsXQh5bt20FBWTMGG3wC5iJdKq8VlbcUYG4ckSXz73FNExCUwZc6FjDpxJgrl77ABHgYq9jYjIRE7JIxJiZNYGLmZiII4nFYPYca+nTHWZheL3ttNTIqBU64ZQcn2RnYur8RucWMwDcz23ZFti8vRGBWsNH7Lw9k9FF86BMwcNJMXsl4i3B3Fuf5B8o++LY19TXtDj0NOyR55DpSvJULjphVwqmzEEYiM6C0l3ZQia1tB23fSGPnHvOgR2fHV34+2tVr+4SvVcmGmLR/KhawWPSoXwTrx/9o17uSxcMKD8qIJtvrOSUFNRfKA0pdAD0+Qw/CqAotV/F4N3ZQmzxoa8kibeA3PHf8c05KndW7TJtAPksmlbI3spB49V47qWf+mHGrZk2DuKOBjs+UM2CDBZ9DX8wJ5FqbSyRr6vh/kz3bidZ3bhEVCjbn9vbNFFthdBbpaJycklckyp01jP0wctQLdW9u+hJigUDBm5hmMmXkGAC6bjcq9u6jYvQNHq4Xhx51AxtjxIEHhxrVs+mEBi995lc0/fcuMy64ma/zkw161caCU7mmgwVBObsoIJiZM5PWY95lQdSqbfy4j98QUImLDer2XHcvkaIhJVyXxRd08Nnq2MU28ij2rq5l0Zvdohaq8FsKjtT0unSb6RaoLzFgzqlCplT2aSA4FJ6efzF+1f8WhaSXOk9AeM5w8Tq7JYq2VhVowLC1QMjVa7aAVsGvMxPgC5pfgsV2JCESO1GyThVtstiyAFz0iF8YKZlb2Rms1RASWKksaK7/+eJ+sTV78afcsxmByTktJZ4EedIj2FuEC8mAWkdxu1vm9GrpCEShgJWdh92hGq9osD4YHo9iUPlr2T6j1cMoT8szovVMg72e5xG9fxGbL4aRum1xJsXyt7BeJ6GfZPoVCTjBqLpYH7chB8vqfHelqcumaVNSRyLT2GVJIQ99/lCYtrn3NvZbP1YWHM2TSMQyZdEy3fUOPOY7sKdMo3LiWVZ/M45tnnyJ1+ChmXH4NSUO6mwxaaqtRqlSER8eg+D0e/YOAx+mjocRGZXIep8WdQ6YpEynaiTu+he3LYPuyCsKjtMy8dgTJ2Z21T7fTx+7V1XgyGjlv2d1ISChQMDm5hd2rtEw4bVDbyj8AzTV2vvnXVpRKBRNOH8T4WYM6lZNtqrbjdfvZxCpmDpqJUWP8Q55BTFgMkxImsaNxB+EuK4QFYoaTA8lBVVtg2BntES6xOaCLIBo3+UoXdo2FaI9Ltr8qe/n6m1Jk4VCzXdb2FEo55C8yXTa79CfQrTXtGYnxI+TY5KKl8oo9OT0MfMG2zcXtMeMgO0QV6r6LX4GsFZoDprODsSJORFK31YHacJrlCJ0xc3u36+8PQS18+j2yII5Ilk1cpasGEK0SWPauqVCeRZWtlU0nAyE6S76GyyIPJF1/2zpTwMnqlQfgoEA39CDQTR0Eem/O6z+Io1Sga5C8IpLTh6DvpWZDHwiCQPbkY8kaP5mdS39h7fxP+eT/7iVj7ASShuQQl55BS201e1evoLG8FACFUkVEXBzRKWnEpKZjiktArdWiVGtIys4hInbga0geKOV7mkGCSlM+ubG5CILAhMQJLFS+xWfTFlBdaGbbknJ+fmsXFz44kYjY9qJJe1ZX43X5+dbwPjMHzeTuCXfzz83/ZF3rQqZXX0LJjsZOK9Jv/KEEtUZJ+shoNnxfQv6GOubcM67NNFNbJGsvZfq93JP9/CG/947cM/EeCs2FCCte66Chj5UdZjs+Dwj0QuS1LgeDzkS0z0tZ1C6ajFWEu5y9m1tAnpK7zHLUzPgr5W2CANmz5MUgPPa+FyporYJBATOFRi8PKg17YdZTPQtBU5os9Ju7hODW7pRt2v3FNQeFiFovL9L8ezEmdfdHBNnxuWwG6m9QGyhDT5VnU1Nvb982/R5Z2PYXTx7bQaBrwmW7e3p3Ja5HYobI5halBsb1kHHalv5vkZ2sPWWJBglq5fqYQ76ARX8cpQI9ELrY6kGxnwJdEiUsC0vQ58ahSTMy9tQzGTHjRDb9sIC9q1dQun1Lm3MqaegwTrrmJpRqNZa6Wsx1tTRXVVC6bQui39d2TpVWy/GXX8eYmacfMtON3yey4fti3AYrxnQl4Rq5lOyEhAksLluMM8LMqBkppOZE8eXfN/HTGzs57/7xaHQq/H6RHcsqUKa4aQyv5M5xb5McnswZmWdwV8ldnBRxCTtXVLYJ9KYqG4Wb65lw2iCOmTOY0h2N/Pj6DvLW1TL+VDnUr6bIglfnxBSjZ2JCP1Pjg8yImBGMiBkBC//a/qNWh8HEa+C3l+WoheBal+ow0JmI9DhZmv1vEg2JCO7ovjMmgwLS52o3mYC8FufGd2Ht63D8/T0f67HLQqDjtH/KTXIERscSAx1RaWSh3tyl2FztTrneSn8E+xuecHC0ZmOSHMoX1E6DSJJczCxlwoArSPZL/HA4+5XO27JOhMk3ygNoX0QPBgQ50sXrkLelHzuw68YEHKMjzuk5KqZj+r8htm+TS9BufpgjXOAoF+g+ixt14v6NiK69zdhWViHavESnySYWTZieYy+8jGMvvAyvy0VTZTk6YwSRCT3bCP0+H45WM36PF5fdxurPPmLpe69TuHEtM2+4DVN8+3FOm5WmijK0hnAq9tqJTUsgfUTPU8n6slYsDU6yJ3bXAnYsr6Sl1sFvIxcwOqHd6RMUpisrVzI3Zy6RCXpOvX4kP7y6nYVv7WTQqFiszS5sLW4KctaQHZXdVifkuJTjMGqNNAzOx7t1KCs/zeO4i7LZ8H0Jap2SZ90PMGRlFn859i/EpRsp3tbQJtBriyzUGouZnHwY/Q9Oc2c7+JSbYO2rco2WpoL2KbnWRJTbDgqI0cWApbl/DT1IR8GVOhGGzYY1L8mDR0+CIFhlsaNAn3hN//cSnSnb0IPY6gOhgX3Yz4MENcSDtYBCRBIgyf6Ijjbh8rVyFuk5rx2c6/SGIMAZz/XfTq2TzWCN+bLPQx/TPsD3R8pEUIXBlFt63t9RQwf5s1CF9TwDCj6jw2w/h6NcoPst+7euqCRJtC6XbY3uYkuPNni1TkfikL5TpJUqFcbo9h/z+Q8/yfbFP/Prf97jg7tvZvwZ5zD65NPYsewXti38Aa+7PfFHUGjJHDua1BG5DJk4haikduGx+osCGiptDB4fj6LD4g92s5uNP5QQN0xHXsRmrohrXzk9OyqbaF00z6x/hn9u/ic5UTk8OvVRjrsom9VfFlKxV17hJTJJx3LhB25Iu779XpVqZg6ayXfF83julHnsXFJFQ4WV2uJWoqb5KHDlUVCSR0VrBTePfIRdP9dhN7uRJDlipmJQPmdEDXCKeyhwmTtr2hHJcm3vLf+Ws/cmBLQ1nQmNuQyDyUC0LhqcRX1XCQxqvCpdd/v1yY9D3hRY+Tyc/vfuxwaLcvXnmOtKdBbsXtD+vnan/Bpcvqwv2jT0HrTHA8EYcOh2Feib3pfNWiPPOzjXORjEDpUHb7dNjowZqHKRMAIeruo907WtnktghaRglmhvJjM47BEucLQKdKMaBDm5qC/8fhFnq5fwKHkAcBea8VbaUKeE462y4W9xo4r+/SseCYLA2FlnMHjCZFZ/9hEbv5vPxu/mgyCQM3U6I2acyOaFhVTn14FYT0tNNcVbNrLyP++TkDWEwROmIKGmYk8pAjoq96aTNiKD1oZ6ti36ke1LliOK8QjT0sABY+PHtl1bISj46PSP2FS7iUJzIT+V/MS9K+7ls9mfMXLG8XhdfrxuP4trF6JbCUkb7JQIm8kcOwGAM7POZH7BfBwTSzkhIZeVn+aj1av4Nforkp3J/Hnyn3lo1UO85H2Kk7mRku0N6MJlm26tsZicqKt+9/M7ILwu2STSNVJl6u2w/VP5/9hAAonOBC4L2YPGybHyzkV9m1wikgFBXmGmq+M0bqhsc934rjwj6FrLJJj2v78FmqIy5dA4Z4s8ewgK9IFo6EGB0lNhrgOhTaB3KE9rb5QXv5h4bfv6mUcCsdlQvEKuljjpun6bd6KvIIeuFRd7yhINEpUhh88OZPA9xByVAl1QKlAYNfgtnj7bbVtczuaFZVz73HGo1EqsyytQRmiIOncI9a9uw11sOSgCPYgxJpbTb7uHmPRjWfvVUibPmcXUcyfRXGOnvtxK4pDBNFbYOPWWcRhjvOSvW8O+NSv57cuPO53nyycXYoiMwmGxgACCIg1BKKd1fh4Xh2ew0/I5tekZxKYPIjoljbT4VAYNlU0hJ6WfxPWLruepdU/xxPhH8bqdeBxOtn33FefvSKHUv4qKVeu44JGnSR02kvHx44nXx/NT8U+8fNJpxKUbqbPV8dKmVdyccTUTtCN546TXufqXa5gV5aN4WwPRSeGgFGk0VDE0uofZTG9Ow67Lfv0egmnZXQVz4ijZ7ly0rL0Ylc4ErlbmnTZPLrf7w1N9m1yUatm2mzmj5/0nPCQno3x6sRxdY4iRV7WPymgX6EGhOFDaIl1KICUg0E1pfS+3FiQYOx60C/9egrOLjtmr+b/ImajjLj841zhYxAyRhTkM3H4+ELrWRLc3tH9GXdGGwz17YIAJcoeSo1Kgg1zTxd/at4ZesacZr8uPpd5JuE/EXWzBNDsLdXI4CoMKd7EZQw/26t9L2S4lqrCpbFlkJTatjuJtDag0SkqnrCG8YjTVhWYm5WQycfa5TJx9Ll6Xi+9f3Yq12Ym9pYmEQTZ0+kZM8QmERY5n3Tf15Fwn8OqihzjNO4GagjzyflvZdj2lWk1s2iDiMwcTnZzKtRVTaVm2lddendvWxgT4h8Vz+VX/x48vP8e3zz7FxU8+R0xqGqdnnM7H+z5me8N2RqWM5NMv53HaugRcPy3nPZYjKBRcGJZGq+FbvDvGYGkYjCuygWR9AkZ1u03R0Wph5zcfULJ8PrE5E0idfi4pw0cSbtAhfHqxbO+c8/rBechBzamnWPITHpaLVQXt3zoTuFtRIsjOM9Hbt0AHuGG5nLDTExFJMPtF2VZfukoO8avcDNf+LAt0XeT+a7FBYdFSIjtPgyn/A0Gjh9vWHzwNPSxaDpfsuIBEU6H8POIOQnbowSQ4aKv1B1dDDouSn0HpGnmwttV1rivflYMRXXQQOGoFutKkwVvv6HW/3ydSVyLXKTHXOZB2N6IwqDBMTkRQCGgzTLiLLb0eP1BKtjeg1ipJHSZrUvVlrdSXWZl67mBKdzay5IM9iKJE9onR3Fv1PldEPEZ1QWety+9XUlvswjDRhbdYg1I7hjPvlCMiln60F51BzTeWz2kZouXaC/6JRqnB7bDTVFlOU1UFTZUVNJQWU7BuDS67DV24ESk+nC1h9QxOyCHaFM/8loW8cP5jJCQN4fyH/8Inj9zH/GceY/I5F3BOxkmsFZfx+sv3kVsbh6+1lZhwA9MvvQJ9hAlLfS3Lt/6IVFGOx1dGfSDb+pRCNS9/fz4RcfHoIyOpyd+H3+cjTqtk7/Z9bN8qO7b0WohXNWNS16BqeBGVMQ67uZmWmmpcNitDj5nGmJlnyLOSVgvlu7ZTW5hHfUkxTVUVxKZnkHPMcQyZPBV9RNC2aQbA7lPTsH0LrQ312M0tDD3mOGLSJsENS9sfsC4CkOQEFre8IIpfY6LPrAK1PHPzOB3sWrEEj9OJoFBgjI5h+HEnIIy9FMZeKrdd+zr88hBUbgJrDZIxGYe5BdHvxxjTTyw1sm/Hp09CDXKki8ch24VHzun32DYiD6L9VqGQZxgdY9Gbi+QEnN5i9w8XQSdo6sTel507EFRamHEfrPgbDDtTLk9wMGL8DzFH2KczcJQmLa58c6/JRQ3lVnxeOcW7pcaOrsCMflwcCo38M9ZmmXDubsLX7Dpgs4skSSz/OA+fx8/Fj0wmIjaMXb9WodIoGDkjhZEzUljwwhZszS4K09dDHlSE52EqjsPvF1EGEnlKtjciiRKrND+jUyWgL49su6+aQjORgzSsrFrJjaNvbKt6p9UbSB46nOShwzv1x2Exy0LY08pbO97i26JvsXrWExETwfgEeZAwxSdy3kN/4dvnn2bp+28AcCwKJDSUJDayJ9vMvRf+lcmZ7UkapaMV/GPtP7ht+wO4LDXkxa9laEY6Y4yjaG2ow9rUSO7JpzJWtZWY6l8QDQnUN7RSrRtDfWkR9aos6swWvCuW4/ODITKKyIQk9KZI1n71KesXfElUUjJNlbLTWqXREpeeQcaY8VTn72XxO6+y5N3XSRk2giGTjkFrLWFv+SjK//Fupxoo677+nCnnXsTkORfiDAwO1l2VGMwJ6DesprGsmKKSMdQ8/xVDj6nlpGtuwhDZs7ZeumMri99+hdaGzjXnS7Zt5rRb/4RSFRAg469AWv53iue/wKY9ZhrsMbhXXgGCwDHnXczU8y/utcSEpb6WX954iYo9O4nXT2LQsq1kSj+TIoooAhq6z+uluaoCXbiR8KjoTufyeb38f3vvGd7GdSZs3we9kQDB3klRpCSqd8m9yb3E3Y6d5iROcXpxkvX7bTa7m+z7elOd6sSx4zjuvVuW414kS7IqSZFUYe8gARJEB+b7cQB2UZREmYQy93XxwuDMYHAOBnzmwVOr336dvW9uImdOOWuvvO6w6zkqEs0kEvQenLJJx93ZQUv1HrJKy8goKp40IW/A1UNbXQ1zlq9Gb5L/h211NWz68+9IzczilGtvInvO3MO/mS0bJXsJovKKKc0tQSwWxdvbO3n+yOnflfV3nou3KDxKp3NfRxvu9jZS0jNIzczCYD7xvocpCXQhxIXAbwAtcI+iKBO490EIcTXwBLBaUZRt0zbLCdDajSihKEowijCNX0b7fql9a40QaOpHCUUxznUM7TeWye3gIWlHDx50E6jtI+XsQjQTnG/QE6RuSydLzi4Yypjs7/Hjj9eUef2BGi68dTH1WzupWJsz1J3+mttX4h8Mce3rP0MrtDTZ9jG/7RS6mwbIKZXa5sGd3VjTDGyNvs08y1pCHVH6ewLojVo8XX66i5vRCi3Xzbtu0s9ECDH0z+wwOfjBmh/wzRXf5LWm10gzpqEbYULILi3ji7+7l/7uTtrq9uHv9xAtT+e2D7+DWWfmzDEd3ldkrUDRKpgXZhLZkcvWiie4csOXOat4TGbeX86BnMVorvgdOX85lxzfK3Ddd+C8H8MTn4f6V1G+XYUY0R+zr72VHa+8QG9bC/NPPZPiJcvILp07JLgURaG78RD1W95j/7YtvPn3ewCw602su+h8ilefTWpWNlqdjjf/fg8fPPEQH730LEHf4IiJVcAf/iTXbhIsXrOU6u1baNyzg3VX3YDF7iAWiRD0+Rjo7aGvrYWDH20lLa+AG35yJzlzy4nFYnz00nO8+/D9+Af6ufRbPyDk99HX3saWrlNpbh/AYQgzv8SB89Qb6TxQz+YnH6a5ajcbvngbzrwCRLw5gs/jpm7ze7z90N8QAlZcfAVdHzzD9n0ettbch0W7ljmv7mbw2e00V+8hEgzGr7EGq9NJSnoGKc4M2mqr8fb1kpZXwM5XX2TvG5tYev7FOLJz0RkMaHU6NDodWp0Oi91Ben7hYQVLNBLG5/Ew6O7DrM0i1VMrfQ6KAq6DRPLXU/f26+x67RXcHW2kFxSRUVRMWk4eKRlZ6I1G9rz+KnUfvIuiSGXKaLFSuHAxc1evZ87KNZhtKUPXtPrt13njb38m6BvEYnew5oprCHgH2PL049ic6bTV1vCPH32LslXrKFiwEHtmNkarjUFPH95eF72tLXQ1HMDVkkFhXxPnFLaRljNxdJGiKLg72mipqaJh9w6a9uwk4B3gnFu+zPILLh1/fCxGT2srxjP/h5THPiE/hyMI9MCgl56mBtrq9lG3+V06D+4ftd/mTCerZA5ZpXMpX7OerJLD2OSPgyMKdCGEFvg9sAFoAbYKIZ5TFKV6zHEpwDeBj6U4+cjQxYkEcNt+N4o9SDNNLO6Ud37jHMfQfl2WBY1FJx2jmWZ67qtCCcfw7enBef08jMXDAsfvDfHsr3fS1z5ISrqJXCWGv7oXV7k835JzCtj9egvP37WTSDjGgtNzeLf1Xdbnrkdn0FLbW0Wrt5XrKq7j+eDLcn71bnJK7YQCEZqre3GsUIgRo9sq6630NA+QaJj5evhFzpt7HlmWow9LM+lMXDpn/BcW5A3AnpUzKm7+7+l/JxqLjqtFXpFWgU1vo6l4O2VlCwm0DI6vwheLyZZtKz4lHYSffkYWLVpzq9y/9suw9wnE7kdhzReHXpaWm885n/vSYdcghJD/CCVzOPX6T+Hu7CC4+W9kffQ/iGseG5VReMk3vk/l6WdT8+6bZJWWUbx4GY7gQXx/u5HBC35LijFCyitfhZt+z6obHWz68+9464G/jno/nd6ALT2dNZ+4lvVX34jOIH8VaYG1n7gWi93Oprt/x+9vuWH4c7ZZOSfnEEscrWjP+gGcLUsCFy9Zzmv3/IG/ffer6PQGHDm5+Af6GXTLcLiiRUu44MvfIjUzC+w7CdW9ziHradTvrqZux06sDieLzjqPvHmVhP1+BlzdDLh6GHB109VwgPTCYi786ncoWryUvvY23nvsH2x7/qnDfpYAKemZ5M+vpGTpCjKKSmjY9RF1m9+l69Dozko2nZPcX/yMWMiHr34uvbX7CQZ/SVpuPqXLVtHb2sze1zeNCss1mC2suuxK5p96Jq7mRppr9nJo53b2b92M0Ghw5hWQkpFJNBSiuXoP+fMrWXnplex85YWhG/XCM8/j7M/eCihsf/EZdmx8kQPbNo9bhykllezSMhaddR41777J/d+7jVWXXoXJZsPb68LncRMKBAgHfLhamoc+c2uak7KVaxhw9fDGfX/GkZ07FPXVXLWb6nfe5NCOrUPH6/XryND2kbFxO5mNCqkZmYQDAUIBP56uTrobD9Hd1IDXNdwbNaesnDNvvoWcuRV4e114urtwNTfS1XCQQzu2Y8/MmhmBDqwB9iuKchBACPEIcAUwtir/fwH/DzhMCt30kmhFF/WE0GVZ8L7Tisamx7IkEzSC9gNu3Jlt9Pk7sfoWoM+3obUOCymhERhK7QRqewnUuNCkGnBcPAf3CwfovnsX9gtKsJ1RQCgQ5fm7dtHf40dn0NCytwdLo4eYL0KfP4LBpOXUa8rxdPtp3OMiuzSVTYPPc+fWO7m6/Gp+vP7HPHvgWSw6C19e+mUeq3sM4QjRXu+G84vZsamJaCRGe1Y9wiXotbSDRqF/dzchjUCjgyZjHd+d89WP42NlvnPiuiFajZalWUvZ7vkQTY6CRWehIGVM3Qp3gyx/mojxzlk82rFXsEpGhWy5W1a3G9nK6yhwZOdIL69gdJPjOKXLV1G6fET2apsHuyGIPds23MzAnIbTns91//4z+jqkaUGr02EwmzHZUiZNllp89vk4snJort6DLS0dmzOd/PmVGDd+D3Y9NCoGvfKMcyhYsIiG3TvobWuhr72V7DnlZBaXkFUyh4IFi4a0dpwlGHxtzEupYd46O3zu8aP6XJx5+Vz2rR8QvPXrhAN+opEwkVCYWDRCNBLB2+vC1dJEd1MDTXt3se+9t4Zem1s+j3VX30iKMx2z3Y536xO07XiHzsaDaEUUiyZKeWUFCy6+icKFi4c+H0VR8Pd76O/pxudxy8/BIqM9skrmsOD0s1EUhc4D9ezfthlXSzMDrh4C3n7OuPkWVl5yBRqNlvLV6+Mlr0OULB3OqD3l2ptYf80nCQ4O4unuJDjoxepIw+ZMx2C2DM1j3VU38Mb9f2HL07L3q85gxOpwYDBb0JvMFC1aSv78hRQsWIgzvxAhBKGAn0d+/ANe+PX/ZcOtX2fvG5to3L0Dg9lMydKVlC5fRTQcxtXSRM+hWup317Dn/Q9HfeYarVZGmi1YREY88iyzuHRUnspYwsEAnKDWDVMR6PlA84jnLcDakQcIIVYAhYqivCiEOKxAF0LcCtwKUFR0fE6cIQ3dHcS3rRPPSzLLzvPyIbSLMggNRjhYVEVEiZAWAE3heC+0sdROoMqFJkVP5i2L0KWbMZbZ6XuqHs/LDYRdAd484MHV4uWiryym5r12xL5eYooCOg2GpgGM+Qq7e3Zx9s0LeOmPe1h9SQnf3v8zzDozT9Y/iV6j59WGV7mg5AIyLZnkWnMZSO+i/YCFjzY2su3FBirWZPM3/sqyrGXU9dWhtftJ39dLQCPQZIWIaaKHFbQfJyuzVnLXjrsAmdCkEWMEcqLzTvZhyqoKIbX0p2+Fg6+P7+c5lnBAdvY55RtQevrofX735AW2RjKy6a8/nigSD0uTWuPRN/UtXLiEwoVjoipO/aZsgjGmM1BqZhZLzr3gyCdNRLp07pGf0zFitFgwWiYwq5SVDxWsU2IxuhoP4WpupKBy8XhbsrGZ5V33wG3/gJYP4dmn4AsPjAvdE0JgsTuw2B2HnY8Qgpy5FUdM2CuonDjmXgiByWbDZLMd9rU2ZzqXffuH9Pd0YzCZMVqtR8xgNpjMXHn7v/PgHd/hxd/ciSkllbM+/QWWbrh46FfZSBRFwdvrwtvnwmAyozeZsdgd6PRH54zVG6cvVHosx+0UFUJogF8Cnz3SsYqi/Bn4M8CqVauO6x6lTZUf+MA+F9H9Hoxz7KScVYj3vVYCH7RTZtTwoHEHqwNL0QpBaIJ635YlGQQPeUg9rxhduixkpTHpcN44n35nAwNvtlAUjrHghnJKFmfg7fJjOdiHtsyBPt1E+tYOdkff5/43/8mLV73ItT9cRbWrmvrt9dyx9g4OeQ7x0L6HAIa68pSnldPeWc95ohj3y4eYtzSDtZ8s5vuPVXHLolsIRoPkGENoAmCJKTjMXlL0KWRbZt7DvjxLNovY797PdRUT2PMTdbInqw648BPw8u0yjnukQO89JDvJz794eKz+VfkXHIDSV0afZ2yW6GSMEuhuWZBJfwIcVFnz4fapN4QeR9qIJKWphiweI0KjIbu0jOzSwzg6h5KL2mVddo1uVmRCHomjLZKXkp7Btf/nv2nY9RGLzj5/4hthHCGE9F1MIXJpppiKQG8FRhYpKIiPJUgBFgFvxu+IOcBzQojLT6RjVGg1hDUCqnsRRi1p11Wgc5gwVaSx7782U6EoxPQ+ShQnMUXBq9EwVg/TphrJ+NT4FHAhBCkbitn+ThvlgG5zO4F8G1mDIUIaQW+2FVu6Ea0QZCphuvxdPFH3BDdX3swz+5/BoDFwUelFpBhSiCkxDngODEWYzHXMJTroJluvIUsPonWA5qd2IGKyLktrfyvlIRs9kRgGIZg3YKHCUTEr6rUvzlyMXqMnHAtP3J2os0oKJePhNSl0RhkGVvMCRILDDQte+RHUb4Rv7IS0eK/PvU/Ix6YPZFnckcWtxtZxmQxj3B+S0NDNadOX4DSdOD8+gX5ERgr02RqyOE2kFxSRXjD7b1ZTYSpGzK1AuRCiVAhhAG4AnkvsVBTFoyhKhqIoJYqilACbgRMqzBMkXDH95WnoHMM/Y6p8UXQCrnddQGWwGHdUoa93fCPlSCjKjlebCIfGt6Sr+7CTGleQyDlFsqDbX/YQ3NJGtxA0tHrp6AvhjiqsD8zDqrPyytbn6LhvF+GtvZxTeA52ox2N0HDHuju494J7h8wT86zlXOxZR7jYQPZ3VmJZlknqbri18xqWZS1jrXcx9piZg8EYtcEoGaEUzvNNktDwMWLUGrmWS7i99XNU2CYogtRZdXhzy0gqr4CgBw7GbbgDnVITV2KyXgjIxKC6jbD0k9K0svmPo89xNBq6VifLqwb6hwX6bMScFk9o0R25BvqJJlHoa6D9qEIWVWaWI95yFUWJCCG+BmxEOvrvVRSlSgjxn8A2RVGem/wMJ47WUAxDNMaB3T3MDUXRG7S4u3x09AU5WDjI5X1noUVDrTZAuHN8ElLDHhfvP7WfWCzGygtLhsaj0RhbX2ogo9BGyYYilLMK2PboJmz7FLqKHLTscxP0R7AYIiwK5vPb6H/g3KcnQB+fV64gEIPQ3AGiAyFCjf0Ig5aUMwsQWg3zD+ZhiA6yf6Wb0iwLzmsq2Nj+Kpe1ngl7vSw4mE+XrpeOSAqpOQYao62sqS9HiSkIzcxqlaE2LzfuOw9dVINxixlG1mgK+6Umt/DKw75+iDlnSa255lmoOF/W2FaiMrPzo7/L1Pral2StlpWflYL7wz/Dhp8MOxz97qMTMvF6Lvj7pq7ZzwTOMrlu3XgT4ceK0SavUX87uA4O13dXmdVMKcxAUZSXFEWpUBSlTFGUn8bH/n0iYa4oylkfh3YeCUep9UbwzHHg6w9T9XYr3r4AL/xuF3qjlmeK30AIDVpFyyFDN+4JBLqr1QvAzteaCQeHtfTazR30d/tZc9kchBAMKF6+q/8p15ffTlthK5FglPb9Hg5lugiKELnVVhqdXXx67h3cU/wM5l4tXb/biev+agbebqX/1UZ67qsi4gli3BZkq62K3bpaAHxhH79IvY/ujAF6n6wnpU3HC2lvY61QMC0I82DmS1g8etzPHUCJJ0pNFUVRCLV68WxqxLu5DWVsE+IxRPuDeDe349vdPe7Y6GAY1z9q0FuNRBabCH7Yjb/aNXxAd63UsKfSCV5nhIoLYd+Lsub2zoegYDWc/9/g74Wqp2Q7OXsRFK6RRbCUGHz4l+FzHI2GDnGB7o6/bpZq6AAX3wmX/WamZyFJyZVt+MKDw42VVWY1SWsU88ULc5WtyEJR4KONjex5qxX/QIhLv76Ee7Z8nwvmrqb8UDZVpgMsaM0flZ0J0NPixWDSEvCG2ft2K8s3FDHQG2DzMwfIKk6hZLGMb/7Dzj/QH+rHordwwLKbPM3ZKDGFZvtBHrF9xLeWfQtnoY2+V/pJW15ETvkq/FUu9Flm9AUp+Pf00PdUPZ2/2I4SivLmop3E3NIzvrVjK0FCBC5PQfO4lphfYaPjPT6/diF9sSjv+nZgXJ/J4AfthBo8OG+cjz7bKkvEuuphw38SHQgRGwyjseoRBg3BQ/3xcMzeURUpw62DOD4xF6Ed1vQVRcG/twfv262EmgeGxo0VaaRdVY7WbiDiCuB+Zj9RT5DMLy3BkGejq2cnfU/WYShYKR3UCYfoVKoDgjS77HlMNqToroFLfy1bj2XOh3d/LWuHnPJ1aetOK4F5F8P2++CM78vaJUdjQwcw2Ql7dGi8MbTZs1ig56+c6RkMk5o73Hj7cIWpVGYVySvQ4xmaOhusubSUJ+/cTjSicPk3lxFK9+CP+PGdZuSdpQ20vtHIvJhCf7eftBENMVwtXooXpeP3htmxqYn563N48Q+7iYZjnPe5SoQQ1PfV82jto1xbcS0dgx3s6d/FitIraD/gYZ/hI0rzC7CuymYZ2dx/4f3Md85HqzdgWzdcbc+6Mhutw4jrgRpMC5zoC23s7dmLJ+jhp1t+Sp41j2VzVqG7VSHaH0K3zUhjfyP+sJ+8lDwyr5iPf14WfU/U0fW7naRdU4Fl+33QsRd/7tfofbR+nPYu9BqMcx2knluEaYET7/ttDLzeTNQXxnHJHIReQ3QghOfFgwQPeNBlmUk9vxjzwnSCBz14XjpE56+2I/QaYl5ZzS7t6nKMRdLB6LxxPl2/3UHPfXtxXj8PfWeVrB8+1X/8uefK6nRv/Ew2Dlh0lRTeq78AL31PHrP42uHj13xRtgzb/xoB7TpiwbVYjkJDj+kz6aq/Gb2mkUzTQWahS3T2kZI7XMkwXRXoyUDSCvTBeHOLX1X/L3+88Vec97lKMgpspOfbeK1xKwAVzgoOaQ/hNslaHH0dviGBHvRHGOgNsPCMPHLL7Dz9ix089tOtDLqDXHLbUtJyrCiKwp1b78Sqt/K1ZV/j4dqHebvlbeaeko7eqmV/uIYNjrOG5pSIZJkIU5mD3B+uRmg1lFeXs7FhI99/6/t0+7t54KIHMOvMkAn6TAsldSU09jfiDrgpT5POR/N8J4ZvrsD1YA29D+8jrF+EVsnC/WAt+nwbKacXEPOFiQUiGPJTMJbaESOaOtvPL0Fj1eN5/iAdVcOmEmHW4biiDOua3CHNXZ9txVSRhmdjA0KrwVCSinGOHX3mcEiXPsuC88b59D1ZR+ddO0hJd5CaUYmYaiNtvVnaz6uelg0TEqGFS29A2fQTsOcjRjpYi08jZszH/VIvvp5a4HvoAoc4QrfNIbzu1SiKiVB0HoFBBfORX/IvT9RQTG/oZ1h1G7EkQciiShIL9ITJZbt3C80DzcxbOxxZWddXh0BQ5ijDH/HjNkuBPtKO7mqR9vP0fBt55WnkzrXTvt/DqdfMpXiRNLXs6t7F5vbN3L76dhwmBwvTF6KgECzrpnxBCsrzCnMcU9dcEiUKEkL6g/YP+OGaH7IoY7SZoji1mDea32AgNMC5xecOjWtTDGR+YTF9D29loEpqr6acQZy3njJUdGwyUk7Nx1CQQqTLhxKRGr15SeaoDNoEunQz6Z+cvFSquTIdQ/EqPC8cZGDHOgKDFTi7faME/0TEQlGCdX34ej9FKHgx+u5cjO+2ojHpCNT1Egg+hMYjsLzWhGV5FlF3kEBdLz7fr4mFDdhWmhjc3kP/vjwyjtB2MvF+3s5KjJodRJRc+vcXYzpMUbeZJuIOQkyZ1jr9x4ISVXBVLycUsxIMLYTqPiyLT3wjdJXjI2kF+qAnSEzECOi9vNrwKp9fPNytpK6vjuLUYsw6M9mWbEI6PxpLbLRAjztEMwpkzPS5n6mkrd7N/PXDdU0erHmQFH0KV5dfDcDCdKkxVvVUkWmRX+4y+9E7ixIx3BuKN/DJ+Z8ct78otQh30A0MC/8EQqchrbIOQ+3zRMkmtVSDMFw45fc2FqeOqlNzvGitepzngHnvf9IX+Te6frsD+wUlCL2WcOcgMV8EXboJXaaZaH+YQH2fLFsciaGxWDDMSSHcJwi8IBska2x6zItziPYHGXi9iYF/NsXfSGDM1mHv+RaGrJvQ6PbR3/ZZgg0ejCXj0/9HRgUNfthBLGIk1fAQkVg+fe5vEajuxbzwCF3lJ0GJKcR8YZRQjFggQqixn0BtH+GOQVIvKMG6/Ojr7vh2dtH31H6USBTr6hxSzy0eSqA7ErFgBGHQTttNqn9TIyGXFYfu9/gMV9L7sA6h0RzXZ3YiUKIK/j3daO1GjKXjvwfHQ9QbItTiJdwxiBKIYDu9YELlBzhs1dePm6QV6D5PiIDeiyIUXm0cLdDr++qHhGa2VWZYKo4AXU3DTr+eVi9Giw6rQ4aH2TPN2DOHf4h3DHawqXETNy+4GUs8qzDdnE6uNZcqVxWFoUK0QktxavFRzz3fls+9F9zLooxFE34JSlJLhrYr0sanS4v2HdisH0DecmjvO+r3n3aqnsGs3Yrhi3PpfbEP9/NSOAu9Bo1Fh29naKh2hS7TjG1NDqZKJ8ZSx5CZJ+IJEvNF0GdbhgRxxB3AX+VCl2bCWOZAIwJwZzvsfBCbtg2v4bN4Xmkg80tLiPYGGNzaSah1gHD7IDF/BNvaXGxnFuB9uwWDcwCjrwaDqGXA8g36NzVgWuCcMBQ00uOX5ia9BuvaXAxFKSihGMH9boIH3IRavYTbvSih0X4LrdOExqyj77FaiMSwrs4hOhBi4K0WIn0B9NkW9DlWdGkmtKkGNFY9sWCU2GAY7/ttDG5ux1Ccij7PyuCHHfg+6sJ2Sh62MyYXJN732/C8fAhThRPn9fPQGKdo9joM/moXA282Y63UYjv4MpblZfQ0zcP1QDW6LItUCirSMC9MP+5Q2uhACH+1C22KAV26CSUG4dYBwh0+TPPTMM0d7cBWwlGEXq4v3DFI7+N1hOPKmaE0ldRzijCVT+70VmIyEMC3owtdphljiR1jqR2NeVgcBhv76blnz7BvSkBgXy8ZX1iM1jZ8k1UUBf/ObtzPH8A034njsrJR5/m4SVqB7nUH8OrdpBnTqHZV0zzQTGFKIb6wj+aBZi4ruwyQyTBOk5OB/HaUrRb6OgZJy7HiavGSmmvky699mZ+c8hNyrKO7vTxW+xgKCjfMv2HU+KKMRezt2UsoGqIotQj9MRbVX52z+rD7EjcJg8ZAUcoEtsv2nTJmO3+ljBIJB4YaMswIVU9D0Xq0+YVkfKGAUFM/2hQD2jQTQiNQwlEirgDCqEWXNvE8dXYjjCnPoHOYSDl1ZH6vVbaXq30JjYDUU1Jxv9ZP9927CTX2gxDoc62Y5jlBUfBubsO7uQ1ikHb6AGwFIWKkrjPR+6qPzl9sQ1+QgiHPii7Lgi7TQqDGRf+rjRAXVL6PutA6TbIheVRB6DXo82xYV+WgSzchjFqEQSsFdaYZIjF6Hqih78l6AvvdBGpcKJEYujQTgWrXpEWZbGcWYD+/GKHVkHJaPp5NjQy83YJ3czu2dbnoMs1SCzdopYlNJxj4ZxOB2j4MhSkEalx0/2kX6Z9diM5uRAnHCLUO4N/rIlDjQph12NbnYVmaiRJTCDX2E+7wobUb0DlNRPtDeN9vI7jfjT7XiuOyPLhLgyavnIwNi/Bubid0yINvTw+DWzvQZZpJPacI89LMUYJdUaRzn0hMrlenQWvTI3Sjo6TDXT567t07cW9gAd73WnFcVobtlDwiniDup/cT2NeLxqJD6zQRbh9EY9bhvHEeUW+Ygbda6PnrXqxrcnBcXjbu/ZRwjEBdL/2vNRFuH0SbaiBQ14f37VaZbX51OZYlmYR7/Ljur5LtKq+uQJ9jIdTqpef+arr/sofMLy5GY9ET84Zxv3gQ/65udNkWfDu7CO5347i6HFN52tBnEgtECNT1oUszYZigptR0krQCfcDtx2fo5xPln+C+vfcNmV02NW5CQRml2WZbsmmxVDNflFG/tZPVl5TiahvEvCjI+23v81jtY3xjxTeGjg9EAjxe9zhnFZw1rqLgwvSFbGrchD/in9QJejwUphQO+QB0Y9ugRcPQsVdGfeSvgFgEOvfKSoYzQdc+GXZ4kexOlOgGNRKhlwJvWph/iUw6Aqxr8vDuChPp9pFydiG2dbloU4dvCilnF9L/WhMoCsbiHpnzDJiXpOMwmgkc8BBq6Me/q3vUW5gWOEm7ci7CqMO3q4tAlQvzonRM85wYi1PHCYpR6LVkfLoS14M1+Hd1Y16SQeqGYvSZFpRwjHC3j6g7KENNvWE0Ji0aqx5dpgVD/nDJBF26mfQb5hOOr2HgrZaJ30+nkU7tdbkEavvofXgfnb/cjtAKYr6IPEYrMM11EOkL0vd4He7nD6KEohAbf3fRphpIPb8Y27pchEUPt74FWQvQaHWknlUIZxUOabj9/2yi99FaNC8ckJ9NmYNwqxd/tWtCIa2x6NDn2zAvTEebaqT38TqEVpB56xKEXkPE5ZcfYb4NbaqB3kdqcT93gED8lxExBdsZ+ShBqSBYV2aTekHJ0K8X29pc+jc1MvBWC+GOQZzXzSM6GCbc6pXn2N+HEoqhdZpwXj8P89JMiCqEmvvxvNJA70P7CB5wE9jvBgEZn1uELkP+ajeVp5Hx2Upc91fT/n+3QjR+s9IIUs8vJuWsQsKtXnofq8V1XxUaiw5DUSpoBIG6XojIz9qyIgv7xaWjtPzpJGkFuq8/hM/ST6VzFYszFvNq46ssy1rGTz74CSuyVnBa/mlDx2Zbs2n1NnJuhYP6bV1UrMkhEoziTemBIDx74FluW3Yb2niExsuHXsYddHPTgpvGve/CDGlHdwVczLGfmFAuk87E3LS5Q8WwRtFVA9GgNLfkxW8orR9NXaD3NUqB2PieFMbX3T+1dP3DUf0MIKDy8mM/x9FQcSEIDSgxhNVB9jecIMSEQlafaSH9xngK/YHh7jvC4sR2qhNbXPuP+cKEu/1EunxoUgyY5qUNmcJsa3KxrTm6hs9CpyH9U5XEBkJDVUFBmqAMeTbIm6TWzdg1ZFtJv2kBMX+EmD+CEo4SC8rGLkowij7XOlRYzjzfSdZXljLwZjPCqEVrN6LLNGMqT0Nj0qEoCsH9bvmrI9WAscyBPs9KdCBM1OWXgr/COSpPYaI+nUIjsCzJxLwog0BNL7493fhrevF91AU6DaZyh8yMNmgh/gstNhAm2h8keMCD+xlZwEyXYSbjlkVDDuCx2mv6pyrxvHQI77utGOfYSbu6fGith/vc7ReVos+30fd4HR0/H85v1NqNWFZkY1rgxDTXgUjko2gExjkOMr+0BM8rDXjfaUXoNWR8cfGQME9gmptGxhcW49/VjTBp0Zj1GMvs8prG55/9jeX4dvUQbPAQaupHCcawrcmVn1VdHwPvtOCvdpF2dQWWxdNf5CspBXosGiPkjeFz9GM32rmg5AJ+vu3nfP2fXyffls9d59w11KoNIMeSw/bO7ZSvyubNB2vZt1n+c3eaGiEIXb4uPmj/gNPyTyMcDXPv3nspTyuf0CxSmT6cCVnmOHHZc3+/8O+j1jBE+075mLdcpsFbs6Btx9ROGg3DPefKmuCJDvXb75fZicdK1dNQfMpw7Y8TjTVDNutt3wVaPWKq5uKhuuliXA11jUWPsVg/rc5ioRGjhPnxojHrpmSb1edYcd4wcR0YIQSm8rRxNmatzQC5R/8LSmgE5oXpmBemo0QVwh2D6DLMk9rwFUUh0uUj1OzFtMB5WN9A4vyOS+dgW5+L1mmastPRsiQTfbaFwL5edJmWIY1/stcLrQbHJXMwzXPKHI6iib8LRwoqEHot1lXZEzafN86xY1mRhfv5A+gcJ6a0w7F1GJhhfP0y2cGn78dhdLAh3gZNr9Xzh/P+gN04+h8225rNQGiAvMUpaLSCXf9sRgg4pNnH8qzlpBnTeKpednn5W9XfaOhv4Nsrvj3hFyDVkDpk4z5RGjqAzWCbWKC37ZQ1NtJKZSJO/gpo+2hqJ23ZJoX5VX+Bb+6C8vOlhh0bX5xsSnTVQPe+qdVvmU7OvgPO+T9H95pEVqnJDlONlVeZMkIrMOTbjuiQFUKgz7ZiXZU9qTAfiS7dfNQRJPpsKylnFmKuTEdnN0759aa5jmm9sY+bV5aFzM8vPmG29CQV6NI+5zN4SDOlkWfL484z7uTeC+6lMKVw3PEJh2ef6KGo0kkkFMOeZaHR38Ac+xwuLbuUN5rfYG/PXu7efTcbijdwesHp486TYGH6QjRCQ4m95ISsb1LadkiHaKLLTd5yWUcl6D3yaw++Ic0V5fE+oIuuAm+nLE87EdHw5OeregYQsOBjMrckKDkV1n3l6F6TKKF7NPVfVFSSjKQU6IPxpKJBQ/+QNn5R6UWHNYEkmkN0DHZQvlpu23ON9AZ6KUot4sq5VxKJRbj11VvRCi23r7590vf//OLP8x/r/wOj9mOuiBcNyxK1Izvi5K0AFGmCOBIH3pA3gERxqooLZdr93gl6UIYDcNdyePRTsm75ROx/DQrXQsrMN984Iomm1LO5MJeKynGSlALdF0/7j5gCMmX+CCQ09M7BTkqWZGBO0WMslGaGopQiytPKWZyxmIHwALctu21cCONYKtIquLL8YzYzwLBDNHfZ8Fhe3HG6/T4pmJu2yC7tYwl4oHU7zDl7eMxghYoLoPpZiEZGH1/3MniaoeY5eOQmWR53JLGovLnkn5hIn2lHZ5Q3L1Wgq5zEJKVAH3QHUVAw2qZmCx3S0H0dGEw6PvM/pxKplB26Eyaaryz9CpeXXc4nF4zP3Jw1JEwjCSEOYMuUAn7P4/DE5+De8+G1H49/bcO7suZ42dmjxxddBb4eaHhn9PiuR2Vxpkt/JTXxh64fram7DkDEP/OddY4Gk31210JXUTlOkjLKZbA/RNQYwm6emvPCoDXgNDnpHOwEQKvT0DIg+14nBPrpBadPajefFhTl+Fqf7XwQshePr2j4xdfB1ysdnpt/D+/9Rgr9kc7KA2/IPpoFYyJ3ys+X3XyqnhoW9oM9sH8TrPsqrLpF2t2f/6asX74o3tWic498nGq53NnA+f8lo3tUVE5SklJD93lCBI2DOIyOKb8mx5pD++BwLHLTQBOZ5syhtP6Phfsugo13HNtr23dLO/mKT42/KWi0UlPProRLfgUFa+CZ26CzeviYg2/IrjNjO+HozTDvIqh+Tt4UQJpuYhFYGs+SXXaTvBk0bR5+Xcce0OhnvlXa0bDkOtkwQ0XlJCVJBXpQhiwexc/nBc4F7O7eTThe37mpv2nCiJgTRmeVNJkceuvwxwz2QE/9xPt2PABa4+ga4ROhM8B1f5ctxB65Ud4E3M2yYcRYc0uCdV+FsA8e/4x0vO5+RGreiYQjrV6WGWgeKdD3QuY8+X4qKiqzgqQU6IOeEAP6vqPS0E/PPx1v2MvOrp0ANA80U5T6MdZ43vO4fOyuG++ATPDy7fD3K8aPh/2y7+aCy8DiPPJ7pebC9Q9CyAd/Phue/pIcn3MYgZ6/Ai67Cw69LaNaWrfDkutHH1O4VgrxRHhkx57ksp+rqPwLkHQCXYkp+PtDeLQ9RxbosdiQAFqbuxadRsc7re/gC/vo9ndPXPjqRKAosOdJ0BpklErfoYmPOfgm9LfK9mojqXlBRqms+PTU37NwNXztQ1j2SZnmb8uGrEnqmy+7EU77toxuEZrxvwSK1kunaus2+UvC25Fc9nMVlX8Bkk6g+71hYjEFr95zZIG+9S/wmyUQDWMz2FiRtYJ3W9+lOeEQTf2YTC7NH4KnCVbFS/x2VY8/pnsf+OKdhFz7R+/76H7pzCs5SqetOQ2u+B3c8qrU2I/kkD3n3+VNY+VnpZY/ksLVgJB29I64Q1TV0FVUZhVJJ9CHs0T7x6X4j6PhHSkk+9sAaXap76tna4csu3fCNHRfL7z982En457HZb/N078LCBlPPpZDI8IGe+qGt/vb5DqW3TycHXq0FK2NC+QjoNHA5b+VoYpjMdkhq1IV6Coqs5ikE+iDbpklmkj7n5SE4PFIjTxRgfGR2kcApscpuvcpqH9t9Ng7v4DX/wv+ukHazKuelpEktkwZcjiRht7wDqTmy8iRkQK9NV6nZc5Zxz/X46VorawH074LUvKmZs9XUVH52Eg+gR7PEk0U5josAQ/0NchttxToZY4ycqw5NPY34jQ5STFMQ4GcjXfAU1+EYLwbUtALHz0g4719vXD36TJxJ2GTzlowXkOPxWTiT+mZUuCPjHTp2C1t2sdT4na6KFwHoQGofVnVzlVUZiFJJ9ATzaGPaHLprBredsu+lEIITs+Xduhp0c79fTDQBv5e2PInObb7EQh64Pz/hi+8BvYCsGbC3PPk/qxKmWUZDgyfp7tGnqPkNMgoHyPQ90B6ORg+xnj5w1G0Tj6GByFHdYiqqMw2kk6gL99QhOUzbUQ1EdKMk5hcEuYWnVk6JOMkzC7TYj9PJO5Ys+D930oBv+VumYpfuBbSy+DL78JX3h9O6MlaIKNFRppVGt6Vj6WnQ0YF9B4crnTYvnv2aMOOIlkOAGbPnFRUVIZIOoGu1WvwGHrQCR1W/SRF+Tt2S804e+GQyQVgXe46UgwpLEifJIRvIhreg18tGnWuIVv45XdJE8+jn5KCet1XhiNK9GawjegAnxVvkDHS7HLobXAUS4GZUQ6xsOws5OuF/pYJu8bMCELIGxXIEgQqKiqziqSs5eIOurEb7ZMXrU8kvpgcw11+AIvewstXvTz5zWAs0Qi89H3pXD3wOqz8jBzvqgajXZahXXAZ1DwvtfXJGj6kl0nHZ+JmEIvJOPF5l8jnGfFeqD118mYAkDNLBDrIhKOAG5ylMz0TFRWVMSSdhg7gCR4hwiUalhpwzmJwFIKnRQrOOHajfXzz5cn46H7oqpLOyeYPh8c7q2X9FCHgrH8DoZXNm8fWSxmJVi+FdkJD76qSpprSeIx5+lz56KofER44iwT6/Ivh08+qXX9UVGYhSamh9wX7pEN06z0yq/KM740+oLsWoiEpCP19ctvbOT5ZZir43fDGT6H4NFkfpXmLHFcUKZQXXy2fZ1fC17eBfQq2+awF8sYQDcsoGa1BRriA7Khjy5YaeiQoQxmt6Uc/bxUVlX85klZDdxgdsmb3W3dK+/VIRia+OOIC1tPMMfH2/0pb9oU/k/ZjVz0MumSKftAzbBMHGXKoncI9MmuBdNQ+9w1ZrOuyu0bfbNLjkS7tu2eXdq6iojKrSUqB7g66pUD3dsraKDUvjD6gY4+MbkmfC/Z4eKK7adx5jkhfg4xaWfEp2ccz4RBs+XA4wuVY4sMTN4FdD8Gp35R1VEaSUS61f1f97HGIqqiozHqSTqArioI7kBDoXXJw7xOjD+rYLU0gGq20ocOxaehv3SnPcda/yed5y0Gjk2aXhFNzsoJXhyMRw11xIZw7QXehjAoI9oMSU8MDVVRUpkzS2dAHw4NElAgOrVG2QDOnySqF3i4ZHqgoUkNf+An5AmOKPOZwGnosOrGDr6cedj0sa4UnzCEGi9TUmz+UCUMpecfWo9JRBJ97RTZ7nui9E5EuoJpcVFRUpkzSaeh9wT4AHEp86qtukZps1dPxAw7JsLqRmq29cHT8eIKOvfCzfFmfZCxv/o8025z27dHjhWtlvfD2XfJXwLFSvH44LHEsGfFIF5Nj2AegoqKicgSSTqB7gtIB6ohG5UDpGTLJZc8TMNAhO9SPjBoBKRQnMrk0vi+1/Hd+OXq8s0oW3Vr3ZbBmjN5XuAYiAVnuNus4BPpk2AtldcacxcfXg1RFReVfiikJdCHEhUKIWiHEfiHEDyfY/x0hRLUQYrcQ4p9CiOLpn6rEHXQD4Eh0oLdly9DBlg/hng0yw/Kmx6VjMUFCQ1eU0Sfritd7qX1RVkUEecxr/wHGVDjl6+MnULhuePtEFczSaGH912DV507M+VVUVE5KjijQhRBa4PfARUAlcKMQYqxqugNYpSjKEuAJ4M7pnmiCvkDc5BKKF7eyZcOieCx40AOffmZ8qVlHkSwolahPnqCzWmrZOhN88Fs5tu2vUP8qnP2jie3jqbnDsebH4hCdKuf+f8PrUlFRUZkCU9HQ1wD7FUU5qChKCHgEGNX4UlGUNxRF8cWfbgYKpneawwyZXPwemUJvTpMC+/oH4fOvTdzVfSjSZYRjNJEYVHyq7Gq/6xGZ1v/Kv8nKiGu+dPhJFK6RWaMZ86ZxZSoqKirHx1QEej4w0gDdEh87HJ8HXj6eSU1GUWoRF5VcRMqgW2rnCRvzgkshs2LiFw3Foo9YhrtJ1vbOroT1t8mszX9cIzvzfOKPk3cHOvN2uPJu0JumZU0qKioq08G0OkWFEDcDq4D/Pcz+W4UQ24QQ27q7u4/pPc4oOIM7z7wT7WDX6CqGkzFRtuhQHPlCWTBrwWWyrO2VfzryeTPnwZLrjn7yKioqKieQqQj0VmBkN4iC+NgohBDnAXcAlyuKEpzoRIqi/FlRlFWKoqzKzMw8lvkO4+2SGvpUMKeB3jo6Fj3RACNhB7/8t3DLRph77vHNS0VFRWWGmIpA3wqUCyFKhRAG4AbguZEHCCGWA3cjhXnX9E9zArwdkDJFgS6E1NLH1jK3F4EpVT43O4Y78qioqKgkIUcU6IqiRICvARuBGuAxRVGqhBD/KYS4PH7Y/wI24HEhxE4hxHOHOd30EI3AYM/UNXSQMd2N7w23fkuUvlVRUVE5SZhS6r+iKC8BL40Z+/cR2+dN87wmx9cDKFO3oYMsgLXnMRlzPv8yWfhq3kUnbIoqKioqHzdJlykKyCqLcHQaeumZkFoAOx6UwjwWOXGJQSoqKiozQJIK9LiZ3pYz9ddotLDskzLWvH6THDtRqfsqKioqM0ByCvSBDvl4NCYXkAIdBd79pSyDm2j3pqKionISkJwCfcjkcpQC3VkqW8kFPLJErc4w/XNTUVFRmSGSVKB3gdF++PKzk7H8ZvmomltUVFROMpJUoHdOPQZ9LJWXy1IAc8488rEqKioqSUTSdSwCpEA/mgiXkRis8K09ap1xFRWVk47k1dCP1n4+ElWYq6ionIQkqUA/ijouKioqKv8iJJ9AD3oh5D0+DV1FRUXlJCT5BPrgMSQVqaioqPwLkHwCfeAYY9BVVFRUTnKST6AfSx0XFRUVlX8BklCgJ0wuqkBXUVFRGUnyCXR7Psy/FCzpMz0TFRUVlVlF8iUWzb9E/qmoqKiojCL5NHQVFRUVlQlRBbqKiorKSYIq0FVUVFROElSBrqKionKSoAp0FRUVlZMEVaCrqKionCSoAl1FRUXlJEEV6CoqKionCUJRlJl5YyG6gcajfFkG0HMCpjPTnKzrAnVtyYq6ttlLsaIomRPtmDGBfiwIIbYpirJqpucx3Zys6wJ1bcmKurbkRDW5qKioqJwkqAJdRUVF5SQh2QT6n2d6AieIk3VdoK4tWVHXloQklQ1dRUVFReXwJJuGrqKioqJyGFSBrqKionKSkBQCXQhxoRCiVgixXwjxw5mez1QQQhQKId4QQlQLIaqEEN+MjzuFEJuEEPXxx7T4uBBC3BVf424hxIoR5/pM/Ph6IcRnZmpNIxFCaIUQO4QQL8SflwohtsTn/6gQwhAfN8af74/vLxlxjh/Fx2uFEBfM0FJGIYRwCCGeEELsE0LUCCHWn0TX7Nvx7+JeIcTDQghTsl43IcS9QoguIcTeEWPTdp2EECuFEHvir7lLCCE+3hUeI4qizOo/QAscAOYABmAXUDnT85rCvHOBFfHtFKAOqATuBH4YH/8h8P/i2xcDLwMCWAdsiY87gYPxx7T4dtosWN93gIeAF+LPHwNuiG//CfhKfPurwJ/i2zcAj8a3K+PX0giUxq+xdhas637gC/FtA+A4Ga4ZkA8cAswjrtdnk/W6AWcAK4C9I8am7ToBH8aPFfHXXjTT380pfS4zPYEpXLj1wMYRz38E/Gim53UM63gW2ADUArnxsVygNr59N3DjiONr4/tvBO4eMT7quBlaSwHwT+Ac4IX4l74H0I29ZsBGYH18Wxc/Toy9jiOPm8F12eNCT4wZPxmuWT7QHBdeuvh1uyCZrxtQMkagT8t1iu/bN2J81HGz+S8ZTC6JL2KClvhY0hD/uboc2AJkK4rSHt/VAWTHtw+3ztm4/l8DtwOx+PN0wK0oSiT+fOQch+Yf3++JHz8b11UKdAP3xc1J9wghrJwE10xRlFbg50AT0I68Dts5Oa5bgum6Tvnx7bHjs55kEOhJjRDCBjwJfEtRlP6R+xR5+0+quFEhxKVAl6Io22d6LicAHfJn/B8VRVkODCJ/ug+RjNcMIG5PvgJ508oDrMCFMzqpE0iyXqfjJRkEeitQOOJ5QXxs1iOE0COF+YOKojwVH+4UQuTG9+cCXfHxw61ztq3/VOByIUQD8AjS7PIbwCGE0MWPGTnHofnH99sBF7NvXSA1sRZFUbbEnz+BFPDJfs0AzgMOKYrSrShKGHgKeS1PhuuWYLquU2t8e+z4rCcZBPpWoDzujTcgHTTPzfCcjkjcK/5XoEZRlF+O2PUckPCmfwZpW0+MfzrukV8HeOI/HzcC5wsh0uJa1vnxsRlBUZQfKYpSoChKCfJavK4oyk3AG8A18cPGriux3mvixyvx8Rvi0RSlQDnSETVjKIrSATQLIebFh84FqknyaxanCVgnhLDEv5uJtSX9dRvBtFyn+L5+IcS6+Gf16RHnmt3MtBF/is6Pi5FRIgeAO2Z6PlOc82nIn3y7gZ3xv4uRdsh/AvXAa4AzfrwAfh9f4x5g1Yhz3QLsj/99bqbXNmJeZzEc5TIH+Y+9H3gcMMbHTfHn++P754x4/R3x9dYyS6IIgGXAtvh1ewYZ/XBSXDPgJ8A+YC/wADJSJSmvG/Aw0hcQRv6y+vx0XidgVfxzOgD8jjGO8tn6p6b+q6ioqJwkJIPJRUVFRUVlCqgCXUVFReUkQRXoKioqKicJqkBXUVFROUlQBbqKiorKSYIq0FVUVFROElSBrqKionKS8P8DA3Lwet3P8ykAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(pd.DataFrame(performace).T)    \n",
    "pd.DataFrame(performace).T.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'CNNweight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_performance = {}\n",
    "predict = []\n",
    "true = []\n",
    "model.eval()\n",
    "for X, y in val_loader:\n",
    "    #print(X.float())\n",
    "    outputs = model(X.float()) # Forward propagation\n",
    "    val_loss = error(outputs,y.float())\n",
    "    outputs = outputs.cpu().detach().numpy()\n",
    "    y = y.cpu().detach().numpy()\n",
    "    \n",
    "    for pred in outputs:\n",
    "        predict.append(np.argmax(pred))\n",
    "    for label in y:\n",
    "        true.append(np.argmax(label))\n",
    "final_performance['val'] = tools.get_performance(true,predict)\n",
    "predict = []\n",
    "true = []\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size)\n",
    "\n",
    "for X, y in train_loader:\n",
    "    #print(X.float())\n",
    "    outputs = model(X.float()) # Forward propagation\n",
    "    val_loss = error(outputs,y.float())\n",
    "    outputs = outputs.cpu().detach().numpy()\n",
    "    y = y.cpu().detach().numpy()\n",
    "    \n",
    "    for pred in outputs:\n",
    "        predict.append(np.argmax(pred))\n",
    "    for label in y:\n",
    "        true.append(np.argmax(label))\n",
    "final_performance['train'] = tools.get_performance(true,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>confusion matrix</th>\n",
       "      <td>[[5368, 62], [54, 107]]</td>\n",
       "      <td>[[21474, 172], [123, 595]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.979252</td>\n",
       "      <td>0.986809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.633136</td>\n",
       "      <td>0.77575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.648485</td>\n",
       "      <td>0.801347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.664596</td>\n",
       "      <td>0.828691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matthews_corrcoef</th>\n",
       "      <td>0.638001</td>\n",
       "      <td>0.794996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       val                       train\n",
       "confusion matrix   [[5368, 62], [54, 107]]  [[21474, 172], [123, 595]]\n",
       "acc                               0.979252                    0.986809\n",
       "precision                         0.633136                     0.77575\n",
       "f1_score                          0.648485                    0.801347\n",
       "recall                            0.664596                    0.828691\n",
       "matthews_corrcoef                 0.638001                    0.794996"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(final_performance)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "758b741b386b57519efd53b073ac35bdb1f696dd4ad70fef9c572829f656d496"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
